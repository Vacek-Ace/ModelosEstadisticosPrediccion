[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Problemas de Modelos Estad√≠sticos para la Predicci√≥n",
    "section": "",
    "text": "Prefacio\nEste manual de soluciones complementa el libro Modelos Estad√≠sticos para la Predicci√≥n y est√° dise√±ado para proporcionar un apoyo integral al proceso de aprendizaje. Cada soluci√≥n ha sido desarrollada con el mismo rigor te√≥rico-pr√°ctico que caracteriza al curso, ofreciendo no solo la respuesta correcta, sino tambi√©n el razonamiento estad√≠stico y la interpretaci√≥n pr√°ctica necesarios para una comprensi√≥n profunda.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#filosof√≠a-pedag√≥gica",
    "href": "index.html#filosof√≠a-pedag√≥gica",
    "title": "Problemas de Modelos Estad√≠sticos para la Predicci√≥n",
    "section": "Filosof√≠a pedag√≥gica",
    "text": "Filosof√≠a pedag√≥gica\nAl igual que el libro principal, este manual sigue un enfoque ‚Äúte√≥rico-pr√°ctico‚Äù sin concesiones. Las soluciones est√°n dise√±adas para:\n\nReforzar la comprensi√≥n de los conceptos fundamentales mediante aplicaciones concretas\nDesarrollar la intuici√≥n estad√≠stica a trav√©s de interpretaciones razonadas\n\nConectar la teor√≠a con la pr√°ctica mediante c√≥digo R completamente funcional\nFomentar el pensamiento cr√≠tico sobre las limitaciones y supuestos de cada m√©todo",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#c√≥mo-usar-este-manual",
    "href": "index.html#c√≥mo-usar-este-manual",
    "title": "Problemas de Modelos Estad√≠sticos para la Predicci√≥n",
    "section": "¬øC√≥mo usar este manual?",
    "text": "¬øC√≥mo usar este manual?\nPara maximizar el beneficio de este recurso:\n\nIntentar primero: Resuelve cada ejercicio por tu cuenta antes de consultar la soluci√≥n\nEstudiar el proceso: No solo copies el c√≥digo, entiende la l√≥gica detr√°s de cada paso\n\nExperimentar: Modifica los par√°metros y observa c√≥mo cambian los resultados\nReflexionar: Considera las implicaciones pr√°cticas de cada resultado obtenido",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#metodolog√≠a-de-las-soluciones",
    "href": "index.html#metodolog√≠a-de-las-soluciones",
    "title": "Problemas de Modelos Estad√≠sticos para la Predicci√≥n",
    "section": "Metodolog√≠a de las soluciones",
    "text": "Metodolog√≠a de las soluciones\nCada soluci√≥n incluye:\n\nC√≥digo R completo: Totalmente ejecutable y comentado\nExplicaciones paso a paso: Qu√© hace cada l√≠nea y por qu√©\nInterpretaci√≥n de resultados: Qu√© significan los n√∫meros obtenidos\nGr√°ficos explicativos: Visualizaci√≥n de conceptos clave\nConsejos pr√°cticos: Cu√°ndo y c√≥mo usar cada t√©cnica\n\n\n\n\n\n\n\nImportanteUso responsable\n\n\n\nEste manual es una herramienta de aprendizaje, no un sustituto del pensamiento propio. Util√≠zalo para verificar tu comprensi√≥n y mejorar tu t√©cnica, pero siempre tras haber hecho un esfuerzo genuino por resolver los problemas de forma independiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-de-software",
    "href": "index.html#requisitos-de-software",
    "title": "Problemas de Modelos Estad√≠sticos para la Predicci√≥n",
    "section": "Requisitos de software",
    "text": "Requisitos de software\nPara ejecutar las soluciones necesitas tener instalados los siguientes paquetes de R:\n# Paquetes principales\ninstall.packages(c(\n  \"car\",           # Diagn√≥sticos avanzados\n  \"MASS\",          # Datasets y funciones estad√≠sticas  \n  \"glmnet\",        # Regularizaci√≥n\n  \"caret\",         # Machine learning\n  \"pROC\",          # Curvas ROC\n  \"fitdistrplus\",  # Ajuste de distribuciones\n  \"lmtest\"         # Tests estad√≠sticos\n))\n\n\n\n\n\n\nNotaSobre los autores\n\n\n\nV√≠ctor Ace√±a Gil es graduado en Matem√°ticas por la UNED, m√°ster en Tratamiento Estad√≠stico y Computacional de la Informaci√≥n por la UCM y la UPM, doctor en Tecnolog√≠as de la Informaci√≥n y las Comunicaciones por la URJC y profesor del departamento de Inform√°tica y Estad√≠stica de la URJC. Miembro del grupo de investigaci√≥n de alto rendimiento en Fundamentos y Aplicaciones de la Ciencia de Datos, DSLAB, de la URJC. Pertenece al grupo de innovaci√≥n docente, DSLAB-TI.\nIsaac Mart√≠n de Diego es diplomado en Estad√≠stica por la Universidad de Valladolid (UVA), licenciado en Ciencias y T√©cnicas Estad√≠sticas por la Universidad Carlos III de Madrid (UC3M), doctor en Ingenier√≠a Matem√°tica por la UC3M, catedr√°tico de Ciencias de la Computaci√≥n e Inteligencia Artificial del departamento de Inform√°tica y Estad√≠stica de la URJC. Es fundador y coordinador del DSLAB y del DSLAB-TI.\n\n\nEsta obra est√° bajo una licencia de Creative Commons Atribuci√≥n-CompartirIgual 4.0 Internacional.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html",
    "href": "tema1_regresion_simple_soluciones.html",
    "title": "1¬† Soluciones: Regresi√≥n Lineal Simple",
    "section": "",
    "text": "1.1 Ejercicio 1: Fundamentos Conceptuales\nEn este cap√≠tulo encontrar√°s las soluciones detalladas a todos los ejercicios del Tema 1. Cada ejercicio incluye tanto el enunciado como la soluci√≥n completa con c√≥digo R y explicaciones te√≥ricas.\nBas√°ndote en el texto, explica con tus propias palabras por qu√© un coeficiente de correlaci√≥n de Pearson (\\(r\\)) alto no es suficiente para modelar una relaci√≥n y por qu√© la regresi√≥n lineal es un paso m√°s all√°. Menciona al menos dos cosas que el modelo de regresi√≥n proporciona y que la correlaci√≥n por s√≠ sola no ofrece.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Soluciones: Regresi√≥n Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html#ejercicio-1-fundamentos-conceptuales",
    "href": "tema1_regresion_simple_soluciones.html#ejercicio-1-fundamentos-conceptuales",
    "title": "1¬† Soluciones: Regresi√≥n Lineal Simple",
    "section": "",
    "text": "üëÅÔ∏è Ver Soluci√≥n\n\nLa correlaci√≥n de Pearson (\\(r\\)) solo mide la fuerza y direcci√≥n de una relaci√≥n lineal entre dos variables, pero no es suficiente para modelar porque:\n\nNo proporciona un modelo predictivo: La correlaci√≥n solo nos dice qu√© tan relacionadas est√°n las variables, pero no nos permite hacer predicciones espec√≠ficas sobre una variable a partir de la otra.\nNo cuantifica el cambio: No nos dice cu√°nto cambia una variable cuando la otra cambia en una unidad espec√≠fica.\n\nLa regresi√≥n lineal va m√°s all√° porque proporciona:\n\nCapacidad predictiva: Permite predecir valores espec√≠ficos de la variable dependiente para valores dados de la independiente.\nCuantificaci√≥n del cambio: Los coeficientes nos dicen exactamente cu√°nto cambia Y por cada unidad de cambio en X.\nIntervalos de confianza y predicci√≥n: Permite cuantificar la incertidumbre de nuestras estimaciones.\nMarco para inferencia estad√≠stica: Permite realizar pruebas de hip√≥tesis sobre la significancia de la relaci√≥n.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Soluciones: Regresi√≥n Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html#ejercicio-2-interpretaci√≥n-de-coeficientes",
    "href": "tema1_regresion_simple_soluciones.html#ejercicio-2-interpretaci√≥n-de-coeficientes",
    "title": "1¬† Soluciones: Regresi√≥n Lineal Simple",
    "section": "1.2 Ejercicio 2: Interpretaci√≥n de Coeficientes",
    "text": "1.2 Ejercicio 2: Interpretaci√≥n de Coeficientes\nUn analista ajusta un modelo para predecir el gasto anual en compras online (gasto, en euros) bas√°ndose en la edad del cliente (edad). El modelo ajustado es:\ngasto = 1500 + 12 * edad\n\n¬øCu√°l es el gasto predicho para un cliente de 30 a√±os?\nInterpreta el significado de la pendiente (12) en el contexto espec√≠fico de este problema.\nInterpreta el significado del intercepto (1500). ¬øCrees que esta interpretaci√≥n tiene sentido pr√°ctico en el mundo real? ¬øPor qu√©?\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\na) Gasto predicho para un cliente de 30 a√±os:\n\n# C√°lculo directo\ngasto_30 = 1500 + 12 * 30\nprint(paste(\"Gasto predicho:\", gasto_30, \"euros\"))\n\n[1] \"Gasto predicho: 1860 euros\"\n\n\nb) Interpretaci√≥n de la pendiente (12): Por cada a√±o adicional de edad del cliente, se espera que el gasto anual en compras online aumente en 12 euros, manteniendo todo lo dem√°s constante.\nc) Interpretaci√≥n del intercepto (1500): Representa el gasto predicho para un cliente de 0 a√±os, que ser√≠a 1500 euros. Esta interpretaci√≥n NO tiene sentido pr√°ctico porque: - No existen clientes de 0 a√±os - Estamos extrapolando fuera del rango de datos observados - El modelo probablemente no es v√°lido para edades tan bajas\n:::\n\n1.2.1 Ejercicio 3: Aplicaci√≥n Pr√°ctica con R (Ajuste e Inferencia)\nUtiliza el conjunto de datos pressure de R, que contiene mediciones de temperatura y presi√≥n de vapor de mercurio.\n\nAjusta un modelo de regresi√≥n lineal simple para predecir la presi√≥n (pressure) en funci√≥n de la temperatura (temperature). Guarda el modelo en un objeto.\nUtiliza la funci√≥n summary() sobre el objeto del modelo.\nInterpreta el valor del coeficiente de determinaci√≥n R¬≤. ¬øQu√© porcentaje de la variabilidad de la presi√≥n es explicado por la temperatura?\nInterpreta el p-valor del estad√≠stico F. ¬øEs el modelo √∫til en su conjunto?\n¬øEs el coeficiente de la temperatura estad√≠sticamente significativo a un nivel de \\(\\alpha = 0.05\\)? Justifica tu respuesta bas√°ndote en el p-valor del test t.\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\n\n# a) Ajustar el modelo\nmodelo_pressure &lt;- lm(pressure ~ temperature, data = pressure)\n\n# b) Summary del modelo\nsummary(modelo_pressure)\n\n\nCall:\nlm(formula = pressure ~ temperature, data = pressure)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-158.08 -117.06  -32.84   72.30  409.43 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -147.8989    66.5529  -2.222 0.040124 *  \ntemperature    1.5124     0.3158   4.788 0.000171 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 150.8 on 17 degrees of freedom\nMultiple R-squared:  0.5742,    Adjusted R-squared:  0.5492 \nF-statistic: 22.93 on 1 and 17 DF,  p-value: 0.000171\n\n\nc) Interpretaci√≥n del R¬≤:\n\nr_squared &lt;- summary(modelo_pressure)$r.squared\nprint(paste(\"R¬≤ =\", round(r_squared, 4)))\n\n[1] \"R¬≤ = 0.5742\"\n\nprint(paste(\"La temperatura explica el\", round(r_squared * 100, 2), \"% de la variabilidad en la presi√≥n\"))\n\n[1] \"La temperatura explica el 57.42 % de la variabilidad en la presi√≥n\"\n\n\nd) Interpretaci√≥n del p-valor del estad√≠stico F:\n\nf_pvalue &lt;- summary(modelo_pressure)$fstatistic\nf_test_pvalue &lt;- pf(f_pvalue[1], f_pvalue[2], f_pvalue[3], lower.tail = FALSE)\nprint(paste(\"p-valor F-test:\", format(f_test_pvalue, scientific = TRUE)))\n\n[1] \"p-valor F-test: 1.709745e-04\"\n\n\nComo p &lt; 0.05, el modelo es globalmente significativo - es decir, el modelo es √∫til para predecir la presi√≥n.\ne) Significancia del coeficiente de temperatura:\n\ntemp_pvalue &lt;- summary(modelo_pressure)$coefficients[\"temperature\", \"Pr(&gt;|t|)\"]\nprint(paste(\"p-valor temperatura:\", format(temp_pvalue, scientific = TRUE)))\n\n[1] \"p-valor temperatura: 1.709745e-04\"\n\n\nComo p &lt; 0.05, el coeficiente de temperatura es estad√≠sticamente significativo.\n\n\n\n1.2.2 Ejercicio 4: Intervalos de Confianza y Predicci√≥n\nUsando el modelo del ejercicio anterior (lm(pressure ~ temperature, data = pressure)):\n\nCalcula el intervalo de confianza al 95% para la presi√≥n media esperada cuando la temperatura es de 250 grados.\nCalcula el intervalo de predicci√≥n al 95% para la presi√≥n de una √∫nica y nueva medici√≥n realizada a 250 grados.\n¬øCu√°l de los dos intervalos es m√°s ancho? Explica la raz√≥n te√≥rica de esta diferencia.\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\n\n# a) Intervalo de confianza para la media cuando temp = 250\nic_mean &lt;- predict(modelo_pressure, newdata = data.frame(temperature = 250), \n                   interval = \"confidence\", level = 0.95)\nprint(\"Intervalo de confianza (95%) para la presi√≥n media:\")\n\n[1] \"Intervalo de confianza (95%) para la presi√≥n media:\"\n\nprint(ic_mean)\n\n       fit      lwr      upr\n1 230.2061 143.5771 316.8351\n\n# b) Intervalo de predicci√≥n para una nueva observaci√≥n\nic_pred &lt;- predict(modelo_pressure, newdata = data.frame(temperature = 250), \n                   interval = \"prediction\", level = 0.95)\nprint(\"Intervalo de predicci√≥n (95%) para una nueva observaci√≥n:\")\n\n[1] \"Intervalo de predicci√≥n (95%) para una nueva observaci√≥n:\"\n\nprint(ic_pred)\n\n       fit      lwr      upr\n1 230.2061 -99.5663 559.9785\n\n# c) Comparaci√≥n de anchos\nancho_conf &lt;- ic_mean[3] - ic_mean[2]\nancho_pred &lt;- ic_pred[3] - ic_pred[2]\nprint(paste(\"Ancho intervalo confianza:\", round(ancho_conf, 2)))\n\n[1] \"Ancho intervalo confianza: 173.26\"\n\nprint(paste(\"Ancho intervalo predicci√≥n:\", round(ancho_pred, 2)))\n\n[1] \"Ancho intervalo predicci√≥n: 659.54\"\n\n\nc) ¬øCu√°l es m√°s ancho? El intervalo de predicci√≥n es m√°s ancho porque incluye dos fuentes de incertidumbre: 1. La incertidumbre sobre la media poblacional (como en el intervalo de confianza) 2. La variabilidad natural de las observaciones individuales alrededor de esa media\n\n\n\n1.2.3 Ejercicio 5: Supuestos del Modelo\nEnumera los cuatro supuestos del modelo de regresi√≥n lineal cl√°sico (tambi√©n conocidos como supuestos de Gauss-Markov) y explica brevemente la importancia de cada uno.\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\nLos cuatro supuestos de Gauss-Markov son:\n\nLinealidad: La relaci√≥n entre X e Y es lineal. Importante porque si no se cumple, las predicciones ser√°n sistem√°ticamente err√≥neas.\nIndependencia: Las observaciones son independientes entre s√≠. Crucial para que los errores est√°ndar sean correctos.\nHomocedasticidad: La varianza de los errores es constante. Necesario para que los intervalos de confianza y las pruebas de hip√≥tesis sean v√°lidas.\nNormalidad de los errores: Los errores siguen una distribuci√≥n normal. Importante para la validez de las pruebas de hip√≥tesis y los intervalos de confianza.\n\n\n\n\n1.2.4 Ejercicio 6: Diagn√≥stico de Linealidad y Homocedasticidad\nPara el modelo del ejercicio 3:\n\nGenera y muestra el gr√°fico de Residuos vs.¬†Valores Ajustados. Bas√°ndote en este gr√°fico, ¬øse cumple el supuesto de linealidad? Explica en qu√© te basas.\nGenera y muestra el gr√°fico Scale-Location. Bas√°ndote en este gr√°fico, ¬øse cumple el supuesto de homocedasticidad? Describe el patr√≥n que indicar√≠a un problema de heterocedasticidad.\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\n\n# a) Gr√°fico de Residuos vs. Valores Ajustados\npar(mfrow = c(1, 2))\nplot(modelo_pressure, which = 1, main = \"Residuos vs. Valores Ajustados\")\n\n# b) Gr√°fico Scale-Location\nplot(modelo_pressure, which = 3, main = \"Scale-Location\")\n\n\n\n\n\n\n\n\na) Linealidad: En el gr√°fico de residuos vs.¬†valores ajustados, observamos un patr√≥n curvado en lugar de una distribuci√≥n aleatoria alrededor de cero. Esto indica que NO se cumple perfectamente el supuesto de linealidad.\na) Linealidad: En el gr√°fico de residuos vs.¬†valores ajustados, observamos un patr√≥n curvado en lugar de una distribuci√≥n aleatoria alrededor de cero. Esto indica que NO se cumple perfectamente el supuesto de linealidad.\nb) Homocedasticidad: En el gr√°fico Scale-Location, la l√≠nea roja muestra una tendencia creciente, lo que sugiere heterocedasticidad (varianza no constante). Un problema de heterocedasticidad se manifestar√≠a como un patr√≥n de embudo o una tendencia clara en este gr√°fico.\n\n\n\n1.2.5 Ejercicio 7: Diagn√≥stico de Normalidad\nPara el modelo del ejercicio 3:\n\nGenera un gr√°fico Normal Q-Q de los residuos. ¬øParecen seguir los residuos una distribuci√≥n normal?\nRealiza un test de Shapiro-Wilk sobre los residuos del modelo. ¬øQu√© concluyes a partir del p-valor?\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\n\n# a) Gr√°fico Normal Q-Q\npar(mfrow = c(1, 1))\nplot(modelo_pressure, which = 2, main = \"Normal Q-Q Plot\")\n\n\n\n\n\n\n\n# b) Test de Shapiro-Wilk\nshapiro_test &lt;- shapiro.test(residuals(modelo_pressure))\nprint(\"Test de Shapiro-Wilk para normalidad de residuos:\")\n\n[1] \"Test de Shapiro-Wilk para normalidad de residuos:\"\n\nprint(shapiro_test)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_pressure)\nW = 0.89337, p-value = 0.03697\n\n\na) Q-Q Plot: Los puntos se desv√≠an considerablemente de la l√≠nea diagonal, especialmente en las colas, indicando que los residuos no siguen una distribuci√≥n normal.\nb) Test de Shapiro-Wilk: Con p-valor &lt; 0.05, rechazamos la hip√≥tesis nula de normalidad. Los residuos no son normales.\n\n\n\n1.2.6 Ejercicio 8: Descomposici√≥n de la Varianza (ANOVA)\nExplica qu√© representan la Suma de Cuadrados Total (SST), la Suma de Cuadrados de la Regresi√≥n (SSR) y la Suma de Cuadrados del Error (SSE). ¬øCu√°l es la ecuaci√≥n fundamental que las relaciona?\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\n\nSST (Suma de Cuadrados Total): Mide la variabilidad total en Y alrededor de su media. \\(SST = \\sum(y_i - \\bar{y})^2\\)\nSSR (Suma de Cuadrados de la Regresi√≥n): Mide la variabilidad explicada por el modelo. \\(SSR = \\sum(\\hat{y}_i - \\bar{y})^2\\)\nSSE (Suma de Cuadrados del Error): Mide la variabilidad no explicada (residual). \\(SSE = \\sum(y_i - \\hat{y}_i)^2\\)\n\nEcuaci√≥n fundamental: \\(SST = SSR + SSE\\)\nEsta descomposici√≥n permite calcular el coeficiente de determinaci√≥n: \\(R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\\)\n\n\n\n1.2.7 Ejercicio 9: Observaciones Influyentes\nBasado en la teor√≠a de los apuntes:\n\nExplica la diferencia entre un residuo simple (\\(e_i\\)), un residuo estandarizado y un residuo estudentizado. ¬øPor qu√© se prefieren los estudentizados para el diagn√≥stico?\n¬øQu√© mide el leverage (\\(h_{ii}\\))? ¬øY la distancia de Cook (\\(D_i\\))? ¬øPuede una observaci√≥n tener un leverage alto y no ser influyente?\n\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\na) Tipos de residuos:\n\nResiduo simple (\\(e_i\\)): \\(e_i = y_i - \\hat{y}_i\\). Diferencia bruta entre observado y predicho.\nResiduo estandarizado: \\(\\frac{e_i}{\\hat{\\sigma}}\\). Residuo dividido por la desviaci√≥n est√°ndar residual.\nResiduo estudentizado: \\(\\frac{e_i}{\\hat{\\sigma}_{(i)}\\sqrt{1-h_{ii}}}\\). Usa la desviaci√≥n est√°ndar calculada sin la observaci√≥n i-√©sima.\n\nLos estudentizados se prefieren porque tienen propiedades estad√≠sticas m√°s estables y siguen una distribuci√≥n t conocida.\nb) Medidas de influencia:\n\nLeverage (\\(h_{ii}\\)): Mide qu√© tan extrema es una observaci√≥n en el espacio de las X. Valores altos indican observaciones con valores de X inusuales.\nDistancia de Cook (\\(D_i\\)): Mide el cambio en las predicciones si se elimina la observaci√≥n i. Combina residuo y leverage.\n\nS√≠, una observaci√≥n puede tener leverage alto pero no ser influyente si est√° cerca de la l√≠nea de regresi√≥n (residuo peque√±o).\n\n\n\n1.2.8 Ejercicio 10: Relaci√≥n entre Pruebas de Hip√≥tesis\nEn el contexto exclusivo de la regresi√≥n lineal simple, ¬øqu√© relaci√≥n matem√°tica existe entre el estad√≠stico F del test ANOVA y el estad√≠stico t del test para la pendiente \\(\\beta_1\\)? ¬øQu√© implica esto para sus respectivos p-valores?\n\n\nüëÅÔ∏è Ver Soluci√≥n\n\nEn regresi√≥n lineal simple, existe una relaci√≥n matem√°tica exacta:\n\\[F = t^2\\]\nDonde: - \\(F\\) es el estad√≠stico F del test ANOVA global - \\(t\\) es el estad√≠stico t para la pendiente \\(\\beta_1\\)\nImplicaciones para los p-valores: - Los p-valores de ambos tests son id√©nticos - Si el coeficiente de la pendiente es significativo (test t), entonces el modelo global tambi√©n lo es (test F) - Ambos tests eval√∫an la misma hip√≥tesis nula: \\(H_0: \\beta_1 = 0\\)\nEsta equivalencia solo se da en regresi√≥n simple. En regresi√≥n m√∫ltiple, el test F eval√∫a todos los coeficientes conjuntamente, mientras que cada test t eval√∫a coeficientes individuales.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Soluciones: Regresi√≥n Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html",
    "href": "tema2_regresion_multiple_soluciones.html",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "",
    "text": "2.1 Ejercicio 1: Conceptual (Interpretaci√≥n Ceteris Paribus)\nUn analista ajusta dos modelos para predecir el consumo de un coche (mpg):\nExplica detalladamente por qu√© el coeficiente para la variable wt (peso) cambia al a√±adir la variable hp (caballos de fuerza). ¬øCu√°l de los dos coeficientes representa el efecto ‚Äúpuro‚Äù o ‚Äúaislado‚Äù del peso? Fundamenta tu respuesta en el principio de ceteris paribus.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-1-conceptual-interpretaci√≥n-ceteris-paribus",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-1-conceptual-interpretaci√≥n-ceteris-paribus",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "",
    "text": "lm(mpg ~ wt) obtiene un coeficiente para wt de -5.3.\nlm(mpg ~ wt + hp) obtiene un coeficiente para wt de -3.8.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-2-pr√°ctico-ajuste-e-interpretaci√≥n-de-un-modelo-m√∫ltiple",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-2-pr√°ctico-ajuste-e-interpretaci√≥n-de-un-modelo-m√∫ltiple",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.2 Ejercicio 2: Pr√°ctico (Ajuste e Interpretaci√≥n de un Modelo M√∫ltiple)",
    "text": "2.2 Ejercicio 2: Pr√°ctico (Ajuste e Interpretaci√≥n de un Modelo M√∫ltiple)\nUsa el conjunto de datos iris de R. Queremos modelar la anchura del p√©talo (Petal.Width) en funci√≥n de la longitud del p√©talo (Petal.Length) y la anchura del s√©palo (Sepal.Width).\n\nAjusta un modelo de regresi√≥n lineal m√∫ltiple: lm(Petal.Width ~ Petal.Length + Sepal.Width, data = iris).\nInterpreta el coeficiente estimado para Petal.Length.\nInterpreta el coeficiente estimado para Sepal.Width.\nInterpreta el intercepto del modelo. ¬øTiene un significado pr√°ctico en este contexto biol√≥gico?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-3-conceptual-r¬≤-vs.-r¬≤-ajustado",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-3-conceptual-r¬≤-vs.-r¬≤-ajustado",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.3 Ejercicio 3: Conceptual (R¬≤ vs.¬†R¬≤ Ajustado)",
    "text": "2.3 Ejercicio 3: Conceptual (R¬≤ vs.¬†R¬≤ Ajustado)\nCuando pasamos de un modelo simple a uno m√∫ltiple, introducimos el R¬≤ ajustado como medida de bondad de ajuste.\n\n¬øCu√°l es el principal problema de usar el R¬≤ tradicional para comparar modelos con diferente n√∫mero de predictores?\n¬øC√≥mo soluciona el R¬≤ ajustado este problema? Explica qu√© ‚Äúpenalizaci√≥n‚Äù introduce en su f√≥rmula.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-4-interpretaci√≥n-de-salidas-de-r",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-4-interpretaci√≥n-de-salidas-de-r",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.4 Ejercicio 4: Interpretaci√≥n de Salidas de R",
    "text": "2.4 Ejercicio 4: Interpretaci√≥n de Salidas de R\nTe presentan el siguiente resumen de un modelo que predice el prestigio de una ocupaci√≥n (prestige) en funci√≥n de los ingresos (income) y el nivel educativo (education).\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.0647    4.2750   -1.419   0.1595    \nincome       0.0013    0.0003    4.524   1.9e-05 ***\neducation    4.1832    0.3887   10.762   &lt; 2e-16 ***\n\nMultiple R-squared:  0.79,  Adjusted R-squared:  0.785 \nF-statistic: 185.6 on 2 and 99 DF,  p-value: &lt; 2.2e-16\n\n¬øEs el modelo globalmente significativo? ¬øEn qu√© te basas?\n¬øSon los predictores income y education individualmente significativos, despu√©s de controlar por el efecto del otro? Justifica tu respuesta.\nExplica la diferencia conceptual entre lo que eval√∫a el test F global y lo que eval√∫an los tests t individuales en este modelo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-5-conceptual-multicolinealidad",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-5-conceptual-multicolinealidad",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.5 Ejercicio 5: Conceptual (Multicolinealidad)",
    "text": "2.5 Ejercicio 5: Conceptual (Multicolinealidad)\nDescribe con tus propias palabras qu√© es la multicolinealidad. Menciona tres consecuencias negativas que puede tener la multicolinealidad severa en un modelo de regresi√≥n y si afecta m√°s a la predicci√≥n o a la inferencia.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-6-pr√°ctico-diagn√≥stico-de-multicolinealidad",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-6-pr√°ctico-diagn√≥stico-de-multicolinealidad",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.6 Ejercicio 6: Pr√°ctico (Diagn√≥stico de Multicolinealidad)",
    "text": "2.6 Ejercicio 6: Pr√°ctico (Diagn√≥stico de Multicolinealidad)\nUsa el dataset mtcars. Ajusta un modelo para predecir el consumo (mpg) usando como predictores el n√∫mero de cilindros (cyl), la cilindrada (disp), los caballos de fuerza (hp) y el peso (wt).\n\nObserva el summary() del modelo. ¬øHay alguna variable que, a pesar de tener una alta correlaci√≥n simple con mpg, no resulte significativa en el modelo m√∫ltiple?\nCarga la librer√≠a car y calcula el Factor de Inflaci√≥n de la Varianza (VIF) para cada predictor.\nBas√°ndote en los valores del VIF, ¬øqu√© variables presentan un problema de multicolinealidad? ¬øCu√°l es tu recomendaci√≥n para simplificar el modelo?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-7-te√≥rico-notaci√≥n-matricial",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-7-te√≥rico-notaci√≥n-matricial",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.7 Ejercicio 7: Te√≥rico (Notaci√≥n Matricial)",
    "text": "2.7 Ejercicio 7: Te√≥rico (Notaci√≥n Matricial)\n\nEscribe la f√≥rmula del estimador de M√≠nimos Cuadrados Ordinarios (\\(\\hat{\\mathbf{\\beta}}\\)) en notaci√≥n matricial.\n¬øQu√© supuesto fundamental del modelo de regresi√≥n m√∫ltiple garantiza que la matriz \\((\\mathbf{X}^T\\mathbf{X})\\) sea invertible?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-8-pr√°ctico-gr√°ficos-de-regresi√≥n-parcial",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-8-pr√°ctico-gr√°ficos-de-regresi√≥n-parcial",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.8 Ejercicio 8: Pr√°ctico (Gr√°ficos de Regresi√≥n Parcial)",
    "text": "2.8 Ejercicio 8: Pr√°ctico (Gr√°ficos de Regresi√≥n Parcial)\nUsa el dataset Prestige de la librer√≠a car.\n\nAjusta el modelo lm(prestige ~ income + education + women, data = Prestige).\nGenera los gr√°ficos de regresi√≥n parcial (o ‚Äúadded-variable plots‚Äù) para este modelo usando la funci√≥n avPlots(tu_modelo).\nExplica qu√© representa el gr√°fico para la variable education. ¬øQu√© significan los ejes X e Y de ese gr√°fico espec√≠fico? ¬øA qu√© corresponde la pendiente de la l√≠nea en ese gr√°fico?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-9-inferencia-f-test-vs.-t-tests",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-9-inferencia-f-test-vs.-t-tests",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.9 Ejercicio 9: Inferencia (F-test vs.¬†t-tests)",
    "text": "2.9 Ejercicio 9: Inferencia (F-test vs.¬†t-tests)\nDescribe un escenario hipot√©tico en el que el test F global de un modelo de regresi√≥n m√∫ltiple sea altamente significativo (p &lt; 0.001), pero ninguno de los tests t individuales para los coeficientes sea significativo. ¬øCu√°l es la causa estad√≠stica m√°s probable de este fen√≥meno?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-10-pr√°ctico-comparaci√≥n-de-modelos-anidados",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-10-pr√°ctico-comparaci√≥n-de-modelos-anidados",
    "title": "2¬† Regresi√≥n Lineal M√∫ltiple",
    "section": "2.10 Ejercicio 10: Pr√°ctico (Comparaci√≥n de Modelos Anidados)",
    "text": "2.10 Ejercicio 10: Pr√°ctico (Comparaci√≥n de Modelos Anidados)\nUsa el dataset swiss.\n\nAjusta un modelo reducido para predecir Fertility usando solo Agriculture y Education.\nAjusta un modelo completo que, adem√°s de las variables anteriores, incluya Catholic y Infant.Mortality.\nUtiliza la funci√≥n anova() para comparar formalmente los dos modelos. ¬øAportan las variables Catholic y Infant.Mortality una mejora estad√≠sticamente significativa al modelo? Interpreta el p-valor del test F resultante.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>**Regresi√≥n Lineal M√∫ltiple**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "",
    "text": "3.1 Ejercicio 1: Conceptual (Diagn√≥stico antes de Transformar)\nEl texto desaconseja fuertemente el enfoque de ‚Äúensayo y error‚Äù al aplicar transformaciones. Explica con tus propias palabras por qu√© la pr√°ctica de probar transformaciones hasta que mejore el R¬≤ es metodol√≥gicamente peligrosa. Menciona al menos tres de los riesgos espec√≠ficos discutidos en los apuntes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-2-pr√°ctico-escalado-de-variables",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-2-pr√°ctico-escalado-de-variables",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.2 Ejercicio 2: Pr√°ctico (Escalado de Variables)",
    "text": "3.2 Ejercicio 2: Pr√°ctico (Escalado de Variables)\nUtiliza el dataset iris de R y c√©ntrate en las cuatro variables predictoras continuas (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width).\n\nCalcula la media y la desviaci√≥n est√°ndar de estas cuatro variables en su escala original. ¬øSon sus escalas directamente comparables?\nCrea un nuevo data frame donde hayas aplicado la estandarizaci√≥n Z-Score a estas cuatro variables. Verifica que las nuevas variables tienen una media cercana a 0 y una desviaci√≥n est√°ndar de 1.\n¬øPor qu√© este paso de escalado es crucial antes de aplicar m√©todos de regularizaci√≥n como Ridge o Lasso, tal y como se menciona en el texto?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-3-conceptual-elecci√≥n-del-m√©todo-de-escalado",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-3-conceptual-elecci√≥n-del-m√©todo-de-escalado",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.3 Ejercicio 3: Conceptual (Elecci√≥n del M√©todo de Escalado)",
    "text": "3.3 Ejercicio 3: Conceptual (Elecci√≥n del M√©todo de Escalado)\nDescribe un escenario hipot√©tico para cada uno de los siguientes casos, explicando por qu√© el m√©todo de escalado elegido ser√≠a el m√°s apropiado:\n\nUn escenario donde la estandarizaci√≥n Z-Score es preferible.\nUn escenario donde la normalizaci√≥n Min-Max es preferible.\nUn escenario donde el escalado robusto (usando mediana y IQR) es necesario.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-4-pr√°ctico-transformaci√≥n-para-linealizar",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-4-pr√°ctico-transformaci√≥n-para-linealizar",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.4 Ejercicio 4: Pr√°ctico (Transformaci√≥n para Linealizar)",
    "text": "3.4 Ejercicio 4: Pr√°ctico (Transformaci√≥n para Linealizar)\nEn el tema anterior vimos que la relaci√≥n en el dataset cars (entre speed y dist) no era perfectamente lineal.\n\nAjusta el modelo lm(dist ~ speed, data = cars) y genera el gr√°fico de residuos vs.¬†valores ajustados para confirmar visualmente la no linealidad (patr√≥n curvo).\nLos apuntes sugieren que la transformaci√≥n logar√≠tmica es √∫til para relaciones con ‚Äúrendimientos decrecientes‚Äù. Prop√≥n y aplica una transformaci√≥n (ej. sobre el predictor, la respuesta, o ambos) para intentar linealizar la relaci√≥n. Por ejemplo, ajusta lm(log(dist) ~ speed, data = cars).\nGenera de nuevo el gr√°fico de residuos vs.¬†valores ajustados para el nuevo modelo. Compara ambos diagn√≥sticos. ¬øHa mejorado la linealidad?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-5-pr√°ctico-transformaci√≥n-de-box-cox",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-5-pr√°ctico-transformaci√≥n-de-box-cox",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.5 Ejercicio 5: Pr√°ctico (Transformaci√≥n de Box-Cox)",
    "text": "3.5 Ejercicio 5: Pr√°ctico (Transformaci√≥n de Box-Cox)\nUsa el dataset Boston de la librer√≠a MASS. La variable respuesta medv (valor mediano de la vivienda) es estrictamente positiva y tiene cierta asimetr√≠a.\n\nCarga la librer√≠a MASS y utiliza la funci√≥n boxcox() para encontrar el valor de \\(\\lambda\\) √≥ptimo para la variable medv en un modelo simple frente a lstat. La f√≥rmula ser√≠a boxcox(medv ~ lstat, data = Boston).\nObservando el gr√°fico que se genera, ¬øa qu√© valor ‚Äúsimple‚Äù (como -1, 0, 0.5, 1) se aproxima el \\(\\lambda\\) √≥ptimo?\nBas√°ndote en este resultado, ¬øcu√°l de las transformaciones cl√°sicas (logar√≠tmica, ra√≠z cuadrada, inversa, etc.) ser√≠a la m√°s recomendable para la variable medv?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-6-conceptual-codificaci√≥n-de-variables-categ√≥ricas",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-6-conceptual-codificaci√≥n-de-variables-categ√≥ricas",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.6 Ejercicio 6: Conceptual (Codificaci√≥n de Variables Categ√≥ricas)",
    "text": "3.6 Ejercicio 6: Conceptual (Codificaci√≥n de Variables Categ√≥ricas)\nExplica la diferencia fundamental entre la Codificaci√≥n Ordinal y la Codificaci√≥n One-Hot. Para cada una de las siguientes variables, indica qu√© m√©todo de codificaci√≥n usar√≠as y justifica tu elecci√≥n:\n\nmes: (‚ÄúEnero‚Äù, ‚ÄúFebrero‚Äù, ‚ÄúMarzo‚Äù, ‚Ä¶)\nnivel_riesgo: (‚ÄúBajo‚Äù, ‚ÄúMedio‚Äù, ‚ÄúAlto‚Äù, ‚ÄúCr√≠tico‚Äù)\npais_origen: (‚ÄúEspa√±a‚Äù, ‚ÄúFrancia‚Äù, ‚ÄúAlemania‚Äù, ‚ÄúItalia‚Äù)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-7-pr√°ctico-interacci√≥n-entre-variables-continuas",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-7-pr√°ctico-interacci√≥n-entre-variables-continuas",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.7 Ejercicio 7: Pr√°ctico (Interacci√≥n entre Variables Continuas)",
    "text": "3.7 Ejercicio 7: Pr√°ctico (Interacci√≥n entre Variables Continuas)\nUsa el dataset mtcars para investigar si el efecto del peso de un coche (wt) sobre su consumo (mpg) depende de su potencia (hp).\n\nAjusta un modelo que incluya un t√©rmino de interacci√≥n entre wt y hp. Escribe la f√≥rmula en R.\nObserva el summary() del modelo. ¬øEs el t√©rmino de interacci√≥n (wt:hp) estad√≠sticamente significativo a un nivel de \\(\\alpha = 0.05\\)?\nBas√°ndote en el signo del coeficiente de la interacci√≥n, ¬øc√≥mo cambia el efecto del peso sobre el consumo a medida que aumenta la potencia? (Es decir, ¬øel efecto negativo del peso se hace m√°s fuerte o m√°s d√©bil en los coches m√°s potentes?).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-8-interpretaci√≥n-de-una-interacci√≥n-continua-x-categ√≥rica",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-8-interpretaci√≥n-de-una-interacci√≥n-continua-x-categ√≥rica",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.8 Ejercicio 8: Interpretaci√≥n de una Interacci√≥n (Continua x Categ√≥rica)",
    "text": "3.8 Ejercicio 8: Interpretaci√≥n de una Interacci√≥n (Continua x Categ√≥rica)\nUn investigador modela el salario (salario, en euros) en funci√≥n de los a√±os de experiencia (experiencia) y si el empleado tiene o no un m√°ster (master, con ‚ÄúNo‚Äù como categor√≠a de referencia). El modelo ajustado es:\nsalario = 30000 + 1200*experiencia + 8000*masterSi + 300*experiencia:masterSi\n\nEscribe la ecuaci√≥n de regresi√≥n espec√≠fica para los empleados que no tienen un m√°ster.\nEscribe la ecuaci√≥n de regresi√≥n espec√≠fica para los empleados que s√≠ tienen un m√°ster.\nInterpreta el coeficiente de la interacci√≥n (300). ¬øQu√© nos dice sobre el retorno econ√≥mico de la experiencia para ambos grupos?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-9-conceptual-principio-de-jerarqu√≠a",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-9-conceptual-principio-de-jerarqu√≠a",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.9 Ejercicio 9: Conceptual (Principio de Jerarqu√≠a)",
    "text": "3.9 Ejercicio 9: Conceptual (Principio de Jerarqu√≠a)\nExplica el principio de jerarqu√≠a en el contexto de los modelos de regresi√≥n con interacciones. Si un modelo incluye el t√©rmino de interacci√≥n A:B, ¬øpor qu√© es una buena pr√°ctica incluir siempre los efectos principales A y B, incluso si sus tests t individuales no son significativos?",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-10-conceptual-ingenier√≠a-de-caracter√≠sticas-avanzada",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-10-conceptual-ingenier√≠a-de-caracter√≠sticas-avanzada",
    "title": "3¬† Ingenier√≠a de Caracter√≠sticas",
    "section": "3.10 Ejercicio 10: Conceptual (Ingenier√≠a de Caracter√≠sticas Avanzada)",
    "text": "3.10 Ejercicio 10: Conceptual (Ingenier√≠a de Caracter√≠sticas Avanzada)\nLos apuntes discuten la creaci√≥n de nuevas variables mediante ratios y combinaciones. Para cada uno de los siguientes escenarios, prop√≥n una nueva variable (feature) que podr√≠as crear y explica qu√© relaci√≥n podr√≠a capturar mejor que las variables originales por s√≠ solas.\n\nPara predecir la rentabilidad de una tienda, tienes las variables ventas_totales y numero_de_empleados.\nPara predecir el riesgo de impago de un solicitante de pr√©stamo, tienes las variables ingresos_anuales y deuda_total.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>**Ingenier√≠a de Caracter√≠sticas**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html",
    "href": "tema4_seleccion_validacion_soluciones.html",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "",
    "text": "4.1 Ejercicio 1: Conceptual (Sobreajuste vs.¬†Subajuste)\nExplica con tus propias palabras qu√© es el sobreajuste (overfitting) y el subajuste (underfitting). Describe los s√≠ntomas de cada uno comparando el error de entrenamiento con el error de validaci√≥n (o de test), y menciona la soluci√≥n principal para cada problema.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-2-pr√°ctico-filtrado-b√°sico",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-2-pr√°ctico-filtrado-b√°sico",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.2 Ejercicio 2: Pr√°ctico (Filtrado B√°sico)",
    "text": "4.2 Ejercicio 2: Pr√°ctico (Filtrado B√°sico)\nImagina que recibes un nuevo conjunto de datos con 50 predictores para un modelo de regresi√≥n. Antes de aplicar m√©todos computacionalmente costosos, decides hacer un filtrado inicial. Describe los cuatro criterios b√°sicos que aplicar√≠as para descartar variables de forma preliminar, seg√∫n lo explicado en los apuntes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-3-conceptual-aic-vs.-bic",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-3-conceptual-aic-vs.-bic",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.3 Ejercicio 3: Conceptual (AIC vs.¬†BIC)",
    "text": "4.3 Ejercicio 3: Conceptual (AIC vs.¬†BIC)\nTanto el AIC como el BIC son criterios para comparar modelos, pero se basan en filosof√≠as distintas y tienen penalizaciones diferentes.\n\nEscribe la f√≥rmula de la penalizaci√≥n por complejidad para el AIC y para el BIC.\n¬øCu√°l de los dos criterios tender√° a seleccionar modelos m√°s simples (m√°s parsimoniosos)? ¬øPor qu√©?\nSi tu objetivo principal es la precisi√≥n predictiva, ¬øcu√°l de los dos criterios es generalmente preferido?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-4-pr√°ctico-best-subset-y-criterios-de-informaci√≥n",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-4-pr√°ctico-best-subset-y-criterios-de-informaci√≥n",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.4 Ejercicio 4: Pr√°ctico (Best Subset y Criterios de Informaci√≥n)",
    "text": "4.4 Ejercicio 4: Pr√°ctico (Best Subset y Criterios de Informaci√≥n)\nUsa el conjunto de datos mtcars y la librer√≠a leaps.\n\nUtiliza la funci√≥n regsubsets() para realizar una selecci√≥n del mejor subconjunto (best subset selection) para predecir mpg usando el resto de variables.\nObt√©n el summary() de los resultados. ¬øQu√© modelo (cu√°ntas variables) es el mejor seg√∫n el criterio Cp de Mallows?\n¬øY cu√°l es el mejor modelo seg√∫n el R¬≤ ajustado?\n¬øCoinciden ambos criterios en el n√∫mero de variables del modelo √≥ptimo?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-5-conceptual-m√©todos-stepwise",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-5-conceptual-m√©todos-stepwise",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.5 Ejercicio 5: Conceptual (M√©todos Stepwise)",
    "text": "4.5 Ejercicio 5: Conceptual (M√©todos Stepwise)\nLos m√©todos autom√°ticos paso a paso (forward, backward, stepwise) son computacionalmente eficientes, pero el texto advierte sobre su uso. Menciona y explica brevemente tres de las principales limitaciones o problemas de estos m√©todos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-6-pr√°ctico-selecci√≥n-backward-stepwise",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-6-pr√°ctico-selecci√≥n-backward-stepwise",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.6 Ejercicio 6: Pr√°ctico (Selecci√≥n Backward Stepwise)",
    "text": "4.6 Ejercicio 6: Pr√°ctico (Selecci√≥n Backward Stepwise)\nUtiliza el conjunto de datos swiss para predecir Fertility.\n\nAjusta el modelo completo: modelo_completo &lt;- lm(Fertility ~ ., data = swiss).\nUtiliza la funci√≥n step() para realizar una selecci√≥n regresiva (backward) basada en el criterio AIC.\nReporta la f√≥rmula del modelo final que selecciona el algoritmo y su valor de AIC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-7-conceptual-ridge-vs.-lasso",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-7-conceptual-ridge-vs.-lasso",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.7 Ejercicio 7: Conceptual (Ridge vs.¬†Lasso)",
    "text": "4.7 Ejercicio 7: Conceptual (Ridge vs.¬†Lasso)\nLa regresi√≥n Ridge y Lasso son dos m√©todos de regularizaci√≥n muy populares, pero tienen un efecto fundamentalmente diferente sobre los coeficientes del modelo.\n\n¬øQu√© tipo de penalizaci√≥n utiliza cada m√©todo (\\(L_1\\) o \\(L_2\\))?\n¬øCu√°l de los dos m√©todos puede realizar selecci√≥n de variables (es decir, anular coeficientes por completo)?\nDescribe un escenario en el que preferir√≠as usar Ridge sobre Lasso.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-8-pr√°ctico-regresi√≥n-lasso",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-8-pr√°ctico-regresi√≥n-lasso",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.8 Ejercicio 8: Pr√°ctico (Regresi√≥n Lasso)",
    "text": "4.8 Ejercicio 8: Pr√°ctico (Regresi√≥n Lasso)\nUtiliza el paquete glmnet y el conjunto de datos mtcars para predecir mpg.\n\nPrepara los datos: crea una matriz x para los predictores y un vector y para la respuesta.\nUtiliza la funci√≥n cv.glmnet() para realizar una validaci√≥n cruzada y encontrar el valor de lambda √≥ptimo para una regresi√≥n Lasso (alpha = 1).\nExtrae y muestra los coeficientes del modelo Lasso ajustado con el lambda.min.\n¬øQu√© variables ha eliminado el modelo (coeficientes iguales a cero)?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-9-conceptual-validaci√≥n",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-9-conceptual-validaci√≥n",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.9 Ejercicio 9: Conceptual (Validaci√≥n)",
    "text": "4.9 Ejercicio 9: Conceptual (Validaci√≥n)\nExplica la diferencia entre la estrategia de validaci√≥n Train/Test Split simple y la Validaci√≥n Cruzada k-fold. ¬øCu√°l es la principal ventaja de la validaci√≥n cruzada sobre la divisi√≥n simple? ¬øEn qu√© situaci√≥n (tama√±o del dataset) recomendar√≠as usar cada una?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-10-pr√°ctico-validaci√≥n-cruzada",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-10-pr√°ctico-validaci√≥n-cruzada",
    "title": "4¬† Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n",
    "section": "4.10 Ejercicio 10: Pr√°ctico (Validaci√≥n Cruzada)",
    "text": "4.10 Ejercicio 10: Pr√°ctico (Validaci√≥n Cruzada)\nImagina que has ajustado dos modelos para predecir mpg en el dataset mtcars: 1. Un modelo simple: mpg ~ wt + hp 2. Un modelo complejo: mpg ~ . (todas las variables)\nUtilizando la librer√≠a caret y la funci√≥n train(), como se muestra en el callout-tip ‚ÄúLa maldici√≥n del sobreajuste‚Äù, configura y ejecuta una validaci√≥n cruzada de 10 particiones para estimar el RMSE de ambos modelos. ¬øCu√°l de los dos modelos generaliza mejor a nuevos datos seg√∫n esta estimaci√≥n?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>**Selecci√≥n de variables, Regularizaci√≥n y Validaci√≥n**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html",
    "href": "tema5_glm_soluciones.html",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "",
    "text": "5.1 Ejercicio 1: Conceptual (Fundamentos de GLM)\nExplica los tres componentes clave que definen a cualquier Modelo Lineal Generalizado (GLM) y describe brevemente la funci√≥n de cada uno.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-2-conceptual-funci√≥n-de-enlace",
    "href": "tema5_glm_soluciones.html#ejercicio-2-conceptual-funci√≥n-de-enlace",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.2 Ejercicio 2: Conceptual (Funci√≥n de Enlace)",
    "text": "5.2 Ejercicio 2: Conceptual (Funci√≥n de Enlace)\n¬øCu√°l es el prop√≥sito fundamental de la funci√≥n de enlace en un GLM? ¬øPor qu√© la regresi√≥n lineal cl√°sica es considerada un caso particular de un GLM? (Pista: piensa en su funci√≥n de enlace).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-3-pr√°ctico-ajuste-de-un-modelo-log√≠stico",
    "href": "tema5_glm_soluciones.html#ejercicio-3-pr√°ctico-ajuste-de-un-modelo-log√≠stico",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.3 Ejercicio 3: Pr√°ctico (Ajuste de un Modelo Log√≠stico)",
    "text": "5.3 Ejercicio 3: Pr√°ctico (Ajuste de un Modelo Log√≠stico)\nUsa el conjunto de datos mtcars de R. La variable am indica si la transmisi√≥n de un coche es autom√°tica (0) o manual (1).\n\nAjusta un modelo de regresi√≥n log√≠stica para predecir la probabilidad de que una transmisi√≥n sea manual (am) en funci√≥n del peso del coche (wt) y los caballos de fuerza (hp).\nUtiliza la funci√≥n summary() para examinar el modelo. ¬øQu√© variables parecen ser significativas?\nObt√©n los coeficientes del modelo. ¬øC√≥mo interpretar√≠as el signo del coeficiente para la variable wt?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-4-interpretaci√≥n-odds-ratios",
    "href": "tema5_glm_soluciones.html#ejercicio-4-interpretaci√≥n-odds-ratios",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.4 Ejercicio 4: Interpretaci√≥n (Odds Ratios)",
    "text": "5.4 Ejercicio 4: Interpretaci√≥n (Odds Ratios)\nBasado en el modelo del ejercicio anterior:\n\nCalcula el Odds Ratio (OR) para el coeficiente de la variable hp.\nInterpreta este Odds Ratio en el contexto del problema. Espec√≠ficamente, ¬øc√≥mo cambian las ‚Äúodds‚Äù (la raz√≥n de probabilidad) de tener una transmisi√≥n manual por cada caballo de fuerza adicional, manteniendo el peso constante?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-5-pr√°ctico-validaci√≥n-del-modelo-log√≠stico",
    "href": "tema5_glm_soluciones.html#ejercicio-5-pr√°ctico-validaci√≥n-del-modelo-log√≠stico",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.5 Ejercicio 5: Pr√°ctico (Validaci√≥n del Modelo Log√≠stico)",
    "text": "5.5 Ejercicio 5: Pr√°ctico (Validaci√≥n del Modelo Log√≠stico)\nContinuando con el modelo log√≠stico de mtcars:\n\nGenera las predicciones de probabilidad del modelo para los datos.\nConvierte estas probabilidades en clases (‚Äú0‚Äù o ‚Äú1‚Äù) usando un umbral de decisi√≥n de 0.5.\nCrea la matriz de confusi√≥n comparando las predicciones con los valores reales.\nCalcula la precisi√≥n (accuracy) global del modelo.\n(Bonus) Utiliza el paquete pROC para calcular y visualizar la curva ROC y obtener el valor del AUC. ¬øQu√© tan buena es la capacidad discriminativa del modelo?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-6-conceptual-regresi√≥n-de-poisson",
    "href": "tema5_glm_soluciones.html#ejercicio-6-conceptual-regresi√≥n-de-poisson",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.6 Ejercicio 6: Conceptual (Regresi√≥n de Poisson)",
    "text": "5.6 Ejercicio 6: Conceptual (Regresi√≥n de Poisson)\n\n¬øQu√© tipo de variable respuesta est√° dise√±ada para modelar la regresi√≥n de Poisson?\n¬øCu√°l es el supuesto fundamental de la distribuci√≥n de Poisson respecto a la relaci√≥n entre la media y la varianza?\n¬øC√≥mo se llama el problema que surge cuando este supuesto se viola y la varianza es mayor que la media?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-7-pr√°ctico-ajuste-de-un-modelo-de-poisson",
    "href": "tema5_glm_soluciones.html#ejercicio-7-pr√°ctico-ajuste-de-un-modelo-de-poisson",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.7 Ejercicio 7: Pr√°ctico (Ajuste de un Modelo de Poisson)",
    "text": "5.7 Ejercicio 7: Pr√°ctico (Ajuste de un Modelo de Poisson)\nEl dataset discoveries de R es una serie temporal que cuenta el n√∫mero de ‚Äúgrandes inventos‚Äù por a√±o.\n\nCrea un gr√°fico de la serie temporal. ¬øParece la media del conteo constante a lo largo del tiempo?\nAjusta un modelo de regresi√≥n de Poisson simple donde discoveries es la respuesta y el tiempo (time(discoveries)) es el predictor.\nInterpreta el coeficiente del tiempo. (Pista: recuerda exponenciarlo para obtener el Incidence Rate Ratio - IRR).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-8-diagn√≥stico-sobredispersi√≥n",
    "href": "tema5_glm_soluciones.html#ejercicio-8-diagn√≥stico-sobredispersi√≥n",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.8 Ejercicio 8: Diagn√≥stico (Sobredispersi√≥n)",
    "text": "5.8 Ejercicio 8: Diagn√≥stico (Sobredispersi√≥n)\n\nPara el modelo de Poisson del ejercicio anterior, calcula el estad√≠stico de dispersi√≥n (\\(\\hat{\\phi}\\)). (Pista: \\(\\hat{\\phi} = \\frac{\\sum r_i^2}{n-p}\\), donde los \\(r_i\\) son los residuos Pearson).\nBas√°ndote en el valor de \\(\\hat{\\phi}\\), ¬øhay evidencia de sobredispersi√≥n?\nSi encuentras sobredispersi√≥n, ¬øcu√°l es el modelo alternativo que proponen los apuntes? ¬øQu√© ventaja te√≥rica ofrece este modelo alternativo?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-9-conceptual-deviance",
    "href": "tema5_glm_soluciones.html#ejercicio-9-conceptual-deviance",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.9 Ejercicio 9: Conceptual (Deviance)",
    "text": "5.9 Ejercicio 9: Conceptual (Deviance)\nLa deviance es la medida principal de bondad de ajuste en los GLM. Explica conceptualmente qu√© mide. ¬øC√≥mo se utiliza la diferencia en deviance entre dos modelos anidados para decidir cu√°l es mejor?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-10-elecci√≥n-del-modelo-adecuado",
    "href": "tema5_glm_soluciones.html#ejercicio-10-elecci√≥n-del-modelo-adecuado",
    "title": "5¬† Modelos de Regresi√≥n Generalizada",
    "section": "5.10 Ejercicio 10: Elecci√≥n del Modelo Adecuado",
    "text": "5.10 Ejercicio 10: Elecci√≥n del Modelo Adecuado\nPara cada uno de los siguientes escenarios, indica qu√© tipo de GLM (Log√≠stico, Poisson, Binomial Negativo, Gamma‚Ä¶) ser√≠a el m√°s apropiado y por qu√©.\n\nQuieres modelar el tiempo (en minutos) que tarda un cliente en resolver una consulta en un centro de atenci√≥n telef√≥nica. El tiempo es siempre positivo y muchos valores se agrupan en tiempos cortos, con una cola larga de tiempos muy largos.\nQuieres predecir la presencia o ausencia de una especie de planta en diferentes parcelas de un bosque.\nQuieres modelar el n√∫mero de visitas que cada usuario hace a una p√°gina web en un mes. Observas que la varianza del n√∫mero de visitas es mucho mayor que la media.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>**Modelos de Regresi√≥n Generalizada**</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html",
    "href": "ejercicios_avanzados_soluciones.html",
    "title": "6¬† Ejercicios: Popurr√≠",
    "section": "",
    "text": "6.0.1 Ejercicio 1: Derivaci√≥n de Estimadores\nEnunciado: Considera el modelo de regresi√≥n lineal simple \\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\). Partiendo de la funci√≥n objetivo de M√≠nimos Cuadrados Ordinarios (MCO), \\(S(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\\), realiza la derivaci√≥n matem√°tica completa para obtener las expresiones de los estimadores \\(\\hat{\\beta}_0\\) y \\(\\hat{\\beta}_1\\).\nSoluci√≥n:\nEl objetivo es encontrar los valores de \\(\\beta_0\\) y \\(\\beta_1\\) que minimizan la Suma de Cuadrados del Error (SSE). Para ello, calculamos las derivadas parciales de la funci√≥n \\(S(\\beta_0, \\beta_1)\\) con respecto a cada par√°metro y las igualamos a cero.\n\nDerivada parcial con respecto a \\(\\beta_0\\): \\[\n\\frac{\\partial S}{\\partial \\beta_0} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-1) = -2 \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)\n\\] Igualando a cero y dividiendo por -2: \\[\n\\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum y_i - n\\hat{\\beta}_0 - \\hat{\\beta}_1 \\sum x_i = 0\n\\] Reordenando, obtenemos la primera ecuaci√≥n normal: \\[\nn\\hat{\\beta}_0 + \\hat{\\beta}_1 \\sum x_i = \\sum y_i \\quad \\text{(1)}\n\\]\nDerivada parcial con respecto a \\(\\beta_1\\): \\[\n\\frac{\\partial S}{\\partial \\beta_1} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-x_i) = -2 \\sum_{i=1}^{n} x_i(y_i - \\beta_0 - \\beta_1 x_i)\n\\] Igualando a cero y dividiendo por -2: \\[\n\\sum_{i=1}^{n} x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum x_iy_i - \\hat{\\beta}_0 \\sum x_i - \\hat{\\beta}_1 \\sum x_i^2 = 0\n\\] Reordenando, obtenemos la segunda ecuaci√≥n normal: \\[\n\\hat{\\beta}_0 \\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i \\quad \\text{(2)}\n\\]\nResoluci√≥n del sistema: De la ecuaci√≥n (1), dividiendo por \\(n\\), podemos despejar \\(\\hat{\\beta}_0\\): \\[\n\\hat{\\beta}_0 + \\hat{\\beta}_1 \\bar{x} = \\bar{y} \\implies \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\] Esta es la f√≥rmula para el intercepto, que depende de la pendiente.\nSustituimos esta expresi√≥n de \\(\\hat{\\beta}_0\\) en la ecuaci√≥n (2): \\[\n(\\bar{y} - \\hat{\\beta}_1 \\bar{x})\\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i\n\\] \\[\n\\bar{y}\\sum x_i - \\hat{\\beta}_1 \\bar{x}\\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i\n\\] Agrupamos los t√©rminos con \\(\\hat{\\beta}_1\\): \\[\n\\hat{\\beta}_1 (\\sum x_i^2 - \\bar{x}\\sum x_i) = \\sum x_iy_i - \\bar{y}\\sum x_i\n\\] Sabiendo que \\(\\sum x_i = n\\bar{x}\\) y \\(\\sum y_i = n\\bar{y}\\): \\[\n\\hat{\\beta}_1 (\\sum x_i^2 - n\\bar{x}^2) = \\sum x_iy_i - n\\bar{x}\\bar{y}\n\\] Las expresiones entre par√©ntesis son las f√≥rmulas de la suma de cuadrados de X (\\(S_{xx}\\)) y la suma de productos cruzados de X e Y (\\(S_{xy}\\)): \\[\n\\hat{\\beta}_1 S_{xx} = S_{xy}\n\\] Finalmente, despejamos el estimador de la pendiente: \\[\n\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\] Estas son las expresiones para los estimadores de MCO.\n\n\n\n\n6.0.2 Ejercicio 2: El Impacto de la Multicolinealidad\nEnunciado: En un modelo de regresi√≥n m√∫ltiple con dos predictores estandarizados (\\(X_1, X_2\\)), la varianza del estimador \\(\\hat{\\beta}_1\\) viene dada por \\(\\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{n(1-r_{12}^2)}\\), donde \\(r_{12}\\) es la correlaci√≥n entre \\(X_1\\) y \\(X_2\\). a) Explica matem√°ticamente qu√© le ocurre a la varianza de \\(\\hat{\\beta}_1\\) cuando la correlaci√≥n (\\(r_{12}\\)) se aproxima a 1. b) Relaciona esta f√≥rmula con la del VIF.\nSoluci√≥n:\n\na) Efecto de la correlaci√≥n en la varianza: La varianza del estimador, \\(\\text{Var}(\\hat{\\beta}_1)\\), es una medida de su imprecisi√≥n. La f√≥rmula \\(\\frac{\\sigma^2}{n(1-r_{12}^2)}\\) muestra que la varianza depende inversamente del t√©rmino \\((1-r_{12}^2)\\).\n\nSi \\(r_{12} = 0\\) (no hay correlaci√≥n), la varianza es m√≠nima: \\(\\text{Var}(\\hat{\\beta}_1) = \\sigma^2/n\\).\nA medida que la correlaci√≥n \\(|r_{12}|\\) aumenta y se acerca a 1 (multicolinealidad perfecta), el t√©rmino \\(r_{12}^2\\) tambi√©n se acerca a 1.\nConsecuentemente, el denominador \\((1-r_{12}^2)\\) se aproxima a 0.\nMatem√°ticamente, cuando el denominador de una fracci√≥n tiende a cero, el valor de la fracci√≥n tiende a infinito. Por lo tanto: \\[\n\\lim_{|r_{12}| \\to 1} \\text{Var}(\\hat{\\beta}_1) = \\lim_{|r_{12}| \\to 1} \\frac{\\sigma^2}{n(1-r_{12}^2)} = \\infty\n\\] Esto significa que con multicolinealidad severa, la varianza de los estimadores de los coeficientes ‚Äúexplota‚Äù, volvi√©ndolos extremadamente inestables y poco fiables.\n\nb) Relaci√≥n con el Factor de Inflaci√≥n de la Varianza (VIF): El VIF para un predictor \\(X_j\\) se define como \\(VIF_j = \\frac{1}{1 - R_j^2}\\), donde \\(R_j^2\\) es el R-cuadrado de la regresi√≥n de \\(X_j\\) sobre todos los dem√°s predictores. En el caso de solo dos predictores (\\(X_1, X_2\\)), el \\(R^2\\) de la regresi√≥n de \\(X_1\\) sobre \\(X_2\\) es simplemente el cuadrado de su coeficiente de correlaci√≥n, es decir, \\(R_1^2 = r_{12}^2\\). Sustituyendo esto en la f√≥rmula del VIF, tenemos: \\[\nVIF_1 = \\frac{1}{1 - r_{12}^2}\n\\] Ahora podemos reescribir la f√≥rmula de la varianza de \\(\\hat{\\beta}_1\\) usando el VIF: \\[\n\\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{n} \\cdot \\frac{1}{1-r_{12}^2} = \\frac{\\sigma^2}{n} \\cdot VIF_1\n\\] Esta expresi√≥n demuestra que el VIF es, literalmente, el factor multiplicativo por el cual la varianza del estimador del coeficiente se ‚Äúinfla‚Äù en comparaci√≥n con el caso base en el que no habr√≠a correlaci√≥n (donde VIF = 1).\n\n\n\n\n6.0.3 Ejercicio 3: Interpretaci√≥n de Coeficientes en Modelos Transformados\nEnunciado: Considera un modelo de regresi√≥n log-log: \\(\\log(Y_i) = \\beta_0 + \\beta_1 \\log(X_i) + \\varepsilon_i\\). Demuestra matem√°ticamente que el coeficiente \\(\\beta_1\\) puede interpretarse como una elasticidad.\nSoluci√≥n:\nLa elasticidad de Y con respecto a X se define como el cambio porcentual en Y para un cambio del 1% en X. Para cambios infinitesimales, esta se expresa como: \\[\\eta = \\frac{\\% \\Delta Y}{\\% \\Delta X} = \\frac{dY/Y}{dX/X}\\] Una propiedad matem√°tica de los logaritmos es que para cambios peque√±os, \\(d(\\log(z)) \\approx \\frac{dz}{z}\\), que representa un cambio relativo o porcentual. Por lo tanto, la elasticidad puede expresarse como la derivada del logaritmo de Y con respecto al logaritmo de X: \\[\\eta = \\frac{d(\\log Y)}{d(\\log X)}\\] Partiendo de nuestro modelo poblacional (ignorando el t√©rmino de error para analizar la relaci√≥n sistem√°tica): \\[\\log(Y) = \\beta_0 + \\beta_1 \\log(X)\\] Ahora, simplemente calculamos la derivada de la ecuaci√≥n con respecto a \\(\\log(X)\\): \\[\\frac{d(\\log Y)}{d(\\log X)} = \\frac{d}{d(\\log X)} (\\beta_0 + \\beta_1 \\log(X))\\] El t√©rmino \\(\\beta_0\\) es una constante, por lo que su derivada es 0. El t√©rmino \\(\\beta_1 \\log(X)\\) tiene una derivada de \\(\\beta_1\\) con respecto a \\(\\log(X)\\). Por lo tanto: \\[\\frac{d(\\log Y)}{d(\\log X)} = \\beta_1\\] Hemos demostrado que el coeficiente \\(\\beta_1\\) es igual a la elasticidad de Y con respecto a X. As√≠, \\(\\beta_1\\) representa el cambio porcentual promedio en Y que se asocia con un aumento del 1% en X.\n\n\n\n6.0.4 Ejercicio 4: Fundamentos de la Regularizaci√≥n\nEnunciado: Explica desde una perspectiva geom√©trica por qu√© la regularizaci√≥n Lasso (L1) puede anular coeficientes, mientras que Ridge (L2) solo los encoge.\nSoluci√≥n:\nLa estimaci√≥n en regresi√≥n regularizada puede entenderse como un problema de optimizaci√≥n restringida. El objetivo es encontrar el conjunto de coeficientes (\\(\\beta_1, \\beta_2, \\dots\\)) que minimice la Suma de Cuadrados del Error (SSE), sujeto a una restricci√≥n en el tama√±o de dichos coeficientes.\n\nGeometr√≠a del problema: El conjunto de todos los posibles valores de los coeficientes para un mismo valor de SSE forma una elipse (en un espacio de dos coeficientes, \\(\\beta_1, \\beta_2\\)) centrada en la soluci√≥n de M√≠nimos Cuadrados Ordinarios (MCO). El objetivo es encontrar la elipse m√°s peque√±a posible que toque la ‚Äúregi√≥n de restricci√≥n‚Äù.\nRegresi√≥n Ridge (Penalizaci√≥n L2): La restricci√≥n es \\(\\sum \\beta_j^2 \\leq s\\). En dos dimensiones, \\(\\beta_1^2 + \\beta_2^2 \\leq s\\) es la ecuaci√≥n de un c√≠rculo. Esta regi√≥n es convexa y no tiene ‚Äúesquinas‚Äù. Cuando las elipses del SSE se expanden desde el punto MCO, el primer punto de contacto con el c√≠rculo ser√° un punto de tangencia. Debido a la forma suave y redondeada del c√≠rculo, es extremadamente improbable que este punto de tangencia ocurra exactamente sobre un eje (donde uno de los coeficientes ser√≠a cero). Por lo tanto, Ridge reduce la magnitud de ambos coeficientes, pero no los anula.\nRegresi√≥n Lasso (Penalizaci√≥n L1): La restricci√≥n es \\(\\sum |\\beta_j| \\leq s\\). En dos dimensiones, \\(|\\beta_1| + |\\beta_2| \\leq s\\) es la ecuaci√≥n de un rombo (o diamante), rotado 45 grados. La caracter√≠stica clave de esta regi√≥n son sus v√©rtices afilados, que se encuentran sobre los ejes. Cuando las elipses del SSE se expanden, es mucho m√°s probable que toquen la regi√≥n de restricci√≥n en uno de estos v√©rtices que en una de las aristas. Si el punto de contacto es un v√©rtice sobre un eje (por ejemplo, el punto (0, \\(\\beta_2\\))), significa que el otro coeficiente (\\(\\beta_1\\)) es exactamente cero. Es esta propiedad geom√©trica, las ‚Äúesquinas‚Äù de la regi√≥n de penalizaci√≥n L1, lo que induce la escasez (sparsity) y permite a Lasso realizar selecci√≥n de variables.\n\n\n\n\n6.0.5 Ejercicio 5: La Familia Exponencial y los GLM\nEnunciado: Explica cu√°l es la funci√≥n de varianza \\(V(\\mu)\\) para un modelo de Poisson y para un modelo Binomial, y qu√© implicaciones tiene sobre los supuestos del modelo.\nSoluci√≥n:\nLa funci√≥n de varianza \\(V(\\mu)\\) es la ‚Äúfirma‚Äù de cada distribuci√≥n dentro de la familia exponencial, ya que define la relaci√≥n te√≥rica entre la media \\(\\mu\\) y la varianza de la variable respuesta.\n\nModelo de Poisson:\n\nFunci√≥n de Varianza: \\(V(\\mu) = \\mu\\).\nImplicaci√≥n: Esto implica que la varianza de la variable respuesta es te√≥ricamente igual a su media: \\(\\text{Var}(Y) = \\mu\\). Este supuesto se conoce como equidispersi√≥n. La implicaci√≥n m√°s importante para el modelado es que, si los datos reales muestran una varianza significativamente mayor que la media (un fen√≥meno muy com√∫n llamado sobredispersi√≥n), el modelo de Poisson ser√° inadecuado. Los errores est√°ndar de los coeficientes estar√°n subestimados, llevando a p-valores incorrectamente bajos y a una inferencia err√≥nea.\n\nModelo Binomial:\n\nFunci√≥n de Varianza: \\(V(\\mu) = \\mu(1-\\mu)\\).\nImplicaci√≥n: En este caso, la varianza no es constante, sino que es una funci√≥n cuadr√°tica de la media (la probabilidad de √©xito). La varianza es m√≠nima cuando \\(\\mu\\) se acerca a 0 o 1, y es m√°xima cuando \\(\\mu = 0.5\\). Esta es la heterocedasticidad inherente a los datos de proporciones. El modelo GLM maneja esto de forma natural a trav√©s del algoritmo de estimaci√≥n (IRLS), que da m√°s peso a las observaciones con menor varianza (aquellas con probabilidades predichas cercanas a 0 o 1) y menos peso a las m√°s inciertas (aquellas con probabilidades cercanas a 0.5).\n\n\n\n\n\n6.0.6 Ejercicio 6: El Problema de la Inferencia en M√©todos Stepwise\nEnunciado: Explica el razonamiento estad√≠stico detr√°s de la advertencia de que los p-valores de un modelo final obtenido mediante selecci√≥n por pasos (stepwise) est√°n sesgados y son excesivamente optimistas.\nSoluci√≥n:\nLa advertencia se debe a que los m√©todos stepwise violan un principio fundamental de la prueba de hip√≥tesis: el modelo y las hip√≥tesis deben ser especificados a priori, antes de examinar las relaciones en los datos. Los m√©todos stepwise hacen exactamente lo contrario.\n\nProblema de M√∫ltiples Comparaciones: En cada paso, un algoritmo como la selecci√≥n forward realiza m√∫ltiples tests (un test t para cada variable candidata a entrar) y selecciona la variable ‚Äúganadora‚Äù, que es la que tiene el p-valor m√°s peque√±o. Al elegir el valor m√≠nimo de un conjunto de pruebas, estamos seleccionando un valor extremo de la distribuci√≥n de p-valores bajo la hip√≥tesis nula. El p-valor reportado para esa variable (p.¬†ej., 0.03) no refleja la probabilidad de observar un resultado tan extremo en un solo intento, sino la probabilidad de que el mejor de varios intentos sea tan extremo, lo cual es una probabilidad mucho mayor.\nInvalidez de la Distribuci√≥n Te√≥rica: El p-valor de un test t se calcula asumiendo que el coeficiente sigue una distribuci√≥n t de Student. Sin embargo, el coeficiente de una variable seleccionada por un algoritmo stepwise no sigue esta distribuci√≥n. Sigue una distribuci√≥n m√°s compleja (una ‚Äúdistribuci√≥n de un estad√≠stico de orden‚Äù), porque ha sido seleccionado condicionalmente por ser el mejor.\nSesgo de Selecci√≥n: El proceso est√° dise√±ado para encontrar relaciones, incluso en datos puramente aleatorios. Si tenemos muchas variables de ruido, la probabilidad de que una de ellas parezca significativa por puro azar es alta. El m√©todo stepwise seleccionar√° esa variable y reportar√° un p-valor bajo y enga√±oso.\n\nEn resumen, los p-valores de un modelo stepwise est√°n sesgados a la baja (son demasiado peque√±os) porque no tienen en cuenta el proceso de b√∫squeda y selecci√≥n que los ha producido. Esto lleva a una inflaci√≥n de la tasa de error de Tipo I, haciendo que concluyamos que ciertas variables son significativas cuando en realidad no lo son.\n\n\n\n6.0.7 Ejercicio 7: Propiedades de los Estimadores MCO\nEnunciado: Demuestra la propiedad de insesgadez para el estimador \\(\\hat{\\boldsymbol{\\beta}}\\) en notaci√≥n matricial. Es decir, demuestra que \\(E[\\hat{\\boldsymbol{\\beta}}] = \\boldsymbol{\\beta}\\).\nSoluci√≥n:\n\nComenzamos con la f√≥rmula del estimador MCO en notaci√≥n matricial: \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n\\]\nSustituimos el modelo poblacional verdadero para el vector \\(\\mathbf{y}\\), que es \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\): \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon})\n\\]\nAplicamos el operador de valor esperado \\(E[\\cdot]\\) a ambos lados. Tratamos la matriz de dise√±o \\(\\mathbf{X}\\) como fija (no aleatoria): \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon})]\n\\]\nDistribuimos el t√©rmino \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\) dentro del par√©ntesis: \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\varepsilon}]\n\\]\nUsamos la propiedad de linealidad del valor esperado (\\(E[A+B] = E[A] + E[B]\\)): \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\varepsilon}]\n\\]\nAnalizamos cada t√©rmino por separado:\n\nEn el primer t√©rmino, todo es constante excepto el operador de valor esperado, y \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\) es la matriz identidad \\(\\mathbf{I}\\). Por lo tanto, \\(E[\\mathbf{I}\\boldsymbol{\\beta}] = \\boldsymbol{\\beta}\\).\nEn el segundo t√©rmino, podemos sacar las constantes del valor esperado: \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T E[\\boldsymbol{\\varepsilon}]\\).\n\nAplicamos el supuesto de exogeneidad (o media del error nula), que establece que el valor esperado del t√©rmino de error es cero: \\(E[\\boldsymbol{\\varepsilon}] = \\mathbf{0}\\). \\[\n(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T E[\\boldsymbol{\\varepsilon}] = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{0} = \\mathbf{0}\n\\]\nUniendo los resultados, concluimos: \\[\nE[\\hat{\\boldsymbol{\\beta}}] = \\boldsymbol{\\beta} + \\mathbf{0} = \\boldsymbol{\\beta}\n\\] Esto demuestra que el estimador MCO \\(\\hat{\\boldsymbol{\\beta}}\\) es insesgado, ya que su valor esperado es el verdadero par√°metro poblacional \\(\\boldsymbol{\\beta}\\).\n\n\n\n\n6.0.8 Ejercicio 8: Intervalos de Confianza vs.¬†Predicci√≥n\nEnunciado: La f√≥rmula para el intervalo de predicci√≥n en RLS es \\(\\hat{y}_0 \\pm t_{\\alpha/2, n-2} \\cdot \\sqrt{\\text{MSE} \\left( 1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{S_{xx}} \\right)}\\). Explica el origen y el significado de cada uno de los tres t√©rminos dentro del par√©ntesis.\nSoluci√≥n:\nLa f√≥rmula cuantifica la incertidumbre total de predecir una √∫nica nueva observaci√≥n. Esta incertidumbre proviene de dos fuentes: la incertidumbre sobre la posici√≥n de la verdadera l√≠nea de regresi√≥n y la variabilidad inherente de un punto individual alrededor de esa l√≠nea. Los tres t√©rminos dentro del par√©ntesis representan estas fuentes de varianza (escaladas por MSE, que estima \\(\\sigma^2\\)):\n\nT√©rmino 1: Esta es la componente m√°s importante y la que distingue al intervalo de predicci√≥n. Representa la varianza del error aleatorio de la nueva observaci√≥n, \\(\\text{Var}(\\varepsilon_0) = \\sigma^2\\). Es la incertidumbre irreducible o inherente de un solo punto, que siempre se desviar√° de la media. Esta es la raz√≥n principal por la que un intervalo de predicci√≥n es siempre m√°s ancho que uno de confianza.\nT√©rmino 1/n: Esta componente est√° relacionada con la incertidumbre en la estimaci√≥n del intercepto \\(\\hat{\\beta}_0\\). Representa la incertidumbre sobre la ‚Äúaltura‚Äù general de la l√≠nea de regresi√≥n. A medida que el tama√±o de la muestra (\\(n\\)) aumenta, nuestra confianza en la posici√≥n de la l√≠nea mejora, y este t√©rmino de incertidumbre se hace m√°s peque√±o.\nT√©rmino (x_0 - \\bar{x})^2 / S_{xx}: Esta componente representa la incertidumbre debida a la estimaci√≥n de la pendiente \\(\\hat{\\beta}_1\\). La incertidumbre en la pendiente tiene un mayor impacto cuanto m√°s nos alejamos del centro de los datos (\\(\\bar{x}\\)). Si predecimos en el punto medio de nuestros datos (\\(x_0 = \\bar{x}\\)), este t√©rmino se anula. A medida que \\(x_0\\) se aleja de \\(\\bar{x}\\), el efecto de un peque√±o error en la estimaci√≥n de la pendiente se magnifica, ensanchando el intervalo.\n\nEn resumen, los t√©rminos 1/n y (x_0 - \\bar{x})^2 / S_{xx} juntos cuantifican la incertidumbre sobre d√≥nde est√° la l√≠nea de regresi√≥n verdadera (lo que cubre el intervalo de confianza). El t√©rmino 1 a√±ade la incertidumbre de un nuevo punto individual alrededor de esa l√≠nea.\n\n\n\n6.0.9 Ejercicio 9: Estimaci√≥n por M√°xima Verosimilitud\nEnunciado: Para un modelo de regresi√≥n log√≠stica, deriva la ecuaci√≥n de puntuaci√≥n para un coeficiente \\(\\beta_j\\) y demuestra que se iguala a cero cuando \\(\\sum_{i=1}^{n} x_{ij}(y_i - p_i) = 0\\).\nSoluci√≥n:\n\nLa funci√≥n de log-verosimilitud para la regresi√≥n log√≠stica es: \\[\n\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} \\left[y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} - \\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\right]\n\\]\nLa ecuaci√≥n de puntuaci√≥n (score equation) se obtiene al calcular la primera derivada de la log-verosimilitud con respecto a un par√°metro, en este caso \\(\\beta_j\\). Debemos calcular \\(\\frac{\\partial \\ell}{\\partial \\beta_j}\\) y igualarla a cero.\nLa derivada de una suma es la suma de las derivadas, por lo que podemos analizar el t√©rmino dentro del sumatorio para una observaci√≥n \\(i\\): \\[\n\\frac{\\partial}{\\partial \\beta_j} \\left[y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} - \\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\right]\n\\]\nLa derivada del primer t√©rmino, \\(y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} = y_i(\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_jx_{ij} + \\dots)\\), con respecto a \\(\\beta_j\\) es simplemente \\(y_i x_{ij}\\).\nLa derivada del segundo t√©rmino, \\(\\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\), requiere la regla de la cadena. Sea \\(u = 1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}\\). \\[\n\\frac{\\partial}{\\partial \\beta_j} \\log(u) = \\frac{1}{u} \\cdot \\frac{\\partial u}{\\partial \\beta_j} = \\frac{1}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}} \\cdot \\frac{\\partial}{\\partial \\beta_j} (1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\n\\] \\[\n= \\frac{1}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}} \\cdot (e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}} \\cdot x_{ij}) = \\left(\\frac{e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}}\\right) x_{ij}\n\\]\nReconocemos que el t√©rmino entre par√©ntesis es la definici√≥n de la probabilidad \\(p_i\\) en el modelo log√≠stico (\\(p_i = \\frac{1}{1+e^{-\\mathbf{x}_i^T\\boldsymbol{\\beta}}}\\)). Por lo tanto, la derivada del segundo t√©rmino es \\(p_i x_{ij}\\).\nUniendo ambos resultados, la derivada para la observaci√≥n \\(i\\) es \\(y_i x_{ij} - p_i x_{ij}\\).\nLa ecuaci√≥n de puntuaci√≥n completa es la suma sobre todas las observaciones: \\[\n\\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{i=1}^{n} (y_i x_{ij} - p_i x_{ij}) = \\sum_{i=1}^{n} x_{ij}(y_i - p_i)\n\\]\nLos estimadores de m√°xima verosimilitud se encuentran al igualar esta ecuaci√≥n a cero: \\[\n\\sum_{i=1}^{n} x_{ij}(y_i - p_i) = 0\n\\]\n\nInterpretaci√≥n: Esta condici√≥n final significa que los estimadores de m√°xima verosimilitud se encuentran cuando los residuos del modelo (\\(y_i - p_i\\), la diferencia entre lo observado y la probabilidad predicha) son ortogonales (no est√°n correlacionados) a los predictores \\(x_{ij}\\). Esto es an√°logo a las ecuaciones normales de MCO y significa que el modelo ha extra√≠do toda la informaci√≥n linealmente asociable a los predictores, no quedando ning√∫n patr√≥n relacionado con ellos en los errores.\n\n\n\n6.0.10 Ejercicio 10: El Coeficiente de Regresi√≥n Parcial\nEnunciado: Explica el concepto de regresi√≥n parcial y su relaci√≥n con el coeficiente de regresi√≥n m√∫ltiple \\(\\hat{\\beta}_j\\).\nSoluci√≥n:\nEl concepto de regresi√≥n parcial es fundamental para entender la interpretaci√≥n ceteris paribus de un coeficiente en regresi√≥n m√∫ltiple. Afirma que el coeficiente \\(\\hat{\\beta}_j\\) del predictor \\(X_j\\) en un modelo m√∫ltiple es matem√°ticamente id√©ntico a la pendiente de una regresi√≥n simple entre dos conjuntos de residuos.\nEl proceso de ‚Äúparcializaci√≥n‚Äù consiste en eliminar la influencia de todos los dem√°s predictores (denotados como \\(X_{-j}\\)) tanto de la variable respuesta \\(Y\\) como del predictor de inter√©s \\(X_j\\).\n\nParcializaci√≥n de Y: Se ajusta un modelo de regresi√≥n de \\(Y\\) en funci√≥n de todos los dem√°s predictores: \\(Y \\sim X_{-j}\\). Los residuos de este modelo, \\(e_{Y|X_{-j}}\\), representan la parte de la variabilidad de \\(Y\\) que no puede ser explicada por el resto de variables del modelo. Es la ‚Äúinformaci√≥n √∫nica‚Äù de Y.\nParcializaci√≥n de \\(X_j\\): Se ajusta un modelo de regresi√≥n de \\(X_j\\) en funci√≥n de todos los dem√°s predictores: \\(X_j \\sim X_{-j}\\). Los residuos de este modelo, \\(e_{X_j|X_{-j}}\\), representan la parte de la variabilidad de \\(X_j\\) que es √∫nica y no est√° correlacionada con el resto de variables. Es la ‚Äúinformaci√≥n √∫nica‚Äù que \\(X_j\\) aporta.\nRelaci√≥n entre los residuos: Si ahora ajustamos una regresi√≥n lineal simple entre estos dos conjuntos de residuos: \\[\ne_{Y|X_{-j}} \\sim e_{X_j|X_{-j}}\n\\] La pendiente de esta regresi√≥n simple es exactamente igual al coeficiente de regresi√≥n m√∫ltiple \\(\\hat{\\beta}_j\\) del modelo original completo.\n\nConclusi√≥n: Esto demuestra que \\(\\hat{\\beta}_j\\) no mide la relaci√≥n ‚Äúbruta‚Äù entre Y y \\(X_j\\), sino la relaci√≥n entre la parte de Y que no es explicada por los otros predictores y la parte de \\(X_j\\) que es √∫nica. Es la asociaci√≥n ‚Äúlimpia‚Äù entre Y y \\(X_j\\) despu√©s de haber controlado estad√≠sticamente por la influencia de todas las dem√°s variables en el modelo. Esto es, precisamente, la formalizaci√≥n matem√°tica del principio ceteris paribus.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Ejercicios: Popurr√≠</span>"
    ]
  }
]