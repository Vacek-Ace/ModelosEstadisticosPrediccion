<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es-ES" xml:lang="es-ES"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.21">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Modelos de regresión generalizada – Modelos Estadísticos para la Predicción</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./conclusiones.html" rel="next">
<link href="./tema4.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea1d7ac60288e0f1efdbc993fd8432ae.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-0687a6949ae11671cfb8b930681aab34.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No se han encontrado resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="estilos_html.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./tema5.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modelos Estadísticos para la Predicción</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción a los modelos de regresión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal simple</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal múltiple</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ingeniería de características: transformaciones de variables e interacciones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables, regularización y validación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema5.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografía</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#introducción-a-los-glm" id="toc-introducción-a-los-glm" class="nav-link active" data-scroll-target="#introducción-a-los-glm"><span class="header-section-number">6.1</span> Introducción a los GLM</a>
  <ul class="collapse">
  <li><a href="#qué-son-los-modelos-lineales-generalizados" id="toc-qué-son-los-modelos-lineales-generalizados" class="nav-link" data-scroll-target="#qué-son-los-modelos-lineales-generalizados"><span class="header-section-number">6.1.1</span> ¿Qué son los modelos lineales generalizados?</a></li>
  <li><a href="#componentes-de-un-modelo-lineal-generalizado" id="toc-componentes-de-un-modelo-lineal-generalizado" class="nav-link" data-scroll-target="#componentes-de-un-modelo-lineal-generalizado"><span class="header-section-number">6.1.2</span> Componentes de un modelo lineal generalizado</a></li>
  <li><a href="#diferencias-clave-entre-la-regresión-lineal-y-los-glm" id="toc-diferencias-clave-entre-la-regresión-lineal-y-los-glm" class="nav-link" data-scroll-target="#diferencias-clave-entre-la-regresión-lineal-y-los-glm"><span class="header-section-number">6.1.3</span> Diferencias clave entre la regresión lineal y los GLM</a></li>
  </ul></li>
  <li><a href="#estimación-de-parámetros-en-glm" id="toc-estimación-de-parámetros-en-glm" class="nav-link" data-scroll-target="#estimación-de-parámetros-en-glm"><span class="header-section-number">6.2</span> Estimación de parámetros en GLM</a>
  <ul class="collapse">
  <li><a href="#método-de-máxima-verosimilitud" id="toc-método-de-máxima-verosimilitud" class="nav-link" data-scroll-target="#método-de-máxima-verosimilitud"><span class="header-section-number">6.2.1</span> Método de máxima verosimilitud</a></li>
  </ul></li>
  <li><a href="#bondad-de-ajuste-en-glms" id="toc-bondad-de-ajuste-en-glms" class="nav-link" data-scroll-target="#bondad-de-ajuste-en-glms"><span class="header-section-number">6.3</span> Bondad de ajuste en GLMs</a>
  <ul class="collapse">
  <li><a href="#la-deviance-como-medida-de-bondad-de-ajuste" id="toc-la-deviance-como-medida-de-bondad-de-ajuste" class="nav-link" data-scroll-target="#la-deviance-como-medida-de-bondad-de-ajuste"><span class="header-section-number">6.3.1</span> La deviance como medida de bondad de ajuste</a></li>
  <li><a href="#test-de-la-razón-de-verosimilitudes" id="toc-test-de-la-razón-de-verosimilitudes" class="nav-link" data-scroll-target="#test-de-la-razón-de-verosimilitudes"><span class="header-section-number">6.3.2</span> Test de la razón de verosimilitudes</a></li>
  </ul></li>
  <li><a href="#diagnosis-de-glms" id="toc-diagnosis-de-glms" class="nav-link" data-scroll-target="#diagnosis-de-glms"><span class="header-section-number">6.4</span> Diagnosis de GLMs</a>
  <ul class="collapse">
  <li><a href="#tipos-de-residuos-en-glms" id="toc-tipos-de-residuos-en-glms" class="nav-link" data-scroll-target="#tipos-de-residuos-en-glms"><span class="header-section-number">6.4.1</span> Tipos de Residuos en GLMs</a></li>
  <li><a href="#la-forma-del-modelo-es-correcta-linealidad-y-enlace" id="toc-la-forma-del-modelo-es-correcta-linealidad-y-enlace" class="nav-link" data-scroll-target="#la-forma-del-modelo-es-correcta-linealidad-y-enlace"><span class="header-section-number">6.4.2</span> ¿La forma del modelo es correcta? (Linealidad y Enlace)</a></li>
  <li><a href="#la-distribución-que-elegimos-es-la-correcta-varianza-y-normalidad" id="toc-la-distribución-que-elegimos-es-la-correcta-varianza-y-normalidad" class="nav-link" data-scroll-target="#la-distribución-que-elegimos-es-la-correcta-varianza-y-normalidad"><span class="header-section-number">6.4.3</span> ¿La distribución que elegimos es la correcta? (Varianza y Normalidad)</a></li>
  <li><a href="#hay-observaciones-que-distorsionan-el-modelo-atípicos-e-influyentes" id="toc-hay-observaciones-que-distorsionan-el-modelo-atípicos-e-influyentes" class="nav-link" data-scroll-target="#hay-observaciones-que-distorsionan-el-modelo-atípicos-e-influyentes"><span class="header-section-number">6.4.4</span> ¿Hay observaciones que distorsionan el modelo? (Atípicos e Influyentes)</a></li>
  </ul></li>
  <li><a href="#regresión-logística" id="toc-regresión-logística" class="nav-link" data-scroll-target="#regresión-logística"><span class="header-section-number">6.5</span> Regresión logística</a>
  <ul class="collapse">
  <li><a href="#fundamentos-de-la-regresión-logística" id="toc-fundamentos-de-la-regresión-logística" class="nav-link" data-scroll-target="#fundamentos-de-la-regresión-logística"><span class="header-section-number">6.5.1</span> Fundamentos de la regresión logística</a></li>
  <li><a href="#estimación-por-máxima-verosimilitud-en-regresión-logística" id="toc-estimación-por-máxima-verosimilitud-en-regresión-logística" class="nav-link" data-scroll-target="#estimación-por-máxima-verosimilitud-en-regresión-logística"><span class="header-section-number">6.5.2</span> Estimación por máxima verosimilitud en regresión logística</a></li>
  <li><a href="#interpretación-de-coeficientes-y-odds-ratios" id="toc-interpretación-de-coeficientes-y-odds-ratios" class="nav-link" data-scroll-target="#interpretación-de-coeficientes-y-odds-ratios"><span class="header-section-number">6.5.3</span> Interpretación de coeficientes y odds ratios</a></li>
  <li><a href="#bondad-de-ajuste-del-modelo-logístico" id="toc-bondad-de-ajuste-del-modelo-logístico" class="nav-link" data-scroll-target="#bondad-de-ajuste-del-modelo-logístico"><span class="header-section-number">6.5.4</span> Bondad de ajuste del modelo logístico</a></li>
  <li><a href="#validación-del-modelo-logístico" id="toc-validación-del-modelo-logístico" class="nav-link" data-scroll-target="#validación-del-modelo-logístico"><span class="header-section-number">6.5.5</span> Validación del modelo logístico</a></li>
  </ul></li>
  <li><a href="#regresión-de-poisson" id="toc-regresión-de-poisson" class="nav-link" data-scroll-target="#regresión-de-poisson"><span class="header-section-number">6.6</span> Regresión de Poisson</a>
  <ul class="collapse">
  <li><a href="#modelo-de-regresión-de-poisson" id="toc-modelo-de-regresión-de-poisson" class="nav-link" data-scroll-target="#modelo-de-regresión-de-poisson"><span class="header-section-number">6.6.1</span> Modelo de regresión de Poisson</a></li>
  <li><a href="#supuestos-y-limitaciones-de-la-regresión-de-poisson" id="toc-supuestos-y-limitaciones-de-la-regresión-de-poisson" class="nav-link" data-scroll-target="#supuestos-y-limitaciones-de-la-regresión-de-poisson"><span class="header-section-number">6.6.2</span> Supuestos y limitaciones de la regresión de Poisson</a></li>
  <li><a href="#interpretación-de-los-resultados" id="toc-interpretación-de-los-resultados" class="nav-link" data-scroll-target="#interpretación-de-los-resultados"><span class="header-section-number">6.6.3</span> Interpretación de los resultados</a></li>
  <li><a href="#estimación-por-máxima-verosimilitud-en-regresión-de-poisson" id="toc-estimación-por-máxima-verosimilitud-en-regresión-de-poisson" class="nav-link" data-scroll-target="#estimación-por-máxima-verosimilitud-en-regresión-de-poisson"><span class="header-section-number">6.6.4</span> Estimación por máxima verosimilitud en regresión de Poisson</a></li>
  <li><a href="#bondad-de-ajuste-en-la-regresión-de-poisson" id="toc-bondad-de-ajuste-en-la-regresión-de-poisson" class="nav-link" data-scroll-target="#bondad-de-ajuste-en-la-regresión-de-poisson"><span class="header-section-number">6.6.5</span> Bondad de ajuste en la regresión de Poisson</a></li>
  <li><a href="#validación-del-modelo-de-poisson" id="toc-validación-del-modelo-de-poisson" class="nav-link" data-scroll-target="#validación-del-modelo-de-poisson"><span class="header-section-number">6.6.6</span> Validación del modelo de Poisson</a></li>
  </ul></li>
  <li><a href="#otros-glms" id="toc-otros-glms" class="nav-link" data-scroll-target="#otros-glms"><span class="header-section-number">6.7</span> Otros GLMs</a>
  <ul class="collapse">
  <li><a href="#regresión-binomial-negativa" id="toc-regresión-binomial-negativa" class="nav-link" data-scroll-target="#regresión-binomial-negativa"><span class="header-section-number">6.7.1</span> Regresión binomial negativa</a></li>
  <li><a href="#modelos-para-variables-continuas-no-normales" id="toc-modelos-para-variables-continuas-no-normales" class="nav-link" data-scroll-target="#modelos-para-variables-continuas-no-normales"><span class="header-section-number">6.7.2</span> Modelos para variables continuas no normales</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-tema4" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Hasta ahora hemos estuadiado la regresión lineal como una herramienta poderosa para modelar la relación entre una variable dependiente continua y un conjunto de variables independientes. Sin embargo, en muchos contextos del mundo real, las suposiciones de la regresión lineal tradicional no son adecuadas. ¿Qué sucede si la variable dependiente es binaria, como en un diagnóstico médico (enfermo/sano)? ¿O si estás modelando el número de accidentes en una intersección o la cantidad de compras realizadas por un cliente?</p>
<p>Para abordar estos desafíos, se utilizan los llamados <strong>Modelos Lineales Generalizados (GLM)</strong>. Esta clase de modelos amplía la regresión lineal al permitir que la variable dependiente tenga distribuciones diferentes a la normal, como la binomial o la de Poisson. Además, los GLM utilizan funciones de enlace que transforman la relación entre la variable dependiente y los predictores, permitiendo una mayor flexibilidad en el modelado.</p>
<p>Algunos de los modelos más comunes dentro de los GLM son:</p>
<ul>
<li>Regresión Logística: Ideal para variables dependientes binarias (sí/no, éxito/fracaso).</li>
<li>Regresión de Poisson: Utilizada para modelar datos de conteo (número de eventos).</li>
<li>Regresión Binomial Negativa: Una extensión de la regresión de Poisson para datos de conteo con sobredispersión.</li>
<li>Modelos de Gamma y Inverso Gaussiano: Utilizados para modelar variables continuas positivas y sesgadas, como tiempos de espera o costos.</li>
</ul>
<p>En este tema, exploraremos cómo utilizar estos modelos para resolver problemas del mundo real, interpretar sus resultados y evaluar su ajuste.</p>
<section id="introducción-a-los-glm" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introducción-a-los-glm"><span class="header-section-number">6.1</span> Introducción a los GLM</h2>
<section id="qué-son-los-modelos-lineales-generalizados" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="qué-son-los-modelos-lineales-generalizados"><span class="header-section-number">6.1.1</span> ¿Qué son los modelos lineales generalizados?</h3>
<p>Los <strong>Modelos Lineales Generalizados (GLM)</strong> son una extensión de los modelos de regresión lineal que permiten manejar una mayor variedad de tipos de datos y relaciones entre variables <span class="citation" data-cites="nelder1972generalized">(<a href="references.html#ref-nelder1972generalized" role="doc-biblioref">Nelder y Wedderburn 1972</a>)</span>. Mientras que la regresión lineal tradicional asume que la variable dependiente es continua y sigue una distribución normal, los GLM permiten trabajar con variables dependientes que:</p>
<ul>
<li>Son <strong>binarias</strong> (como éxito/fracaso o sí/no).</li>
<li>Representan <strong>conteos</strong> de eventos (número de llamadas, accidentes, etc.).</li>
<li>Son <strong>continuas positivas</strong> y no siguen una distribución normal (como tiempos o costos).</li>
</ul>
<p>Los GLM proporcionan una estructura flexible para modelar la relación entre una o más variables independientes y una variable dependiente que sigue alguna distribución de la <strong>familia exponencial</strong> (binomial, Poisson, gamma, entre otras).</p>
</section>
<section id="componentes-de-un-modelo-lineal-generalizado" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="componentes-de-un-modelo-lineal-generalizado"><span class="header-section-number">6.1.2</span> Componentes de un modelo lineal generalizado</h3>
<p>Un GLM se define por tres componentes clave:</p>
<ol type="1">
<li><p><strong>Componente Aleatorio:</strong></p>
<p>Este componente describe la distribución de la variable dependiente. En la regresión lineal, la variable dependiente sigue una distribución normal. En los GLM, puede seguir otras distribuciones de la <strong>familia exponencial</strong>, como:</p>
<ul>
<li><strong>Distribución Binomial:</strong> Para variables categóricas binarias (0/1, éxito/fracaso).</li>
<li><strong>Distribución de Poisson:</strong> Para datos de conteo (número de eventos).</li>
<li><strong>Distribución Gamma:</strong> Para variables continuas y positivas (como costos o tiempos).</li>
</ul></li>
<li><p><strong>Componente Sistemático:</strong><br>
Este componente describe cómo las variables independientes se combinan linealmente en el modelo. Se define como:</p>
<p><span class="math display">\[
\eta = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
\]</span></p>
<p>Donde <span class="math inline">\(\eta\)</span> es el <strong>predictor lineal</strong> y <span class="math inline">\(\boldsymbol{\beta}\)</span> representa los coeficientes del modelo.</p></li>
<li><p><strong>Función de Enlace:</strong><br>
La función de enlace conecta el componente sistemático con la media de la variable dependiente. Mientras que en la regresión lineal la relación es directa (<span class="math inline">\(y = \eta\)</span>), en los GLM se utiliza una función de enlace <span class="math inline">\(g(\mu)\)</span> para transformar la media <span class="math inline">\(\mu\)</span> y ajustar diferentes tipos de datos.</p>
<p><span class="math display">\[
g(\mu) = \eta
\]</span></p></li>
</ol>
<p><strong>Ejemplos de funciones de enlace:</strong></p>
<ul>
<li><strong>Logística (Logit):</strong> Para la regresión logística, que modela la probabilidad de un evento. <span class="math display">\[
g(\mu) = \log\left(\frac{\mu}{1 - \mu}\right)
\]</span></li>
<li><strong>Logarítmica:</strong> Para la regresión de Poisson, que modela tasas de eventos. <span class="math display">\[
g(\mu) = \log(\mu)
\]</span></li>
<li><strong>Identidad:</strong> Para la regresión lineal estándar. <span class="math display">\[
g(\mu) = \mu
\]</span></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Aplicaciones">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Aplicaciones
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Los GLM se utilizan en una amplia variedad de disciplinas para resolver problemas del mundo real:</p>
<p><strong>Regresión Logística (para variables binarias):</strong></p>
<ul>
<li><strong>Medicina:</strong> Predicción de la presencia o ausencia de una enfermedad basada en factores de riesgo.</li>
<li><strong>Marketing:</strong> Determinación de la probabilidad de que un cliente compre un producto.</li>
<li><strong>Finanzas:</strong> Evaluación de la probabilidad de incumplimiento de pago de un préstamo.</li>
</ul>
<p><strong>Regresión de Poisson (para datos de conteo):</strong></p>
<ul>
<li><strong>Transporte:</strong> Modelado del número de accidentes en una carretera en un período de tiempo.</li>
<li><strong>Ecología:</strong> Conteo de especies en un área determinada.</li>
<li><strong>Telecomunicaciones:</strong> Número de llamadas recibidas por un centro de atención.</li>
</ul>
<p><strong>Regresión Binomial Negativa (para conteos con sobredispersión):</strong></p>
<ul>
<li><strong>Salud Pública:</strong> Modelado del número de visitas al médico o incidentes de una enfermedad en una población.</li>
</ul>
<p><strong>Modelos Gamma (para variables continuas positivas):</strong></p>
<ul>
<li><strong>Seguros:</strong> Estimación de los costos de reclamos de seguros.</li>
<li><strong>Ingeniería:</strong> Modelado de tiempos de falla en procesos industriales.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="diferencias-clave-entre-la-regresión-lineal-y-los-glm" class="level3" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="diferencias-clave-entre-la-regresión-lineal-y-los-glm"><span class="header-section-number">6.1.3</span> Diferencias clave entre la regresión lineal y los GLM</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Característica</strong></th>
<th><strong>Regresión Lineal</strong></th>
<th><strong>Modelos Lineales Generalizados (GLM)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Distribución de la variable dependiente</strong></td>
<td>Normal</td>
<td>Familia exponencial (binomial, Poisson, gamma, etc.)</td>
</tr>
<tr class="even">
<td><strong>Tipo de variable dependiente</strong></td>
<td>Continua</td>
<td>Binaria, de conteo, continua positiva</td>
</tr>
<tr class="odd">
<td><strong>Relación entre las variables</strong></td>
<td>Lineal directa</td>
<td>Relación transformada mediante una función de enlace</td>
</tr>
<tr class="even">
<td><strong>Función de Enlace</strong></td>
<td>Identidad (<span class="math inline">\(g(\mu) = \mu\)</span>)</td>
<td>Logit, logarítmica, inversa, etc.</td>
</tr>
</tbody>
</table>
<hr>
<p>Las ventajas principales de los GLM son:</p>
<ul>
<li><p><strong>Flexibilidad:</strong> Los GLM permiten modelar diferentes tipos de variables dependientes, lo que amplía significativamente el rango de problemas que se pueden abordar.</p></li>
<li><p><strong>Interpretación Coherente:</strong> Aunque se utilizan funciones de enlace, los coeficientes de los GLM pueden interpretarse de manera similar a los modelos lineales, proporcionando información sobre el impacto de cada variable independiente.</p></li>
<li><p><strong>Evaluación Estadística Robusta:</strong> Los GLM permiten la realización de pruebas de hipótesis, la construcción de intervalos de confianza y la evaluación de la bondad del ajuste mediante medidas ya conocidas como el AIC o el BIC.</p></li>
</ul>
<p>Los <strong>Modelos Lineales Generalizados</strong> amplían el alcance de la regresión lineal clásica, proporcionando herramientas para modelar una amplia variedad de tipos de datos, desde variables binarias hasta datos de conteo y variables continuas no normales. A través del uso de funciones de enlace y distribuciones flexibles, los GLM permiten resolver problemas complejos del mundo real en campos tan diversos como la medicina, el marketing, la ingeniería y las ciencias sociales.</p>
<p>En las próximas secciones, exploraremos en detalle cómo aplicar estos modelos específicos, como la <strong>regresión logística</strong> y la <strong>regresión de Poisson</strong>, y cómo interpretar sus resultados en diferentes contextos.</p>
</section>
</section>
<section id="estimación-de-parámetros-en-glm" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="estimación-de-parámetros-en-glm"><span class="header-section-number">6.2</span> Estimación de parámetros en GLM</h2>
<p>La estimación de parámetros en los <strong>Modelos Lineales Generalizados</strong> representa un aspecto fundamental que diferencia estos modelos de la regresión lineal clásica. Mientras que en la regresión lineal utilizamos mínimos cuadrados ordinarios para obtener estimadores con propiedades óptimas, en los GLM necesitamos métodos más sofisticados debido a la naturaleza no normal de las distribuciones involucradas y las funciones de enlace no lineales.</p>
<p>La estimación en GLM se basa en el <strong>principio de máxima verosimilitud</strong>, que proporciona un marco teórico unificado para todos los modelos de la familia exponencial. Este enfoque no solo garantiza propiedades estadísticas deseables de los estimadores, sino que también permite el desarrollo de algoritmos computacionales eficientes para encontrar las soluciones.</p>
<p>En esta sección exploraremos los fundamentos teóricos de la estimación por máxima verosimilitud, el algoritmo iterativo IRLS (Iteratively Reweighted Least Squares) que implementan los software estadísticos, y los problemas prácticos que pueden surgir durante el proceso de estimación. Comprender estos aspectos es crucial para interpretar correctamente los resultados y diagnosticar posibles problemas en el ajuste de los modelos.</p>
<section id="método-de-máxima-verosimilitud" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="método-de-máxima-verosimilitud"><span class="header-section-number">6.2.1</span> Método de máxima verosimilitud</h3>
<p>A diferencia de la regresión lineal que utiliza el método de <strong>mínimos cuadrados</strong>, los GLM emplean el <strong>método de máxima verosimilitud</strong> para estimar los parámetros del modelo. Este cambio metodológico es necesario debido a que las distribuciones de la familia exponencial no siempre tienen una relación lineal directa con los predictores, y además porque la varianza de la variable respuesta depende de su media, violando el supuesto de homocedasticidad que requieren los mínimos cuadrados.</p>
<p>El principio de máxima verosimilitud consiste en encontrar los valores de los parámetros <span class="math inline">\(\boldsymbol{\beta}\)</span> que hacen más probable observar los datos que tenemos. Para una muestra de <span class="math inline">\(n\)</span> observaciones independientes <span class="math inline">\(y_1, y_2, \ldots, y_n\)</span>, la <strong>función de verosimilitud</strong> se define como la probabilidad conjunta de observar estos datos dado un conjunto de parámetros:</p>
<p><span class="math display">\[L(\boldsymbol{\beta}) = \prod_{i=1}^{n} f(y_i; \theta_i, \phi)\]</span></p>
<p>donde <span class="math inline">\(f(y_i; \theta_i, \phi)\)</span> es la función de densidad (o masa) de probabilidad de la observación <span class="math inline">\(i\)</span>. En la práctica, es más conveniente trabajar con el logaritmo de esta función, conocida como <strong>log-verosimilitud</strong>:</p>
<p><span class="math display">\[\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \log f(y_i; \theta_i, \phi)\]</span></p>
<p>La ventaja de usar el logaritmo es que convierte productos en sumas, simplificando considerablemente los cálculos matemáticos y numéricos.</p>
<p>La clave para entender los GLM radica en reconocer que todas las distribuciones que podemos usar (binomial, Poisson, gamma, etc.) pertenecen a la <strong>familia exponencial</strong>. Estas distribuciones pueden expresarse en una forma matemática unificada:</p>
<p><span class="math display">\[f(y; \theta, \phi) = \exp\left\{\frac{y\theta - b(\theta)}{a(\phi)} + c(y, \phi)\right\}\]</span></p>
<p>donde <span class="math inline">\(\theta\)</span> es el <strong>parámetro natural</strong> o canónico que está relacionado directamente con la media de la distribución, <span class="math inline">\(\phi\)</span> es el <strong>parámetro de dispersión</strong> que controla la variabilidad, y <span class="math inline">\(b(\theta)\)</span>, <span class="math inline">\(a(\phi)\)</span> y <span class="math inline">\(c(y, \phi)\)</span> son funciones específicas de cada distribución que determinan sus propiedades particulares.</p>
<p>Esta forma unificada tiene propiedades matemáticas muy convenientes que hacen que los GLM sean tanto elegantes teóricamente como computacionalmente eficientes. La esperanza de <span class="math inline">\(Y\)</span> se obtiene como <span class="math inline">\(E(Y) = \mu = b'(\theta)\)</span> (la derivada de <span class="math inline">\(b\)</span> respecto a <span class="math inline">\(\theta\)</span>), y la varianza como <span class="math inline">\(\text{Var}(Y) = a(\phi) b''(\theta) = a(\phi) V(\mu)\)</span>, donde <span class="math inline">\(V(\mu)\)</span> es la <strong>función de varianza</strong> que caracteriza cómo la varianza depende de la media en cada tipo de distribución.</p>
<div class="callout callout-style-default callout-note callout-titled" title="La Familia Exponencial: Un Vistazo General">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>La Familia Exponencial: Un Vistazo General
</div>
</div>
<div class="callout-body-container callout-body">
<p>La elegancia de los GLM reside en que muchas distribuciones aparentemente distintas comparten una estructura matemática común. Esto permite una teoría unificada. Aquí están los miembros más importantes:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Distribución</th>
<th style="text-align: left;">Uso Típico</th>
<th style="text-align: left;">Función de Varianza <span class="math inline">\(V(\mu)\)</span></th>
<th style="text-align: left;">Enlace Canónico <span class="math inline">\(g(\mu)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Normal</strong></td>
<td style="text-align: left;">Datos continuos simétricos</td>
<td style="text-align: left;"><span class="math inline">\(1\)</span></td>
<td style="text-align: left;">Identidad: <span class="math inline">\(\mu\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Binomial</strong></td>
<td style="text-align: left;">Proporciones, datos binarios (éxito/fracaso)</td>
<td style="text-align: left;"><span class="math inline">\(\mu(1-\mu)\)</span></td>
<td style="text-align: left;">Logit: <span class="math inline">\(\log(\frac{\mu}{1-\mu})\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Poisson</strong></td>
<td style="text-align: left;">Conteos de eventos</td>
<td style="text-align: left;"><span class="math inline">\(\mu\)</span></td>
<td style="text-align: left;">Log: <span class="math inline">\(\log(\mu)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Gamma</strong></td>
<td style="text-align: left;">Datos continuos positivos y asimétricos (tiempos, costos)</td>
<td style="text-align: left;"><span class="math inline">\(\mu^2\)</span></td>
<td style="text-align: left;">Inverso: <span class="math inline">\(1/\mu\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Inversa Gaussiana</strong></td>
<td style="text-align: left;">Tiempos hasta un evento, datos muy asimétricos</td>
<td style="text-align: left;"><span class="math inline">\(\mu^3\)</span></td>
<td style="text-align: left;">Inverso al cuadrado: <span class="math inline">\(1/\mu^2\)</span></td>
</tr>
</tbody>
</table>
<p>La <strong>función de varianza <span class="math inline">\(V(\mu)\)</span></strong> es la “firma” de cada distribución, ya que define la relación teórica entre la media y la varianza de la respuesta. El <strong>enlace canónico</strong> es la función de enlace que surge de forma natural de la estructura matemática de la distribución, aunque en la práctica se pueden usar otros enlaces.</p>
</div>
</div>
<p>Esta relación entre media y varianza es fundamental para entender las diferencias entre los diversos GLM. En la regresión lineal clásica, la varianza es constante (<span class="math inline">\(V(\mu) = 1\)</span>), pero en otros GLM la función de varianza toma formas específicas:</p>
<ul>
<li><strong>Distribución binomial</strong>: <span class="math inline">\(V(\mu) = \mu(1-\mu)\)</span> - la varianza es máxima cuando <span class="math inline">\(\mu = 0.5\)</span> y mínima en los extremos.</li>
<li><strong>Distribución de Poisson</strong>: <span class="math inline">\(V(\mu) = \mu\)</span> - la varianza aumenta linealmente con la media.</li>
<li><strong>Distribución gamma</strong>: <span class="math inline">\(V(\mu) = \mu^2\)</span> - la varianza aumenta cuadráticamente con la media.</li>
</ul>
<p>Estas funciones de varianza no solo determinan la heterocedasticidad inherente de cada distribución, sino que también influyen directamente en los pesos del algoritmo IRLS y en la precisión de las estimaciones. Por ejemplo, en regresión logística, las observaciones con probabilidades cercanas a 0.5 tienen mayor varianza y, por tanto, menor peso en la estimación, mientras que en regresión de Poisson, las observaciones con conteos más altos contribuyen con mayor peso al ajuste del modelo.</p>
<section id="algoritmo-de-newton-raphson-irls" class="level4" data-number="6.2.1.1">
<h4 data-number="6.2.1.1" class="anchored" data-anchor-id="algoritmo-de-newton-raphson-irls"><span class="header-section-number">6.2.1.1</span> Algoritmo de Newton-Raphson (IRLS)</h4>
<p>Para encontrar los valores de <span class="math inline">\(\boldsymbol{\beta}\)</span> que maximizan la log-verosimilitud, los GLM utilizan un algoritmo iterativo conocido como <strong>Iteratively Reweighted Least Squares (IRLS)</strong>, que es una implementación especializada del método de Newton-Raphson. La necesidad de un algoritmo iterativo surge porque, a diferencia de la regresión lineal donde existe una solución analítica cerrada, en los GLM las ecuaciones de verosimilitud no tienen solución directa debido a la presencia de funciones no lineales.</p>
<p>El algoritmo IRLS se basa en la idea de que podemos aproximar la función de enlace y la varianza de la distribución en torno a un valor central (la media) y luego aplicar mínimos cuadrados de manera iterativa para ajustar los parámetros del modelo. Los pasos básicos del algoritmo son:</p>
<ol type="1">
<li><p><strong>Inicialización:</strong> Establecer valores iniciales para los parámetros <span class="math inline">\(\boldsymbol{\beta}^{(0)}\)</span>.</p></li>
<li><p><strong>Iteración <span class="math inline">\(t\)</span>:</strong></p>
<ul>
<li>Calcular el predictor lineal: <span class="math inline">\(\eta_i^{(t)} = \mathbf{x}_i^T \boldsymbol{\beta}^{(t)}\)</span>.</li>
<li>Calcular la media estimada: <span class="math inline">\(\mu_i^{(t)} = g^{-1}(\eta_i^{(t)})\)</span>.</li>
<li>Calcular los pesos: <span class="math inline">\(w_i^{(t)} = \frac{1}{\text{Var}(\mu_i^{(t)})} \left(\frac{d\mu_i}{d\eta_i}\right)^2\)</span>.</li>
<li>Calcular la variable dependiente ajustada: <span class="math inline">\(z_i^{(t)} = \eta_i^{(t)} + (y_i - \mu_i^{(t)}) \frac{d\eta_i}{d\mu_i}\)</span>.</li>
</ul></li>
<li><p><strong>Actualización:</strong> Actualizar los parámetros del modelo:</p>
<p><span class="math display">\[\boldsymbol{\beta}^{(t+1)} = (\mathbf{X}^T \mathbf{W}^{(t)} \mathbf{X})^{-1} \mathbf{X}^T \mathbf{W}^{(t)} \mathbf{z}^{(t)}\]</span></p></li>
<li><p><strong>Convergencia:</strong> Repetir el proceso hasta que la diferencia entre iteraciones sucesivas sea menor que un umbral predefinido.</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo: Convergencia del algoritmo IRLS">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo: Convergencia del algoritmo IRLS
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo de seguimiento de la convergencia en regresión logística</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Pima.tr)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para mostrar el proceso iterativo</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>mostrar_convergencia <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ajustar modelo con seguimiento de iteraciones</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  modelo <span class="ot">&lt;-</span> <span class="fu">glm</span>(type <span class="sc">~</span> glu <span class="sc">+</span> bmi, <span class="at">data =</span> Pima.tr, <span class="at">family =</span> binomial,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">control =</span> <span class="fu">glm.control</span>(<span class="at">trace =</span> <span class="cn">TRUE</span>, <span class="at">maxit =</span> <span class="dv">10</span>))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Número de iteraciones necesarias:"</span>, modelo<span class="sc">$</span>iter, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"¿Convergió?"</span>, modelo<span class="sc">$</span>converged, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Log-likelihood final:"</span>, <span class="fu">logLik</span>(modelo), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(modelo)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejecutar y mostrar convergencia</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>modelo_ejemplo <span class="ot">&lt;-</span> <span class="fu">mostrar_convergencia</span>()</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Deviance = 199.36 Iterations - 1
Deviance = 198.4772 Iterations - 2
Deviance = 198.4704 Iterations - 3
Deviance = 198.4704 Iterations - 4
Número de iteraciones necesarias: 4 
¿Convergió? TRUE 
Log-likelihood final: -99.23522 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="propiedades-de-los-estimadores-de-máxima-verosimilitud" class="level4" data-number="6.2.1.2">
<h4 data-number="6.2.1.2" class="anchored" data-anchor-id="propiedades-de-los-estimadores-de-máxima-verosimilitud"><span class="header-section-number">6.2.1.2</span> Propiedades de los estimadores de máxima verosimilitud</h4>
<p>Los estimadores de máxima verosimilitud en GLM poseen propiedades estadísticas muy atractivas que los convierten en la elección preferida para la estimación de parámetros. Estas propiedades son <strong>asintóticas</strong>, lo que significa que se cumplen cuando el tamaño de la muestra tiende a infinito, pero en la práctica proporcionan una excelente aproximación para muestras moderadamente grandes.</p>
<p><strong>1. Consistencia:</strong> <span class="math display">\[\hat{\boldsymbol{\beta}} \xrightarrow{p} \boldsymbol{\beta} \text{ cuando } n \to \infty\]</span></p>
<p>La <strong>consistencia</strong> garantiza que a medida que aumentamos el tamaño de la muestra, nuestros estimadores se acercan cada vez más al valor verdadero de los parámetros. Esto significa que con suficientes datos, los estimadores de máxima verosimilitud convergerán al valor real de <span class="math inline">\(\boldsymbol{\beta}\)</span>, eliminando el sesgo de estimación. Esta propiedad es fundamental porque nos asegura que no estamos introduciendo errores sistemáticos en nuestras estimaciones.</p>
<p><strong>2. Normalidad asintótica:</strong> <span class="math display">\[\sqrt{n}(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta}) \xrightarrow{d} N(\mathbf{0}, \mathbf{I}^{-1}(\boldsymbol{\beta}))\]</span></p>
<p>La <strong>normalidad asintótica</strong> establece que la distribución de los estimadores, apropiadamente escalada, se aproxima a una distribución normal multivariada cuando el tamaño de la muestra es grande. Esta propiedad es crucial porque:</p>
<ul>
<li>Permite construir <strong>intervalos de confianza</strong> para los parámetros usando la distribución normal</li>
<li>Facilita la realización de <strong>pruebas de hipótesis</strong> sobre los coeficientes</li>
<li>Proporciona la base teórica para los <strong>estadísticos de Wald</strong> utilizados en las pruebas de significancia</li>
</ul>
<p>La matriz de covarianza asintótica <span class="math inline">\(\mathbf{I}^{-1}(\boldsymbol{\beta})\)</span> nos permite calcular los errores estándar de nuestras estimaciones, que son esenciales para la inferencia estadística.</p>
<p><strong>3. Eficiencia:</strong></p>
<p>Los estimadores MV alcanzan la <strong>cota de Cramér-Rao</strong>, siendo asintóticamente eficientes. Esto significa que:</p>
<ul>
<li>Entre todos los estimadores insesgados posibles, los de máxima verosimilitud tienen la <strong>menor varianza asintótica</strong></li>
<li>No existe otro método de estimación que, bajo las mismas condiciones, produzca estimadores con menor incertidumbre</li>
<li>Utilizan la información disponible en los datos de manera <strong>óptima</strong></li>
</ul>
<p>En términos prácticos, esta eficiencia se traduce en intervalos de confianza más estrechos y pruebas de hipótesis más poderosas comparado con otros métodos de estimación.</p>
</section>
<section id="matriz-de-información-y-errores-estándar" class="level4" data-number="6.2.1.3">
<h4 data-number="6.2.1.3" class="anchored" data-anchor-id="matriz-de-información-y-errores-estándar"><span class="header-section-number">6.2.1.3</span> Matriz de información y errores estándar</h4>
<p>La implementación práctica de estas propiedades teóricas requiere el cálculo de la <strong>matriz de información</strong>, que cuantifica la cantidad de información que contienen los datos sobre los parámetros del modelo.</p>
<p>La <strong>matriz de información de Fisher</strong> se define teóricamente como:</p>
<p><span class="math display">\[\mathbf{I}(\boldsymbol{\beta}) = E\left[-\frac{\partial^2 \ell}{\partial \boldsymbol{\beta} \partial \boldsymbol{\beta}^T}\right]\]</span></p>
<p>Sin embargo, en la práctica utilizamos la <strong>matriz de información observada</strong>, que se calcula directamente de nuestros datos:</p>
<p><span class="math display">\[\mathbf{I}(\hat{\boldsymbol{\beta}}) = -\frac{\partial^2 \ell}{\partial \boldsymbol{\beta} \partial \boldsymbol{\beta}^T}\bigg|_{\boldsymbol{\beta}=\hat{\boldsymbol{\beta}}}\]</span></p>
<p>Esta matriz representa las segundas derivadas de la log-verosimilitud evaluadas en nuestras estimaciones. Intuitivamente, mide qué tan “puntiaguda” es la función de verosimilitud alrededor del máximo: una función más puntiaguda indica mayor información y, por tanto, menor incertidumbre en la estimación.</p>
<p>Para los GLM, el algoritmo IRLS proporciona una aproximación computacionalmente eficiente:</p>
<p><span class="math display">\[\mathbf{I}(\hat{\boldsymbol{\beta}}) \approx \mathbf{X}^T \mathbf{W} \mathbf{X}\]</span></p>
<p>donde <span class="math inline">\(\mathbf{W}\)</span> es la matriz diagonal de pesos calculada en la última iteración del algoritmo. Esta aproximación es exacta para la distribución normal y muy buena para otras distribuciones de la familia exponencial.</p>
<p>Los <strong>errores estándar</strong> de los coeficientes individuales se obtienen como las raíces cuadradas de los elementos diagonales de la matriz de covarianza:</p>
<p><span class="math display">\[\text{SE}(\hat{\beta}_j) = \sqrt{[\mathbf{I}^{-1}(\hat{\boldsymbol{\beta}})]_{jj}}\]</span></p>
<p>Estos errores estándar son fundamentales para:</p>
<ul>
<li><strong>Intervalos de confianza:</strong> <span class="math inline">\(\hat{\beta}_j \pm z_{\alpha/2} \cdot \text{SE}(\hat{\beta}_j)\)</span></li>
<li><strong>Estadísticos de prueba:</strong> <span class="math inline">\(z_j = \frac{\hat{\beta}_j}{\text{SE}(\hat{\beta}_j)}\)</span></li>
<li><strong>Evaluación de la precisión</strong> de nuestras estimaciones</li>
</ul>
<p>Es importante recordar que estos errores estándar son válidos bajo los supuestos del modelo GLM y que violaciones serias de estos supuestos (como sobredispersión en modelos de Poisson) pueden hacer que sean inadecuados.</p>
</section>
</section>
</section>
<section id="bondad-de-ajuste-en-glms" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="bondad-de-ajuste-en-glms"><span class="header-section-number">6.3</span> Bondad de ajuste en GLMs</h2>
<p>Los <strong>Modelos Lineales Generalizados</strong> requieren métodos específicos para evaluar la calidad del ajuste que van más allá de las métricas tradicionales de la regresión lineal. Mientras que en la regresión lineal clásica utilizamos el coeficiente de determinación (<span class="math inline">\(R^2\)</span>) y la suma de cuadrados residuales como medidas principales de bondad de ajuste, en los GLMs estas métricas no son apropiadas debido a las diferentes distribuciones subyacentes y las funciones de enlace no lineales.</p>
<p>La evaluación de la bondad de ajuste en GLMs se basa fundamentalmente en conceptos de <strong>verosimilitud</strong> y <strong>deviance</strong>, que proporcionan una base teórica sólida para comparar modelos y evaluar su calidad de ajuste. Esta aproximacion basada en la verosimilitud es coherente con el método de estimación utilizado en estos modelos.</p>
<section id="la-deviance-como-medida-de-bondad-de-ajuste" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="la-deviance-como-medida-de-bondad-de-ajuste"><span class="header-section-number">6.3.1</span> La deviance como medida de bondad de ajuste</h3>
<p>La <strong>deviance</strong> (o <strong>desviación</strong>) es la medida principal de bondad de ajuste en los <strong>Modelos Lineales Generalizados</strong>. Conceptualmente, representa una generalización de la suma de cuadrados residuales de la regresión lineal para distribuciones no normales, pero su interpretación y cálculo son fundamentalmente diferentes.</p>
<p>La deviance se basa en el principio de <strong>máxima verosimilitud</strong> y mide qué tan bien el modelo propuesto se ajusta a los datos comparado con el mejor ajuste posible. Para entender este concepto, es importante distinguir entre dos tipos de modelos:</p>
<ol type="1">
<li><p><strong>Modelo Saturado</strong>: Un modelo hipotético que tiene tantos parámetros como observaciones, por lo que puede predecir perfectamente cada valor observado. Este modelo representa el “ajuste perfecto” teórico.</p></li>
<li><p><strong>Modelo Propuesto</strong>: El modelo que estamos evaluando, con un número limitado de parámetros basado en nuestras variables predictoras.</p></li>
</ol>
<p>La deviance mide la <strong>diferencia en log-verosimilitud</strong> entre estos dos modelos:</p>
<p><span class="math display">\[
D = 2 \sum_{i=1}^{n} \left[ \ell(y_i; y_i) - \ell(y_i; \hat{\mu}_i) \right]
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(\ell(y_i; y_i)\)</span> = Log-verosimilitud del modelo saturado para la observación <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(\ell(y_i; \hat{\mu}_i)\)</span> = Log-verosimilitud del modelo propuesto para la observación <span class="math inline">\(i\)</span>.</li>
<li>El factor 2 se incluye para que la deviance siga aproximadamente una distribución chi-cuadrado bajo ciertas condiciones.</li>
</ul>
<p><strong>Interpretación práctica:</strong></p>
<ul>
<li><strong>Deviance = 0</strong>: Modelo perfecto que ajusta exactamente todos los datos observados</li>
<li><strong>Deviance baja</strong>: Buen ajuste del modelo a los datos</li>
<li><strong>Deviance alta</strong>: Mal ajuste del modelo, sugiere que el modelo no captura adecuadamente los patrones en los datos</li>
</ul>
<p><strong>Comparación relativa</strong>: La deviance es más útil para <strong>comparar modelos</strong> que para evaluación absoluta. Un modelo con menor deviance indica mejor ajuste, pero el valor absoluto depende del tamaño de la muestra y la naturaleza de los datos.</p>
<p><strong>Deviance residual vs.&nbsp;deviance nula</strong>:</p>
<ul>
<li><strong>Deviance nula</strong>: Deviance del modelo que solo incluye el intercepto (sin predictores)</li>
<li><strong>Deviance residual</strong>: Deviance del modelo con todos los predictores incluidos</li>
<li>La diferencia entre ambas indica cuánto mejora el modelo al incluir las variables predictoras</li>
</ul>
</section>
<section id="test-de-la-razón-de-verosimilitudes" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="test-de-la-razón-de-verosimilitudes"><span class="header-section-number">6.3.2</span> Test de la razón de verosimilitudes</h3>
<p>El <strong>test de la razón de verosimilitudes</strong> es la herramienta principal para comparar modelos anidados en GLMs y para evaluar la significancia global del modelo. Se basa en el principio de que si un modelo más complejo no mejora significativamente el ajuste, debemos preferir el modelo más simple por parsimonia.</p>
<p>Cuando comparamos dos modelos anidados (donde uno es un caso especial del otro), la diferencia en sus deviances sigue aproximadamente una distribución chi-cuadrado:</p>
<p><span class="math display">\[
LRT = D_{\text{modelo reducido}} - D_{\text{modelo completo}} \sim \chi^2_{df}
\]</span></p>
<p>donde <span class="math inline">\(df\)</span> es la diferencia en grados de libertad (número de parámetros) entre los modelos.</p>
<p><strong>Interpretación del test:</strong></p>
<ul>
<li><strong>Hipótesis nula (<span class="math inline">\(H_0\)</span>)</strong>: El modelo reducido es adecuado (los parámetros adicionales no son necesarios)</li>
<li><strong>Hipótesis alternativa (<span class="math inline">\(H_1\)</span>)</strong>: El modelo completo es significativamente mejor</li>
<li><strong>Decisión</strong>: Si <span class="math inline">\(p\)</span>-valor &lt; <span class="math inline">\(\alpha\)</span> (típicamente 0.05), rechazamos <span class="math inline">\(H_0\)</span> y preferimos el modelo completo</li>
</ul>
<p><strong>Aplicaciones principales:</strong></p>
<ol type="1">
<li><p><strong>Significancia global del modelo:</strong> Comparar el modelo completo con el modelo nulo (solo intercepto) para determinar si las variables predictoras aportan información significativa.</p></li>
<li><p><strong>Selección de variables:</strong> Evaluar si la inclusión o exclusión de variables específicas mejora significativamente el ajuste del modelo.</p></li>
<li><p><strong>Comparación de especificaciones:</strong> Decidir entre diferentes formas funcionales o distribuciones para el mismo conjunto de datos.</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo: Comparando Modelos con el Test de Razón de Verosimilitudes">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo: Comparando Modelos con el Test de Razón de Verosimilitudes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supongamos que queremos determinar si añadir la variable <code>disp</code> (cilindrada) a un modelo de regresión logística que ya contiene <code>wt</code> (peso) mejora significativamente la predicción de si un coche tiene transmisión automática (<code>am</code>).</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usaremos el dataset mtcars</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelo Reducido: solo contiene 'wt'</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>modelo_reducido <span class="ot">&lt;-</span> <span class="fu">glm</span>(am <span class="sc">~</span> wt, <span class="at">data =</span> mtcars, <span class="at">family =</span> binomial)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelo Completo: contiene 'wt' y 'disp'</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>modelo_completo <span class="ot">&lt;-</span> <span class="fu">glm</span>(am <span class="sc">~</span> wt <span class="sc">+</span> disp, <span class="at">data =</span> mtcars, <span class="at">family =</span> binomial)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizamos el Test de Razón de Verosimilitudes (LRT)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># En R, esto se hace con la función anova() especificando el test</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>lrt_resultado <span class="ot">&lt;-</span> <span class="fu">anova</span>(modelo_reducido, modelo_completo, <span class="at">test =</span> <span class="st">"LRT"</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostramos los resultados</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(lrt_resultado)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: am ~ wt
Model 2: am ~ wt + disp
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
1        30     19.176                     
2        29     17.785  1   1.3913   0.2382</code></pre>
</div>
</div>
<p><strong>Interpretación del resultado:</strong></p>
<p>El test compara la <strong>Deviance</strong> de ambos modelos. La hipótesis nula (<span class="math inline">\(H\_0\)</span>) es que el modelo reducido es suficiente (es decir, <span class="math inline">\(\\beta\_{disp} = 0\)</span>).</p>
<ul>
<li>La diferencia en deviance es de 1.391 con 1 grado de libertad (el parámetro adicional).</li>
<li>El p-valor asociado es <strong>0.238</strong>.</li>
</ul>
<p>Dado que el p-valor es mayor que 0.05, <strong>no rechazamos la hipótesis nula</strong>. Esto significa que, una vez que tenemos en cuenta el peso del coche (<code>wt</code>), añadir la cilindrada (<code>disp</code>) no aporta una mejora estadísticamente significativa al modelo. Nos quedaríamos con el <strong>modelo reducido</strong> por el principio de parsimonia.</p>
</div>
</div>
</div>
</section>
</section>
<section id="diagnosis-de-glms" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="diagnosis-de-glms"><span class="header-section-number">6.4</span> Diagnosis de GLMs</h2>
<p>La diagnosis de GLMs implica evaluar los supuestos del modelo y detectar problemas potenciales que puedan afectar la validez de las inferencias. A diferencia de la regresión lineal, donde los residuos ordinarios proporcionan información diagnóstica directa, los GLMs requieren herramientas especializadas debido a la heterocedasticidad inherente y las diferentes distribuciones subyacentes.</p>
<p>En lugar de una simple lista de comprobación, abordaremos el diagnóstico respondiendo a tres preguntas clave que un analista se haría, utilizando diferentes tipos de <strong>residuos</strong> para obtener las respuestas.</p>
<section id="tipos-de-residuos-en-glms" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="tipos-de-residuos-en-glms"><span class="header-section-number">6.4.1</span> Tipos de Residuos en GLMs</h3>
<p>La elección del tipo de residuo apropiado es crucial. Los residuos “crudos” (<span class="math inline">\(y_i - \hat{\mu}_i\)</span>) no son homocedásticos, por lo que se utilizan versiones estandarizadas. Los más importantes son:</p>
<ul>
<li><p><strong>Residuos Pearson:</strong> Estandarizan el residuo crudo dividiendo por la desviación estándar predicha por el modelo. Son un análogo directo a los residuos estandarizados en regresión lineal. <span class="math display">\[
  r_i = \frac{y_i - \hat{\mu}_i}{\sqrt{V(\hat{\mu}_i)}}
  \]</span></p></li>
<li><p><strong>Residuos Estudentizados:</strong> Son una mejora de los residuos Pearson que también tienen en cuenta el leverage (<span class="math inline">\(h_i\)</span>) de cada observación. Son más fiables para la detección de outliers. <span class="math display">\[
  r_{S_i} = \frac{y_i - \hat{\mu}_i}{\sqrt{V(\hat{\mu}_i)(1-h_i)}}
  \]</span></p></li>
<li><p><strong>Residuos deviance:</strong> Son los más recomendados para la inspección visual en gráficos diagnósticos. Su construcción, basada en la contribución de cada punto a la deviance total, les confiere propiedades muy deseables: su distribución se aproxima mejor a la normalidad y su varianza es más estable que la de otros residuos. <span class="math display">\[
  d_i = \text{sign}(y_i - \hat{\mu}_i) \sqrt{2[l_i(y_i) - l_i(\hat{\mu}_i)]}
  \]</span></p></li>
</ul>
</section>
<section id="la-forma-del-modelo-es-correcta-linealidad-y-enlace" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="la-forma-del-modelo-es-correcta-linealidad-y-enlace"><span class="header-section-number">6.4.2</span> ¿La forma del modelo es correcta? (Linealidad y Enlace)</h3>
<p>Esta primera pregunta evalúa si la estructura básica del modelo, <span class="math inline">\(g(\mu) = X\beta\)</span>, es adecuada para los datos. Para ello, utilizamos varias herramientas de diagnóstico:</p>
<ul>
<li><p>El <strong>gráfico de residuos vs.&nbsp;valores ajustados</strong> es la herramienta fundamental. Se grafican los residuos (idealmente, deviance) contra los valores predichos en la escala del predictor lineal (<span class="math inline">\(\hat{\eta}_i\)</span>). Si la forma del modelo es correcta, no deberíamos ver ningún patrón sistemático. Una tendencia curvilínea es una señal clara de que la forma funcional o la función de enlace son incorrectas.</p></li>
<li><p>Los <strong>gráficos de residuos parciales</strong> son esenciales para evaluar si la función de enlace es apropiada para <strong>cada predictor individualmente</strong>. Un patrón no lineal en este gráfico sugiere que la relación de esa variable específica con la respuesta no es la que asume el modelo.</p></li>
<li><p>El <strong>test de especificación de enlace</strong> (como el <em>Linktest</em> de Pregibon) ofrece una prueba formal. La idea es ajustar un segundo modelo que incluye el predictor lineal al cuadrado (<span class="math inline">\(\hat{\eta}^2\)</span>) como una variable adicional. Si este término cuadrático resulta significativo, es una fuerte evidencia de que la función de enlace está mal especificada.</p></li>
</ul>
<p>Si estos diagnósticos revelan problemas, las estrategias de corrección incluyen aplicar <strong>transformaciones</strong> a los predictores (ej. logaritmo, términos polinómicos), <strong>incluir términos de interacción</strong> para capturar relaciones no aditivas, o directamente <strong>cambiar la función de enlace</strong> a una que se ajuste mejor a los datos.</p>
</section>
<section id="la-distribución-que-elegimos-es-la-correcta-varianza-y-normalidad" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="la-distribución-que-elegimos-es-la-correcta-varianza-y-normalidad"><span class="header-section-number">6.4.3</span> ¿La distribución que elegimos es la correcta? (Varianza y Normalidad)</h3>
<p>Esta pregunta evalúa si la elección de la familia de distribución (Poisson, Binomial, etc.) fue acertada, lo que implica verificar la relación entre la media y la varianza, así como la forma general de los errores.</p>
<p>Un primer aspecto clave al verificar la distribución es la <strong>sobredispersión</strong>. Imagina que tu modelo es como una regla estricta sobre el comportamiento de los datos. El modelo de Poisson, por ejemplo, impone que la varianza de los conteos debe ser igual a su media (<span class="math inline">\(Var(Y) = \mu\)</span>). La sobredispersión ocurre cuando tus datos reales son más “desordenados” o variables de lo que esta regla permite.</p>
<p>Para detectar este problema de forma objetiva, calculamos el <strong>Estadístico de dispersión (<span class="math inline">\(\hat{\phi}\)</span>)</strong>, que compara la varianza observada (a través de los residuos Pearson) con la esperada: <span class="math display">\[\hat{\phi} = \frac{X^2_{\text{Pearson}}}{n-p} = \frac{\sum r_i^2}{n-p}\]</span> La interpretación es directa:</p>
<ul>
<li><strong>Si <span class="math inline">\(\hat{\phi} \approx 1\)</span></strong>: ¡Perfecto! La dispersión de los datos es la que el modelo esperaba.</li>
<li><strong>Si <span class="math inline">\(\hat{\phi} &gt; 1\)</span></strong>: Tienes <strong>sobredispersión</strong>. El modelo está subestimando la variabilidad real de los datos, lo que invalida las inferencias (errores estándar, p-valores).</li>
</ul>
<p>La estrategia para corregirlo no es forzar los datos, sino cambiar a un modelo más flexible. El caso clásico es pasar del modelo de <strong>Poisson</strong> al modelo <strong>Binomial Negativo</strong>. Este último funciona porque su fórmula para la varianza incluye un parámetro de dispersión adicional (<span class="math inline">\(\alpha\)</span>) que le permite modelar esa variabilidad extra que el modelo de Poisson no puede capturar: <span class="math display">\[Var(Y) = \mu + \alpha\mu^2\]</span></p>
<p>Este término adicional se ajusta a la variabilidad de los datos, proporcionando estimaciones y errores estándar mucho más fiables.</p>
<p>Un segundo aspecto es la forma general de la distribución, que se evalúa con el <strong>Gráfico Q-Q de residuos deviance</strong>. Aunque los errores de un GLM no son estrictamente normales, los residuos deviance sí deberían tener una distribución aproximadamente normal si el modelo está bien especificado. Desviaciones sistemáticas de la línea diagonal en el gráfico Q-Q pueden indicar que la distribución asumida para los datos es incorrecta.</p>
</section>
<section id="hay-observaciones-que-distorsionan-el-modelo-atípicos-e-influyentes" class="level3" data-number="6.4.4">
<h3 data-number="6.4.4" class="anchored" data-anchor-id="hay-observaciones-que-distorsionan-el-modelo-atípicos-e-influyentes"><span class="header-section-number">6.4.4</span> ¿Hay observaciones que distorsionan el modelo? (Atípicos e Influyentes)</h3>
<p>Finalmente, buscamos identificar puntos individuales que tienen una influencia desproporcionada en el modelo. Las herramientas matemáticas para ello son generalizaciones de las vistas en regresión lineal:</p>
<ul>
<li><p><strong>Leverage generalizado (<span class="math inline">\(h_i\)</span>):</strong> Mide el potencial de una observación para ser influyente debido a su posición en el espacio de los predictores. <span class="math display">\[
  h_i = w_i \mathbf{x}_i^T (\mathbf{X}^T \mathbf{W} \mathbf{X})^{-1} \mathbf{x}_i
  \]</span> donde <span class="math inline">\(w_i\)</span> y <span class="math inline">\(\mathbf{W}\)</span> son el peso y la matriz de pesos de la última iteración del algoritmo IRLS.</p></li>
<li><p><strong>Distancia de Cook para GLMs (<span class="math inline">\(D_i\)</span>):</strong> Mide la influencia global de una observación en <em>todos</em> los coeficientes. Utiliza el residuo Pearson (<span class="math inline">\(r_i\)</span>). <span class="math display">\[
  D_i = \frac{r_i^2 h_i}{p(1-h_i)^2}
  \]</span></p></li>
<li><p><strong>DFBETAS:</strong> Mide la influencia de la observación <span class="math inline">\(i\)</span> en <em>cada coeficiente individual</em> <span class="math inline">\(\beta_j\)</span>. Es útil para ver si un punto influyente está afectando a una variable de interés particular. <span class="math display">\[
  \text{DFBETA}_{j,i} = \frac{\hat{\beta}_j - \hat{\beta}_{j(-i)}}{\text{SE}(\hat{\beta}_{j(-i)})} \approx \frac{(\mathbf{X}^T\mathbf{W}\mathbf{X})^{-1}_{jj}x_{ij}(y_i-\hat{\mu}_i)}{\text{SE}(\hat{\beta}_j)\sqrt{1-h_i}}
  \]</span></p></li>
</ul>
<p>La herramienta visual que consolida esta información es el <strong>gráfico de residuos vs.&nbsp;leverage</strong>. La estrategia ante estas observaciones no es eliminarlas automáticamente, sino <strong>investigarlas</strong> para entender su naturaleza.</p>
</section>
</section>
<section id="regresión-logística" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="regresión-logística"><span class="header-section-number">6.5</span> Regresión logística</h2>
<p>La <strong>regresión logística</strong> es una herramienta fundamental para modelar la probabilidad de eventos binarios en una variedad de contextos, desde la medicina hasta la economía y el marketing <span class="citation" data-cites="hosmer2013applied">(<a href="references.html#ref-hosmer2013applied" role="doc-biblioref">Hosmer Jr, Lemeshow, y Sturdivant 2013</a>)</span>. La correcta interpretación de los coeficientes mediante <strong>odds ratios</strong>, así como la evaluación del ajuste del modelo mediante curvas <strong>ROC</strong> y matrices de confusión, son esenciales para extraer conclusiones válidas de los datos.</p>
<section id="fundamentos-de-la-regresión-logística" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1" class="anchored" data-anchor-id="fundamentos-de-la-regresión-logística"><span class="header-section-number">6.5.1</span> Fundamentos de la regresión logística</h3>
<p>La <strong>regresión logística</strong> es una técnica estadística utilizada para modelar la probabilidad de ocurrencia de un evento binario, es decir, cuando la variable dependiente toma solo dos posibles valores (por ejemplo, <strong>éxito/fracaso</strong>, <strong>sí/no</strong>, <strong>enfermo/sano</strong>). A diferencia de la regresión lineal, que modela una relación lineal entre variables, la regresión logística utiliza una <strong>función logística</strong> para asegurar que las predicciones estén en el rango [0,1], lo cual es necesario para interpretar los resultados como probabilidades.</p>
<p><strong>La función Logística (Sigmoide)</strong></p>
<p>La función logística transforma cualquier valor real en un valor comprendido entre 0 y 1. La forma matemática de la función logística es:</p>
<p><span class="math display">\[
P(Y = 1 | X_1, \dots, X_p) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p)}}
\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(P(Y = 1 | X_1, \dots, X_p)\)</span> es la probabilidad de que el evento ocurra.</li>
<li><span class="math inline">\(\beta_0\)</span> es el intercepto y <span class="math inline">\(\beta_1, \beta_2, \dots, \beta_p\)</span> son los coeficientes asociados a las variables independientes <span class="math inline">\(X_1, X_2, \dots, X_p\)</span>.</li>
</ul>
<p>La <strong>curva sigmoide</strong> que representa esta función tiene forma de “S”, lo que refleja que para valores muy pequeños o muy grandes del predictor, la probabilidad se aplana hacia 0 o 1, respectivamente.</p>
<p><strong>Función de enlace Logit</strong></p>
<p>En la regresión logística, la relación entre el predictor lineal y la probabilidad se establece mediante la <strong>función de enlace logit</strong>. El logit de una probabilidad <span class="math inline">\(p\)</span> se define como:</p>
<p><span class="math display">\[
\text{logit}(p) = \log\left(\frac{p}{1 - p}\right)
\]</span></p>
<p>Esta transformación convierte una probabilidad en una escala que va de <span class="math inline">\(-\infty\)</span> a <span class="math inline">\(+\infty\)</span>, lo que permite ajustar un modelo lineal a los datos. El modelo logístico puede expresarse como:</p>
<p><span class="math display">\[
\log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p
\]</span></p>
</section>
<section id="estimación-por-máxima-verosimilitud-en-regresión-logística" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2" class="anchored" data-anchor-id="estimación-por-máxima-verosimilitud-en-regresión-logística"><span class="header-section-number">6.5.2</span> Estimación por máxima verosimilitud en regresión logística</h3>
<p>La estimación de los parámetros en regresión logística se basa en el método de máxima verosimilitud, adaptado específicamente para la distribución binomial con función de enlace logit.</p>
<p>Para una muestra de <span class="math inline">\(n\)</span> observaciones independientes, donde <span class="math inline">\(y_i \in \{0,1\}\)</span> representa el resultado binario para la observación <span class="math inline">\(i\)</span>, la <strong>función de verosimilitud</strong> se define como:</p>
<p><span class="math display">\[L(\boldsymbol{\beta}) = \prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}\]</span></p>
<p>donde <span class="math inline">\(p_i = P(Y_i = 1|\mathbf{x}_i) = \frac{1}{1 + e^{-\mathbf{x}_i^T\boldsymbol{\beta}}}\)</span> es la probabilidad estimada para la observación <span class="math inline">\(i\)</span>.</p>
<p>La <strong>log-verosimilitud</strong> correspondiente es:</p>
<p><span class="math display">\[\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[y_i \log(p_i) + (1-y_i) \log(1-p_i)\right]\]</span></p>
<p>Sustituyendo la expresión de <span class="math inline">\(p_i\)</span> y simplificando:</p>
<p><span class="math display">\[\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[y_i \mathbf{x}_i^T\boldsymbol{\beta} - \log(1 + e^{\mathbf{x}_i^T\boldsymbol{\beta}})\right]\]</span></p>
<p>Para encontrar los valores de <span class="math inline">\(\boldsymbol{\beta}\)</span> que maximizan la log-verosimilitud, derivamos respecto a cada parámetro:</p>
<p><span class="math display">\[\frac{\partial \ell}{\partial \beta_j} = \sum_{i=1}^{n} x_{ij}(y_i - p_i) = 0\]</span></p>
<p>donde <span class="math inline">\(x_{ij}\)</span> es el valor de la variable <span class="math inline">\(j\)</span> para la observación <span class="math inline">\(i\)</span>.</p>
<p>Esta ecuación tiene una interpretación intuitiva: los estimadores de máxima verosimilitud se obtienen cuando la suma de los residuos ponderados por cada variable predictora es igual a cero.</p>
<section id="implementación-del-algoritmo-irls" class="level4" data-number="6.5.2.1">
<h4 data-number="6.5.2.1" class="anchored" data-anchor-id="implementación-del-algoritmo-irls"><span class="header-section-number">6.5.2.1</span> Implementación del algoritmo IRLS</h4>
<p>Dado que las ecuaciones de verosimilitud no tienen solución analítica cerrada, se utiliza el algoritmo IRLS. Para regresión logística, los elementos específicos son:</p>
<p><strong>Pesos:</strong> <span class="math display">\[w_i = p_i(1-p_i)\]</span></p>
<p><strong>Variable dependiente ajustada:</strong> <span class="math display">\[z_i = \mathbf{x}_i^T\boldsymbol{\beta}^{(t)} + \frac{y_i - p_i^{(t)}}{p_i^{(t)}(1-p_i^{(t)})}\]</span></p>
<p><strong>Actualización de parámetros:</strong> <span class="math display">\[\boldsymbol{\beta}^{(t+1)} = (\mathbf{X}^T \mathbf{W}^{(t)} \mathbf{X})^{-1} \mathbf{X}^T \mathbf{W}^{(t)} \mathbf{z}^{(t)}\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo: Estimación paso a paso en regresión logística">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo: Estimación paso a paso en regresión logística
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demostración del proceso de estimación por máxima verosimilitud</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Pima.tr)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para calcular log-verosimilitud manualmente</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>log_likelihood_logistic <span class="ot">&lt;-</span> <span class="cf">function</span>(beta, X, y) {</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  eta <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>eta))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Evitar problemas numéricos</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="fu">pmin</span>(p, <span class="dv">1</span><span class="fl">-1e-15</span>), <span class="fl">1e-15</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(y <span class="sc">*</span> <span class="fu">log</span>(p) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>y) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>p))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparar datos</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(type <span class="sc">~</span> glu <span class="sc">+</span> bmi, <span class="at">data =</span> Pima.tr)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(Pima.tr<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"Yes"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste con glm para comparación</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>modelo_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(type <span class="sc">~</span> glu <span class="sc">+</span> bmi, <span class="at">data =</span> Pima.tr, <span class="at">family =</span> binomial)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>beta_glm <span class="ot">&lt;-</span> <span class="fu">coef</span>(modelo_glm)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"=== ESTIMACIÓN POR MÁXIMA VEROSIMILITUD ===</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== ESTIMACIÓN POR MÁXIMA VEROSIMILITUD ===</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Coeficientes estimados por glm():</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coeficientes estimados por glm():</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_glm)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         glu         bmi 
-8.21610630  0.03571601  0.09001639 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar que estos coeficientes maximizan la log-verosimilitud</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>ll_optimo <span class="ot">&lt;-</span> <span class="fu">log_likelihood_logistic</span>(beta_glm, X, y)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Log-verosimilitud en el óptimo:"</span>, <span class="fu">round</span>(ll_optimo, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Log-verosimilitud en el óptimo: -99.2352 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparar con valores ligeramente diferentes</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>beta_test <span class="ot">&lt;-</span> beta_glm <span class="sc">+</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>ll_test <span class="ot">&lt;-</span> <span class="fu">log_likelihood_logistic</span>(beta_test, X, y)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Log-verosimilitud con perturbación:"</span>, <span class="fu">round</span>(ll_test, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Log-verosimilitud con perturbación: -99.3995 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Diferencia:"</span>, <span class="fu">round</span>(ll_optimo <span class="sc">-</span> ll_test, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Diferencia: 0.1643 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar información de convergencia</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Información del algoritmo IRLS:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Información del algoritmo IRLS:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Iteraciones necesarias:"</span>, modelo_glm<span class="sc">$</span>iter, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteraciones necesarias: 4 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"¿Convergió?"</span>, modelo_glm<span class="sc">$</span>converged, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>¿Convergió? TRUE </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matriz de información y errores estándar</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>vcov_matrix <span class="ot">&lt;-</span> <span class="fu">vcov</span>(modelo_glm)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Errores estándar de los coeficientes:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Errores estándar de los coeficientes:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">sqrt</span>(<span class="fu">diag</span>(vcov_matrix)))</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         glu         bmi 
1.346965130 0.006311023 0.031268458 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="interpretación-de-coeficientes-y-odds-ratios" class="level3" data-number="6.5.3">
<h3 data-number="6.5.3" class="anchored" data-anchor-id="interpretación-de-coeficientes-y-odds-ratios"><span class="header-section-number">6.5.3</span> Interpretación de coeficientes y odds ratios</h3>
<p>Uno de los aspectos más importantes de la regresión logística es la interpretación de los coeficientes. Dado que los coeficientes están en la escala del logit, su interpretación directa no es tan intuitiva como en la regresión lineal. Sin embargo, podemos interpretarlos utilizando <strong>odds</strong> y <strong>odds ratios</strong>.</p>
<p>El <strong>odds</strong> o razón de probabilidades de que ocurra un evento es el cociente entre la probabilidad de que ocurra el evento y la probabilidad de que no ocurra:</p>
<p><span class="math display">\[
\text{odds} = \frac{p}{1 - p}
\]</span></p>
<p>Por ejemplo, si la probabilidad de éxito es 0.8, el odds sería:</p>
<p><span class="math display">\[
\text{odds} = \frac{0.8}{1 - 0.8} = 4
\]</span></p>
<p>Esto significa que el evento es <strong>4 veces más probable</strong> que no ocurra.</p>
<p>El <strong>odds ratio (OR)</strong> mide el cambio en los odds cuando una variable independiente aumenta en una unidad. Se calcula como el exponencial del coeficiente de la regresión logística:</p>
<p><span class="math display">\[
\text{OR} = e^{\beta}
\]</span></p>
<p><strong>Interpretación de OR:</strong></p>
<ul>
<li>Si <strong>OR &gt; 1</strong>, el evento es más probable a medida que aumenta la variable independiente.</li>
<li>Si <strong>OR &lt; 1</strong>, el evento es menos probable a medida que aumenta la variable independiente.</li>
<li>Si <strong>OR = 1</strong>, no hay efecto.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supongamos que ajustamos un modelo de regresión logística para predecir la probabilidad de tener diabetes en función del índice de masa corporal (BMI). El coeficiente asociado a <strong>BMI</strong> es 0.08.</p>
<p><span class="math display">\[
\text{OR} = e^{0.08} \approx 1.083
\]</span></p>
<p>Esto significa que por cada incremento de 1 unidad en el BMI, la <strong>odds</strong> de tener diabetes aumentan en un <strong>8.3%</strong>.</p>
</div>
</div>
</div>
</section>
<section id="bondad-de-ajuste-del-modelo-logístico" class="level3" data-number="6.5.4">
<h3 data-number="6.5.4" class="anchored" data-anchor-id="bondad-de-ajuste-del-modelo-logístico"><span class="header-section-number">6.5.4</span> Bondad de ajuste del modelo logístico</h3>
<p>La evaluación de la bondad de ajuste en regresión logística presenta desafíos únicos debido a la naturaleza binaria de la variable dependiente. A diferencia de la regresión lineal, donde el <span class="math inline">\(R^2\)</span> tradicional proporciona una medida directa de la varianza explicada, en la regresión logística necesitamos adoptar enfoques alternativos que se basen en la verosimilitud del modelo y que sean apropiados para datos categóricos.</p>
<p>La bondad de ajuste en regresión logística se evalúa principalmente a través de dos enfoques complementarios: la <strong>deviance</strong> y los <strong>pseudo R²</strong>. Ambos métodos nos permiten cuantificar qué tan bien nuestro modelo captura los patrones subyacentes en los datos binarios.</p>
<p>La <strong>deviance</strong> en regresión logística se calcula utilizando la distribución binomial subyacente. Para cada observación, comparamos la probabilidad que predice nuestro modelo con la “probabilidad perfecta” que asignaría un modelo saturado. Matemáticamente, esto se expresa como:</p>
<p><span class="math display">\[D = 2 \sum_{i=1}^{n} \left[ y_i \log\left(\frac{y_i}{\hat{p}_i}\right) + (1-y_i) \log\left(\frac{1-y_i}{1-\hat{p}_i}\right) \right]\]</span></p>
<p>donde <span class="math inline">\(y_i \in \{0,1\}\)</span> representa el resultado observado y <span class="math inline">\(\hat{p}_i\)</span> es la probabilidad estimada por nuestro modelo. Es importante notar que cuando <span class="math inline">\(y_i = 0\)</span> o <span class="math inline">\(y_i = 1\)</span>, algunos términos en esta expresión se anulan automáticamente, lo que refleja la naturaleza discreta de los datos binarios.</p>
<p>La interpretación de la deviance sigue principios similares a los discutidos anteriormente, pero es crucial recordar que ahora estamos tratando con datos binarios. La deviance nos ayuda a entender qué tan bien nuestro modelo logístico se ajusta a los datos de respuesta binaria en comparación con un modelo que simplemente predice la media.</p>
<p>Los <strong>pseudo R²</strong> son medidas alternativas que intentan capturar la proporción de variabilidad explicada por el modelo, similar al <span class="math inline">\(R^2\)</span> en regresión lineal, pero adaptadas a la naturaleza de los datos binarios y la verosimilitud del modelo. Estas medidas son útiles para evaluar y comparar modelos, aunque su interpretación no es tan directa como el <span class="math inline">\(R^2\)</span> tradicional.</p>
<p>El <strong>McFadden’s R²</strong> es quizás el más utilizado y se define como:</p>
<p><span class="math display">\[R^2_{\text{McFadden}} = 1 - \frac{\log L_{\text{modelo}}}{\log L_{\text{modelo nulo}}}\]</span></p>
<p>Este pseudo R² compara la log-verosimilitud de nuestro modelo con la de un modelo que solo incluye el intercepto. Los valores típicamente oscilan entre 0 y 1, aunque raramente alcanzan valores tan altos como el <span class="math inline">\(R^2\)</span> en regresión lineal. En contextos aplicados, valores de McFadden entre 0.2 y 0.4 se consideran indicativos de un buen ajuste.</p>
<p>El <strong>Nagelkerke R²</strong> representa una versión normalizada que garantiza que el valor máximo sea 1:</p>
<p><span class="math display">\[R^2_{\text{Nagelkerke}} = \frac{1 - \left(\frac{L_{\text{nulo}}}{L_{\text{modelo}}}\right)^{2/n}}{1 - (L_{\text{nulo}})^{2/n}}\]</span></p>
<p>Finalmente, el <strong>Cox-Snell R²</strong> se define como:</p>
<p><span class="math display">\[R^2_{\text{Cox-Snell}} = 1 - \left(\frac{L_{\text{nulo}}}{L_{\text{modelo}}}\right)^{2/n}\]</span></p>
<p>Aunque este último tiene la limitación de que su valor máximo teórico es menor que 1, razón por la cual Nagelkerke propuso su corrección.</p>
<p>Es crucial entender que estos pseudo R² no deben interpretarse exactamente como el <span class="math inline">\(R^2\)</span> tradicional. Mientras que en regresión lineal el <span class="math inline">\(R^2\)</span> representa la proporción de varianza explicada, en regresión logística estos índices reflejan más bien la mejora en la verosimilitud que aporta nuestro modelo comparado con el modelo nulo. Sin embargo, proporcionan una herramienta valiosa para evaluar y comparar diferentes especificaciones de modelo.</p>
<p>La evaluación integral de la bondad de ajuste en regresión logística requiere considerar tanto la deviance como los pseudo R² en conjunto, complementando esta información con pruebas de significancia global del modelo mediante tests de razón de verosimilitudes, que permiten determinar si la inclusión de las variables predictoras mejora significativamente el ajuste comparado con el modelo nulo.</p>
</section>
<section id="validación-del-modelo-logístico" class="level3" data-number="6.5.5">
<h3 data-number="6.5.5" class="anchored" data-anchor-id="validación-del-modelo-logístico"><span class="header-section-number">6.5.5</span> Validación del modelo logístico</h3>
<p>Una vez evaluada la bondad de ajuste del modelo logístico, el siguiente paso fundamental es validar su capacidad predictiva y su rendimiento en la clasificación de nuevas observaciones. La validación en regresión logística presenta características particulares debido a la naturaleza categórica de la variable dependiente, lo que requiere métricas y enfoques específicos que van más allá de las medidas tradicionales de error de predicción.</p>
<p>La validación del modelo logístico se centra en dos aspectos complementarios: la <strong>capacidad discriminativa</strong> del modelo (qué tan bien puede distinguir entre las dos clases) y la <strong>precisión de clasificación</strong> (qué proporción de predicciones son correctas). Estas evaluaciones se realizan típicamente mediante la construcción de una <strong>matriz de confusión</strong> y el análisis de curvas <strong>ROC</strong>.</p>
<p>La <strong>matriz de confusión</strong> constituye la herramienta fundamental para evaluar el rendimiento de clasificación en regresión logística. Esta matriz organiza las predicciones del modelo en una tabla de contingencia 2×2 que compara los resultados predichos con los valores reales observados. Para construir esta matriz, primero debemos convertir las probabilidades estimadas por el modelo en predicciones de clase mediante un umbral de decisión, típicamente 0.5.</p>
<p>La clasificación de cada observación resulta en una de cuatro categorías:</p>
<ul>
<li><strong>Verdaderos Positivos (VP):</strong> Predijo positivo y es positivo.</li>
<li><strong>Falsos Positivos (FP):</strong> Predijo positivo pero es negativo.</li>
<li><strong>Verdaderos Negativos (VN):</strong> Predijo negativo y es negativo.</li>
<li><strong>Falsos Negativos (FN):</strong> Predijo negativo pero es positivo.</li>
</ul>
<p>A partir de esta clasificación, podemos calcular métricas fundamentales de rendimiento:</p>
<ul>
<li><strong>Precisión (Accuracy):</strong> <span class="math inline">\(\frac{VP + VN}{\text{Total}}\)</span> - representa la proporción total de predicciones correctas</li>
<li><strong>Sensibilidad:</strong> <span class="math inline">\(\frac{VP}{VP + FN}\)</span> - mide la capacidad del modelo para identificar correctamente los casos positivos<br>
</li>
<li><strong>Especificidad:</strong> <span class="math inline">\(\frac{VN}{VN + FP}\)</span> - evalúa la capacidad para identificar correctamente los casos negativos</li>
</ul>
<p>Es importante reconocer que estas métricas pueden verse influenciadas por el umbral de decisión elegido y por el balance de clases en los datos. Un modelo puede tener alta precisión global pero pobre capacidad para detectar la clase minoritaria, especialmente en datasets desbalanceados.</p>
<p>La <strong>Curva ROC (Receiver Operating Characteristic)</strong> proporciona una evaluación más comprehensiva del rendimiento del modelo al examinar la relación entre la sensibilidad y la especificidad a través de todos los posibles umbrales de decisión. Esta curva grafica la tasa de verdaderos positivos contra la tasa de falsos positivos (1 - especificidad) para cada umbral posible.</p>
<p>Un modelo perfecto produciría una curva ROC que pasaría por la esquina superior izquierda del gráfico (100% sensibilidad, 0% falsos positivos), mientras que un modelo sin capacidad discriminativa produciría una línea diagonal de 45 grados. La <strong>AUC (Área Bajo la Curva ROC)</strong> cuantifica esta capacidad discriminativa en un solo número que varía entre 0.5 (sin capacidad discriminativa) y 1.0 (discriminación perfecta).</p>
<p>La interpretación de la AUC sigue convenciones establecidas:</p>
<ul>
<li><strong>0.9 - 1.0:</strong> Excelente discriminación</li>
<li><strong>0.8 - 0.9:</strong> Buena discriminación<br>
</li>
<li><strong>0.7 - 0.8:</strong> Discriminación aceptable</li>
<li><strong>0.6 - 0.7:</strong> Discriminación pobre</li>
<li><strong>0.5 - 0.6:</strong> Sin capacidad discriminativa útil</li>
</ul>
<p>La validación efectiva del modelo logístico requiere considerar tanto las métricas puntuales derivadas de la matriz de confusión como la capacidad discriminativa global capturada por la curva ROC y la AUC. Además, es crucial evaluar estas métricas tanto en los datos de entrenamiento como en conjuntos de validación independientes para detectar posibles problemas de sobreajuste y asegurar que el modelo generalizará adecuadamente a nuevos datos.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Vamos a aplicar la regresión logística en R utilizando el conjunto de datos <code>Pima.tr</code> del paquete <code>MASS</code>, que contiene información sobre mujeres pima y si tienen o no diabetes.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar la librería y el conjunto de datos</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Pima.tr)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar el modelo de regresión logística</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>modelo_logistico <span class="ot">&lt;-</span> <span class="fu">glm</span>(type <span class="sc">~</span> npreg <span class="sc">+</span> glu <span class="sc">+</span> bmi, <span class="at">data =</span> Pima.tr, <span class="at">family =</span> binomial)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen del modelo</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_logistico)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = type ~ npreg + glu + bmi, family = binomial, data = Pima.tr)

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -8.718723   1.411080  -6.179 6.46e-10 ***
npreg        0.149213   0.051833   2.879  0.00399 ** 
glu          0.033879   0.006327   5.355 8.55e-08 ***
bmi          0.094817   0.032405   2.926  0.00343 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 256.41  on 199  degrees of freedom
Residual deviance: 189.89  on 196  degrees of freedom
AIC: 197.89

Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicciones de probabilidad</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>predicciones_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_logistico, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Clasificación con un umbral de 0.5</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>predicciones_clase <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(predicciones_prob <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear matriz de confusión</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>tabla_confusion <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> predicciones_clase, <span class="at">Actual =</span> Pima.tr<span class="sc">$</span>type)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(tabla_confusion)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Actual
Predicted  No Yes
      No  114  29
      Yes  18  39</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular precisión</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tabla_confusion)) <span class="sc">/</span> <span class="fu">sum</span>(tabla_confusion)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Precisión:"</span>, <span class="fu">round</span>(accuracy, <span class="dv">3</span>)))</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Precisión: 0.765"</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar librería para curvas ROC</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Type 'citation("pROC")' for a citation.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'pROC'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:stats':

    cov, smooth, var</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Curva ROC</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>roc_obj <span class="ot">&lt;-</span> <span class="fu">roc</span>(Pima.tr<span class="sc">$</span>type, predicciones_prob)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = No, case = Yes</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting direction: controls &lt; cases</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(roc_obj, <span class="at">main =</span> <span class="st">"Curva ROC para Regresión Logística"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="tema5_files/figure-html/log1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular AUC</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>auc_valor <span class="ot">&lt;-</span> <span class="fu">auc</span>(roc_obj)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"AUC:"</span>, <span class="fu">round</span>(auc_valor, <span class="dv">3</span>)))</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "AUC: 0.831"</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="regresión-de-poisson" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="regresión-de-poisson"><span class="header-section-number">6.6</span> Regresión de Poisson</h2>
<p>La <strong>regresión de Poisson</strong> es una técnica estadística utilizada para modelar <strong>datos de conteo</strong>, es decir, situaciones en las que la variable dependiente representa el número de veces que ocurre un evento en un período de tiempo o espacio específico <span class="citation" data-cites="coxe2009analysis">(<a href="references.html#ref-coxe2009analysis" role="doc-biblioref">Coxe, West, y Aiken 2009</a>)</span>. Este tipo de modelo es adecuado cuando la variable dependiente toma valores enteros no negativos (<span class="math inline">\(0, 1, 2, \dots\)</span>) y sigue una distribución de <strong>Poisson</strong>.</p>
<p>La distribución de Poisson describe la probabilidad de que ocurra un número determinado de eventos en un intervalo fijo, dado que estos eventos ocurren de forma independiente y a una tasa constante.</p>
<p>La <strong>función de probabilidad</strong> de la distribución de Poisson es:</p>
<p><span class="math display">\[
P(Y = y) = \frac{e^{-\lambda} \lambda^y}{y!}
\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(Y\)</span> es la variable aleatoria que representa el número de eventos.</li>
<li><span class="math inline">\(\lambda\)</span> es la <strong>tasa media de ocurrencia</strong> de los eventos (esperanza de <span class="math inline">\(Y\)</span>).</li>
<li><span class="math inline">\(y\)</span> es el número de eventos observados (<span class="math inline">\(y = 0, 1, 2, \dots\)</span>).</li>
</ul>
<section id="modelo-de-regresión-de-poisson" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="modelo-de-regresión-de-poisson"><span class="header-section-number">6.6.1</span> Modelo de regresión de Poisson</h3>
<p>En la <strong>regresión de Poisson</strong>, el objetivo es modelar la relación entre la <strong>tasa de ocurrencia de los eventos</strong> (<span class="math inline">\(\lambda\)</span>) y un conjunto de variables predictoras <span class="math inline">\(X_1, X_2, \dots, X_p\)</span>.</p>
<p>La <strong>forma funcional</strong> del modelo de Poisson es:</p>
<p><span class="math display">\[
\log(\lambda) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\log(\lambda)\)</span> es la <strong>función de enlace logarítmica</strong> que asegura que la tasa <span class="math inline">\(\lambda\)</span> sea siempre positiva.</li>
<li><span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span> son los coeficientes del modelo que describen la influencia de cada predictor sobre la tasa de eventos.</li>
</ul>
<p>El modelo puede expresarse en términos de la <strong>tasa esperada de eventos</strong> como:</p>
<p><span class="math display">\[
\lambda = e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p}
\]</span></p>
</section>
<section id="supuestos-y-limitaciones-de-la-regresión-de-poisson" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2" class="anchored" data-anchor-id="supuestos-y-limitaciones-de-la-regresión-de-poisson"><span class="header-section-number">6.6.2</span> Supuestos y limitaciones de la regresión de Poisson</h3>
<p>Tal y como ocurre en el modelo de regresión lineal, para que la regresión de Poisson sea adecuada, se deben cumplir ciertos <strong>supuestos</strong>:</p>
<ul>
<li><p><strong>Independencia de los eventos:</strong> Los eventos deben ocurrir de manera independiente unos de otros.</p></li>
<li><p><strong>Distribución de Poisson de la variable dependiente:</strong> La variable de respuesta debe seguir una distribución de Poisson, donde la <strong>media</strong> y la <strong>varianza</strong> son iguales:</p></li>
</ul>
<p><span class="math display">\[
   E(Y) = Var(Y) = \lambda
   \]</span></p>
<ul>
<li><p><strong>No sobredispersión:</strong> Uno de los problemas comunes en los datos de conteo es la <strong>sobredispersión</strong>, que ocurre cuando la varianza de los datos es mayor que la media (<span class="math inline">\(Var(Y) &gt; E(Y)\)</span>). La presencia de sobredispersión indica que el modelo de Poisson puede no ser adecuado, y puede ser necesario considerar modelos alternativos como la <strong>regresión binomial negativa</strong>.</p></li>
<li><p><strong>No exceso de ceros:</strong> Si hay demasiados ceros en los datos (por ejemplo, en el número de accidentes en diferentes localidades donde muchas tienen cero accidentes), puede ser necesario utilizar modelos de <strong>Poisson inflados en ceros (ZIP)</strong> <span class="citation" data-cites="lambert1992zero">(<a href="references.html#ref-lambert1992zero" role="doc-biblioref">Lambert 1992</a>)</span>.</p></li>
</ul>
</section>
<section id="interpretación-de-los-resultados" class="level3" data-number="6.6.3">
<h3 data-number="6.6.3" class="anchored" data-anchor-id="interpretación-de-los-resultados"><span class="header-section-number">6.6.3</span> Interpretación de los resultados</h3>
<p>La interpretación de los coeficientes en la regresión de Poisson difiere de la regresión lineal debido al uso de la función de enlace logarítmica.</p>
<p>Los coeficientes <span class="math inline">\(\beta\)</span> representan el <strong>logaritmo de la tasa</strong> de eventos asociados con un cambio en la variable independiente. Para interpretar en términos de la tasa de ocurrencia, se utiliza el <strong>exponencial de los coeficientes</strong>:</p>
<p><span class="math display">\[
  e^{\beta_i}
\]</span></p>
<p>Esto representa el <strong>factor de cambio multiplicativo</strong> en la tasa de eventos por cada unidad adicional en la variable <span class="math inline">\(X_i\)</span>.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Interpretando el coeficiente de Poisson: Incidence Rate Ratio (IRR)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Importante</span>Interpretando el coeficiente de Poisson: Incidence Rate Ratio (IRR)
</div>
</div>
<div class="callout-body-container callout-body">
<p>En la regresión de Poisson, el coeficiente <span class="math inline">\(\beta_j\)</span> está en la escala logarítmica de la tasa. Para una interpretación práctica, lo exponenciamos para obtener el <strong>Incidence Rate Ratio (IRR)</strong>:</p>
<p><span class="math display">\[
\text{IRR} = e^{\beta_j}
\]</span></p>
<p>El IRR es un <strong>factor multiplicativo</strong> que nos dice cuánto cambia la tasa de eventos esperada por cada incremento de una unidad en el predictor <span class="math inline">\(X_j\)</span>.</p>
<ul>
<li><strong>Si IRR &gt; 1</strong>: Un incremento en <span class="math inline">\(X_j\)</span> se asocia con un <strong>aumento</strong> en la tasa de eventos. Un IRR de 1.25 significa que por cada unidad que aumenta <span class="math inline">\(X_j\)</span>, la tasa de eventos esperada se multiplica por 1.25 (es decir, aumenta un 25%).</li>
<li><strong>Si IRR &lt; 1</strong>: Un incremento en <span class="math inline">\(X_j\)</span> se asocia con una <strong>disminución</strong> en la tasa de eventos. Un IRR de 0.80 significa que por cada unidad que aumenta <span class="math inline">\(X_j\)</span>, la tasa de eventos esperada se multiplica por 0.80 (es decir, disminuye un 20%).</li>
<li><strong>Si IRR = 1</strong>: La variable <span class="math inline">\(X_j\)</span> no tiene efecto sobre la tasa de eventos.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Vamos a utilizar R para ajustar un modelo de regresión de Poisson. Supongamos que tenemos datos sobre el <strong>número de accidentes de tráfico</strong> en diferentes intersecciones de una ciudad, junto con variables como el volumen de tráfico y la visibilidad.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación de datos para el número de accidentes</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)  <span class="co"># Seed diferente para evitar duplicación</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Número de observaciones</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables predictoras</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>trafico_nuevo <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">1000</span>, <span class="at">sd =</span> <span class="dv">300</span>)  <span class="co"># Volumen de tráfico en vehículos por día</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>visibilidad_nueva <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)   <span class="co"># Visibilidad en kilómetros</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar la tasa de accidentes (lambda) usando un modelo logarítmico</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>lambda_nuevo <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fl">0.01</span> <span class="sc">*</span> trafico_nuevo <span class="sc">-</span> <span class="fl">0.2</span> <span class="sc">*</span> visibilidad_nueva)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar el número de accidentes como una variable de Poisson</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>accidentes_nuevo <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> lambda_nuevo)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear el data frame</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>datos_ejemplo <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">accidentes =</span> accidentes_nuevo, <span class="at">trafico =</span> trafico_nuevo, <span class="at">visibilidad =</span> visibilidad_nueva)</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(datos_ejemplo)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  accidentes   trafico visibilidad
1        140  596.9436    5.236303
2      37153 1186.5327    6.739805
3      92909 1240.2624    4.816128
4        117  583.3323    5.137798
5       1793  785.6929    1.635146
6       1935  902.7817    7.233911</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar el modelo de regresión de Poisson</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>modelo_ejemplo <span class="ot">&lt;-</span> <span class="fu">glm</span>(accidentes <span class="sc">~</span> trafico <span class="sc">+</span> visibilidad, <span class="at">data =</span> datos_ejemplo, <span class="at">family =</span> poisson)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen del modelo</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_ejemplo)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = accidentes ~ trafico + visibilidad, family = poisson, 
    data = datos_ejemplo)

Coefficients:
              Estimate Std. Error   z value Pr(&gt;|z|)    
(Intercept)  9.607e-04  2.316e-03     0.415    0.678    
trafico      9.999e-03  1.360e-06  7350.127   &lt;2e-16 ***
visibilidad -2.000e-01  1.012e-04 -1976.897   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 1.6856e+08  on 99  degrees of freedom
Residual deviance: 8.9300e+01  on 97  degrees of freedom
AIC: 1220.4

Number of Fisher Scoring iterations: 3</code></pre>
</div>
</div>
<p>El coeficiente asociado a <code>trafico</code> indica cómo el volumen de tráfico afecta la tasa de accidentes.</p>
<p>El coeficiente asociado a <code>visibilidad</code> muestra cómo la visibilidad afecta la frecuencia de accidentes.</p>
</div>
</div>
</div>
</section>
<section id="estimación-por-máxima-verosimilitud-en-regresión-de-poisson" class="level3" data-number="6.6.4">
<h3 data-number="6.6.4" class="anchored" data-anchor-id="estimación-por-máxima-verosimilitud-en-regresión-de-poisson"><span class="header-section-number">6.6.4</span> Estimación por máxima verosimilitud en regresión de Poisson</h3>
<p>La estimación de parámetros en regresión de Poisson utiliza también el método de máxima verosimilitud, pero adaptado específicamente para la distribución de Poisson con función de enlace logarítmica. Este enfoque garantiza que las estimaciones aprovechen de manera óptima la información contenida en los datos de conteo.</p>
<p>Para una muestra de <span class="math inline">\(n\)</span> observaciones independientes, donde <span class="math inline">\(y_i\)</span> representa el conteo de eventos para la observación <span class="math inline">\(i\)</span>, la <strong>función de verosimilitud</strong> se define como:</p>
<p><span class="math display">\[L(\boldsymbol{\beta}) = \prod_{i=1}^{n} \frac{e^{-\lambda_i} \lambda_i^{y_i}}{y_i!}\]</span></p>
<p>donde <span class="math inline">\(\lambda_i = e^{\mathbf{x}_i^T\boldsymbol{\beta}}\)</span> es la tasa esperada para la observación <span class="math inline">\(i\)</span>.</p>
<p>La <strong>log-verosimilitud</strong> correspondiente es:</p>
<p><span class="math display">\[\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[y_i \log(\lambda_i) - \lambda_i - \log(y_i!)\right]\]</span></p>
<p>Sustituyendo <span class="math inline">\(\lambda_i = e^{\mathbf{x}_i^T\boldsymbol{\beta}}\)</span>:</p>
<p><span class="math display">\[\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[y_i \mathbf{x}_i^T\boldsymbol{\beta} - e^{\mathbf{x}_i^T\boldsymbol{\beta}} - \log(y_i!)\right]\]</span></p>
<p>Para encontrar los valores de <span class="math inline">\(\boldsymbol{\beta}\)</span> que maximizan la log-verosimilitud, derivamos respecto a cada parámetro:</p>
<p><span class="math display">\[\frac{\partial \ell}{\partial \beta_j} = \sum_{i=1}^{n} x_{ij}(y_i - \lambda_i) = 0\]</span></p>
<p>Esta ecuación indica que los estimadores de máxima verosimilitud se obtienen cuando la suma de los residuos (observado menos esperado) ponderados por cada variable predictora es cero.</p>
<section id="implementación-del-algoritmo-irls-1" class="level4" data-number="6.6.4.1">
<h4 data-number="6.6.4.1" class="anchored" data-anchor-id="implementación-del-algoritmo-irls-1"><span class="header-section-number">6.6.4.1</span> Implementación del algoritmo IRLS</h4>
<p>Dado que las ecuaciones de verosimilitud no tienen solución analítica cerrada, se utiliza el algoritmo IRLS adaptado para regresión de Poisson. Los elementos específicos son:</p>
<p><strong>Pesos:</strong> <span class="math display">\[w_i = \lambda_i\]</span></p>
<p><strong>Variable dependiente ajustada:</strong> <span class="math display">\[z_i = \log(\lambda_i^{(t)}) + \frac{y_i - \lambda_i^{(t)}}{\lambda_i^{(t)}}\]</span></p>
<p><strong>Actualización de parámetros:</strong> <span class="math display">\[\boldsymbol{\beta}^{(t+1)} = (\mathbf{X}^T \mathbf{W}^{(t)} \mathbf{X})^{-1} \mathbf{X}^T \mathbf{W}^{(t)} \mathbf{z}^{(t)}\]</span></p>
</section>
<section id="propiedades-específicas-de-la-estimación-poisson" class="level4" data-number="6.6.4.2">
<h4 data-number="6.6.4.2" class="anchored" data-anchor-id="propiedades-específicas-de-la-estimación-poisson"><span class="header-section-number">6.6.4.2</span> Propiedades específicas de la estimación Poisson</h4>
<p>La estimación por máxima verosimilitud en regresión de Poisson tiene características particulares que la distinguen de otros GLMs:</p>
<ol type="1">
<li><p><strong>Equidispersión</strong>: El modelo asume que <span class="math inline">\(E(Y_i) = \text{Var}(Y_i) = \lambda_i\)</span>, lo que significa que la varianza aumenta linealmente con la media.</p></li>
<li><p><strong>Convergencia</strong>: Generalmente requiere menos iteraciones que la regresión logística debido a la naturaleza más estable de la función de enlace logarítmica.</p></li>
<li><p><strong>Estabilidad numérica</strong>: La función de enlace logarítmica garantiza automáticamente que <span class="math inline">\(\lambda_i &gt; 0\)</span>, evitando problemas de valores negativos en las tasas estimadas.</p></li>
<li><p><strong>Interpretación multiplicativa</strong>: Los coeficientes se interpretan como efectos multiplicativos sobre la tasa, lo que es natural para datos de conteo.</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo: Estimación paso a paso en regresión de Poisson">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo: Estimación paso a paso en regresión de Poisson
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demostración del proceso de estimación por máxima verosimilitud</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Usar los datos simulados anteriores</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>trafico <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">1000</span>, <span class="at">sd =</span> <span class="dv">300</span>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>visibilidad <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.001</span><span class="sc">*</span>trafico <span class="sc">-</span> <span class="fl">0.2</span><span class="sc">*</span>visibilidad)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>accidentes <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, lambda)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>datos_accidentes <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(accidentes, trafico, visibilidad)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para calcular log-verosimilitud manualmente</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>log_likelihood_poisson <span class="ot">&lt;-</span> <span class="cf">function</span>(beta, X, y) {</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>  eta <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>  lambda <span class="ot">&lt;-</span> <span class="fu">exp</span>(eta)</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(y <span class="sc">*</span> <span class="fu">log</span>(lambda) <span class="sc">-</span> lambda <span class="sc">-</span> <span class="fu">lgamma</span>(y <span class="sc">+</span> <span class="dv">1</span>))</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparar datos</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(accidentes <span class="sc">~</span> trafico <span class="sc">+</span> visibilidad, <span class="at">data =</span> datos_accidentes)</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> datos_accidentes<span class="sc">$</span>accidentes</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste con glm</span></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>modelo_glm_pois <span class="ot">&lt;-</span> <span class="fu">glm</span>(accidentes <span class="sc">~</span> trafico <span class="sc">+</span> visibilidad, </span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> datos_accidentes, <span class="at">family =</span> poisson)</span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>beta_glm_pois <span class="ot">&lt;-</span> <span class="fu">coef</span>(modelo_glm_pois)</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"=== ESTIMACIÓN POR MÁXIMA VEROSIMILITUD - POISSON ===</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== ESTIMACIÓN POR MÁXIMA VEROSIMILITUD - POISSON ===</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Coeficientes estimados por glm():</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coeficientes estimados por glm():</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_glm_pois)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     trafico visibilidad 
-5.75588458  0.00284373  0.13082078 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar optimización</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>ll_optimo_pois <span class="ot">&lt;-</span> <span class="fu">log_likelihood_poisson</span>(beta_glm_pois, X, y)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Log-verosimilitud en el óptimo:"</span>, <span class="fu">round</span>(ll_optimo_pois, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Log-verosimilitud en el óptimo: -39.65 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretación multiplicativa</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Interpretación multiplicativa (exp(coeficientes)):</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Interpretación multiplicativa (exp(coeficientes)):</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>exp_coefs <span class="ot">&lt;-</span> <span class="fu">exp</span>(beta_glm_pois)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(exp_coefs)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     trafico visibilidad 
0.003164106 1.002847777 1.139763495 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Interpretación:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Interpretación:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"- Intercepto: Tasa base ="</span>, <span class="fu">round</span>(exp_coefs[<span class="dv">1</span>], <span class="dv">4</span>), <span class="st">"accidentes</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>- Intercepto: Tasa base = 0.0032 accidentes</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"- Tráfico: Por cada vehículo adicional, la tasa se multiplica por"</span>, <span class="fu">round</span>(exp_coefs[<span class="dv">2</span>], <span class="dv">6</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>- Tráfico: Por cada vehículo adicional, la tasa se multiplica por 1.002848 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"- Visibilidad: Por cada km adicional de visibilidad, la tasa se multiplica por"</span>, <span class="fu">round</span>(exp_coefs[<span class="dv">3</span>], <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>- Visibilidad: Por cada km adicional de visibilidad, la tasa se multiplica por 1.1398 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Información de convergencia</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Información del algoritmo IRLS:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Información del algoritmo IRLS:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Iteraciones necesarias:"</span>, modelo_glm_pois<span class="sc">$</span>iter, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteraciones necesarias: 6 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"¿Convergió?"</span>, modelo_glm_pois<span class="sc">$</span>converged, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>¿Convergió? TRUE </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar supuesto de equidispersión</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>media_y <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>var_y <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Verificación de equidispersión:</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Verificación de equidispersión:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Media observada:"</span>, <span class="fu">round</span>(media_y, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Media observada: 0.15 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Varianza observada:"</span>, <span class="fu">round</span>(var_y, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Varianza observada: 0.149 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Razón varianza/media:"</span>, <span class="fu">round</span>(var_y<span class="sc">/</span>media_y, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Razón varianza/media: 0.993 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="bondad-de-ajuste-en-la-regresión-de-poisson" class="level3" data-number="6.6.5">
<h3 data-number="6.6.5" class="anchored" data-anchor-id="bondad-de-ajuste-en-la-regresión-de-poisson"><span class="header-section-number">6.6.5</span> Bondad de ajuste en la regresión de Poisson</h3>
<p>Al igual que en la regresión logística, la bondad de ajuste en los modelos de Poisson se aleja del <span class="math inline">\(R^2\)</span> tradicional y se centra en medidas basadas en la verosimilitud. El objetivo es cuantificar si el modelo captura adecuadamente la estructura de los datos de conteo.</p>
<p>La <strong>deviance</strong> sigue siendo la métrica fundamental. Para la regresión de Poisson, se calcula comparando la log-verosimilitud del modelo ajustado con la de un modelo saturado (donde <span class="math inline">\(\hat{\mu}_i = y_i\)</span>). La fórmula específica es: <span class="math display">\[D = 2 \sum_{i=1}^{n} \left[ y_i \log\left(\frac{y_i}{\hat{\mu}_i}\right) - (y_i - \hat{\mu}_i) \right]\]</span> Donde el término <span class="math inline">\(y_i \log(y_i)\)</span> se considera cero si <span class="math inline">\(y_i = 0\)</span>. Al igual que en otros GLMs, la deviance es clave para comparar modelos anidados mediante el <strong>Test de la Razón de Verosimilitudes (LRT)</strong>.</p>
<p>Sin embargo, para los modelos de Poisson, la prueba de bondad de ajuste más importante en la práctica es la evaluación de la <strong>sobredispersión</strong>. Un buen ajuste del modelo de Poisson implica que se cumple el supuesto de equidispersión (<span class="math inline">\(Var(Y) = \mu\)</span>). Por lo tanto, el <strong>estadístico de dispersión</strong> (<span class="math inline">\(\hat{\phi}\)</span>) se convierte en una medida de facto de la bondad de ajuste: <span class="math display">\[\hat{\phi} = \frac{X^2_{\text{Pearson}}}{n-p}\]</span> Un valor de <span class="math inline">\(\hat{\phi}\)</span> cercano a 1 indica que el supuesto de la distribución de Poisson se cumple y que el ajuste del modelo es adecuado. Si <span class="math inline">\(\hat{\phi}\)</span> es significativamente mayor que 1, el modelo no se ajusta bien a la variabilidad de los datos, y este es el principal indicador para buscar alternativas como la regresión binomial negativa.</p>
<p>Aunque los <strong>pseudo R²</strong> (como el de McFadden) pueden calcularse, son menos utilizados e informativos en el contexto de la regresión de Poisson en comparación con el análisis de la dispersión.</p>
</section>
<section id="validación-del-modelo-de-poisson" class="level3" data-number="6.6.6">
<h3 data-number="6.6.6" class="anchored" data-anchor-id="validación-del-modelo-de-poisson"><span class="header-section-number">6.6.6</span> Validación del modelo de Poisson</h3>
<p>A diferencia de la regresión logística, donde la validación se centra en la capacidad de <em>clasificación</em>, la validación de un modelo de Poisson se enfoca en su <strong>capacidad de predicción</strong>: ¿qué tan cerca están los conteos predichos por el modelo de los conteos reales observados?</p>
<p>El proceso de validación suele implicar la división de los datos en un conjunto de <strong>entrenamiento (train)</strong> y uno de <strong>prueba (test)</strong>. El modelo se ajusta con los datos de entrenamiento y su rendimiento predictivo se evalúa sobre los datos de prueba, que el modelo no ha visto antes. Esto nos da una estimación honesta de cómo generalizará el modelo a nuevos datos.</p>
<p>Las métricas de validación principales para modelos de conteo son:</p>
<ul>
<li><p><strong>Raíz del Error Cuadrático Medio (RMSE):</strong> Es una de las métricas más comunes y mide la desviación estándar de los residuos. Penaliza más los errores grandes. <span class="math display">\[
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{\mu}_i)^2}
\]</span></p></li>
<li><p><strong>Error Absoluto Medio (MAE):</strong> Mide la magnitud promedio de los errores, siendo menos sensible a valores atípicos que el RMSE. <span class="math display">\[
\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{\mu}_i|
\]</span></p></li>
</ul>
<p>Ambas métricas se expresan en las mismas unidades que la variable de respuesta (por ejemplo, “accidentes”, “compras”), lo que facilita su interpretación. Un modelo con valores de RMSE y MAE más bajos en el conjunto de prueba se considera que tiene un mejor rendimiento predictivo.</p>
<p>Una herramienta visual clave para la validación es el <strong>gráfico de valores predichos vs.&nbsp;valores reales</strong> en el conjunto de prueba. En un modelo con buena capacidad predictiva, los puntos deberían agruparse cerca de la línea diagonal <span class="math inline">\(y=x\)</span>, indicando que las predicciones (<span class="math inline">\(\hat{\mu}_i\)</span>) son cercanas a los valores observados (<span class="math inline">\(y_i\)</span>).</p>
</section>
</section>
<section id="otros-glms" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="otros-glms"><span class="header-section-number">6.7</span> Otros GLMs</h2>
<p>La <strong>regresión binomial negativa</strong> y los <strong>modelos basados en distribuciones como Gamma e Inversa Gaussiana</strong> amplían la capacidad de los <strong>Modelos Lineales Generalizados (GLM)</strong> para adaptarse a una amplia variedad de situaciones del mundo real. Estos modelos son especialmente útiles cuando los datos presentan características como sobredispersión, sesgo o restricciones en el dominio (por ejemplo, solo valores positivos). La elección adecuada del modelo y la función de enlace garantiza predicciones precisas y válidas, contribuyendo a la toma de decisiones informadas en campos como la salud, la ingeniería y la economía.</p>
<section id="regresión-binomial-negativa" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="regresión-binomial-negativa"><span class="header-section-number">6.7.1</span> Regresión binomial negativa</h3>
<p>Tal y como hemos visto en apartados anteriores, la <strong>sobredispersión</strong> ocurre cuando la varianza de los datos de conteo es <strong>mayor que la media</strong>, lo cual viola uno de los supuestos clave de la regresión de Poisson, que asume que la media y la varianza son iguales (<span class="math inline">\(E(Y) = Var(Y) = \lambda\)</span>). La sobredispersión puede surgir por varias razones:</p>
<ul>
<li><strong>Heterogeneidad no modelada:</strong> Existen factores que afectan la variable dependiente pero no han sido incluidos en el modelo.</li>
<li><strong>Dependencia entre eventos:</strong> Los eventos no ocurren de forma independiente.</li>
<li><strong>Exceso de ceros:</strong> Hay más ceros en los datos de los que predice la distribución de Poisson.</li>
</ul>
<p>Cuando la sobredispersión está presente, la regresión de Poisson subestima los errores estándar, lo que puede llevar a conclusiones incorrectas sobre la significancia de los predictores.</p>
<p>La <strong>regresión binomial negativa</strong> es una extensión de la regresión de Poisson que introduce un parámetro adicional para manejar la sobredispersión. Este modelo permite que la varianza sea mayor que la media:</p>
<p><span class="math display">\[
Var(Y) = \lambda + \alpha \lambda^2
\]</span></p>
<p>Donde <span class="math inline">\(\alpha\)</span> es el parámetro de dispersión. Si <span class="math inline">\(\alpha = 0\)</span>, el modelo se reduce a la regresión de Poisson.</p>
<p>La forma funcional del modelo binomial negativo es similar al de Poisson:</p>
<p><span class="math display">\[
\log(\lambda) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p
\]</span></p>
<p>Pero la varianza ahora incluye el término adicional <span class="math inline">\(\alpha\)</span> para capturar la sobredispersión.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instalar y cargar la librería MASS que contiene la función glm.nb</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Usar los datos de accidentes del ejemplo anterior</span></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste de un modelo binomial negativo</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>modelo_binom_neg <span class="ot">&lt;-</span> <span class="fu">glm.nb</span>(accidentes <span class="sc">~</span> trafico <span class="sc">+</span> visibilidad, <span class="at">data =</span> datos_accidentes)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
control$trace &gt; : iteration limit reached
Warning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
control$trace &gt; : iteration limit reached</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen del modelo</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_binom_neg)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm.nb(formula = accidentes ~ trafico + visibilidad, data = datos_accidentes, 
    init.theta = 2158.536301, link = log)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -5.7560791  1.5223127  -3.781 0.000156 ***
trafico      0.0028439  0.0009831   2.893 0.003818 ** 
visibilidad  0.1308306  0.1402185   0.933 0.350795    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Negative Binomial(2158.536) family taken to be 1)

    Null deviance: 59.679  on 99  degrees of freedom
Residual deviance: 50.680  on 97  degrees of freedom
AIC: 87.301

Number of Fisher Scoring iterations: 1

              Theta:  2159 
          Std. Err.:  49427 
Warning while fitting theta: iteration limit reached 

 2 x log-likelihood:  -79.301 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparar la dispersión con el modelo de Poisson</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Dispersión en Poisson (deviance/df.residual):"</span>, <span class="fu">round</span>(modelo_glm_pois<span class="sc">$</span>deviance <span class="sc">/</span> modelo_glm_pois<span class="sc">$</span>df.residual, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dispersión en Poisson (deviance/df.residual): 0.523 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Parámetro theta en Binomial Negativa:"</span>, <span class="fu">round</span>(modelo_binom_neg<span class="sc">$</span>theta, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parámetro theta en Binomial Negativa: 2158.536 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparar AIC</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AIC Poisson:"</span>, <span class="fu">round</span>(<span class="fu">AIC</span>(modelo_glm_pois), <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>AIC Poisson: 85.3 </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"AIC Binomial Negativa:"</span>, <span class="fu">round</span>(<span class="fu">AIC</span>(modelo_binom_neg), <span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>AIC Binomial Negativa: 87.3 </code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>Interpretación del parámetro <span class="math inline">\(\theta\)</span> en binomial negativa:</strong></p>
<ul>
<li>El parámetro <span class="math inline">\(\theta\)</span> controla el grado de sobredispersión en el modelo</li>
<li><strong>Valores altos de <span class="math inline">\(\theta\)</span></strong> (ej: <span class="math inline">\(\theta &gt; 100\)</span>): Poca sobredispersión, el modelo se aproxima a Poisson</li>
<li><strong>Valores bajos de <span class="math inline">\(\theta\)</span></strong> (ej: <span class="math inline">\(\theta &lt; 10\)</span>): Mucha sobredispersión, diferencia significativa respecto a Poisson</li>
<li><strong>Regla práctica</strong>: Si <span class="math inline">\(\theta\)</span> es pequeño, confirma que había sobredispersión y que el modelo binomial negativa es más apropiado que Poisson</li>
</ul>
<p><strong>Comparación de modelos:</strong></p>
<ul>
<li>Si AIC de binomial negativa &lt; AIC de Poisson → preferir binomial negativa</li>
<li>El modelo binomial negativa corrige la subestimación de errores estándar que ocurre en Poisson con sobredispersión</li>
</ul>
</section>
<section id="modelos-para-variables-continuas-no-normales" class="level3" data-number="6.7.2">
<h3 data-number="6.7.2" class="anchored" data-anchor-id="modelos-para-variables-continuas-no-normales"><span class="header-section-number">6.7.2</span> Modelos para variables continuas no normales</h3>
<p>Existen situaciones en las que la variable dependiente es <strong>continua</strong>, pero <strong>no sigue una distribución normal</strong>. En estos casos, los <strong>Modelos Lineales Generalizados (GLM)</strong> permiten utilizar distribuciones alternativas como <strong>Gamma</strong> o <strong>Inversa Gaussiana</strong>, junto con funciones de enlace específicas.</p>
<section id="regresión-gamma-para-datos-positivos-y-sesgados" class="level4" data-number="6.7.2.1">
<h4 data-number="6.7.2.1" class="anchored" data-anchor-id="regresión-gamma-para-datos-positivos-y-sesgados"><span class="header-section-number">6.7.2.1</span> Regresión gamma para datos positivos y sesgados</h4>
<p>La <strong>regresión Gamma</strong> es adecuada para modelar variables continuas que son <strong>positivas</strong> y tienen una distribución <strong>sesgada a la derecha</strong>. Ejemplos típicos incluyen tiempos de espera, costos médicos o duración de procesos.</p>
<ul>
<li>La distribución Gamma asume que la variable dependiente es continua y positiva.</li>
<li>La varianza de la variable dependiente aumenta proporcionalmente al cuadrado de la media.</li>
</ul>
<p><strong>Función de Enlace Común:</strong> <span class="math display">\[\log(\mu) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación de costos médicos</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>ingresos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">50000</span>, <span class="at">sd =</span> <span class="dv">10000</span>)</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>edad <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">45</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>costos <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(n, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">rate =</span> <span class="fl">0.00005</span> <span class="sc">*</span> ingresos <span class="sc">+</span> <span class="fl">0.01</span> <span class="sc">*</span> edad)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste del modelo Gamma</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>modelo_gamma <span class="ot">&lt;-</span> <span class="fu">glm</span>(costos <span class="sc">~</span> ingresos <span class="sc">+</span> edad, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> <span class="st">"log"</span>))</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen del modelo</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_gamma)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = costos ~ ingresos + edad, family = Gamma(link = "log"))

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)  3.440e-01  5.294e-01   0.650   0.5173  
ingresos    -1.807e-05  7.804e-06  -2.316   0.0227 *
edad         3.584e-03  7.366e-03   0.487   0.6277  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Gamma family taken to be 0.5010938)

    Null deviance: 60.771  on 99  degrees of freedom
Residual deviance: 58.345  on 97  degrees of freedom
AIC: 105.47

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
<ul>
<li>Los coeficientes muestran cómo los ingresos y la edad afectan los costos médicos esperados.</li>
<li>El enlace logarítmico asegura que las predicciones sean siempre positivas.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="regresión-inversa-gaussiana" class="level4" data-number="6.7.2.2">
<h4 data-number="6.7.2.2" class="anchored" data-anchor-id="regresión-inversa-gaussiana"><span class="header-section-number">6.7.2.2</span> Regresión inversa gaussiana</h4>
<p>La <strong>regresión Inversa Gaussiana</strong> es útil para modelar tiempos de respuesta o variables donde la varianza disminuye rápidamente a medida que la media aumenta. Este modelo se aplica en campos como la ingeniería, donde se analizan tiempos hasta fallas de sistemas.</p>
<p><strong>Función de Enlace Común:</strong> <span class="math display">\[\frac{1}{\mu^2} = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instalar y cargar la librería correcta</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(statmod)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación de datos</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>carga_trabajo <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar tiempos hasta el fallo usando la distribución inversa gaussiana</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Aseguramos que los valores de carga_trabajo sean positivos para evitar problemas numéricos</span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>carga_trabajo[carga_trabajo <span class="sc">&lt;=</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>tiempo_fallo <span class="ot">&lt;-</span> <span class="fu">rinvgauss</span>(n, <span class="at">mean =</span> <span class="dv">100</span> <span class="sc">/</span> carga_trabajo, <span class="at">dispersion =</span> <span class="dv">1</span>)</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste del modelo Inversa Gaussiana con enlace logarítmico</span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>modelo_inversa_gauss <span class="ot">&lt;-</span> <span class="fu">glm</span>(tiempo_fallo <span class="sc">~</span> carga_trabajo, <span class="at">family =</span> <span class="fu">inverse.gaussian</span>(<span class="at">link =</span> <span class="st">"1/mu^2"</span>),<span class="at">start =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.01</span>))</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in sqrt(eta): NaNs produced</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: step size truncated due to divergence</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen del modelo</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_inversa_gauss)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = tiempo_fallo ~ carga_trabajo, family = inverse.gaussian(link = "1/mu^2"), 
    start = c(0.01, 0.01))

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)   -0.106143   0.462230  -0.230    0.819
carga_trabajo  0.008261   0.009623   0.859    0.393

(Dispersion parameter for inverse.gaussian family taken to be 1.348442)

    Null deviance: 94.085  on 99  degrees of freedom
Residual deviance: 93.171  on 98  degrees of freedom
AIC: 294.2

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled" title="¿Qué GLM debo usar?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Advertencia</span>¿Qué GLM debo usar?
</div>
</div>
<div class="callout-body-container callout-body">
<p>La elección del modelo correcto depende casi exclusivamente de la naturaleza de tu variable respuesta (<span class="math inline">\(Y\)</span>). Aquí tienes una guía rápida:</p>
<ul>
<li><strong>¿Tu variable respuesta es binaria (Sí/No, 0/1, Éxito/Fracaso)?</strong>
<ul>
<li>Usa <strong>Regresión Logística</strong>.</li>
</ul></li>
<li><strong>¿Tu variable respuesta es un conteo de eventos (nº de accidentes, nº de clientes, nº de fallos)?</strong>
<ul>
<li>Empieza con una <strong>Regresión de Poisson</strong>.</li>
<li><strong>Importante:</strong> Después de ajustar el modelo, comprueba si hay <strong>sobredispersión</strong>.</li>
<li>Si la hay (estadístico de dispersión <span class="math inline">\(\hat{\phi} &gt; 1.5\)</span> o la teoría lo sugiere), cambia a una <strong>Regresión Binomial Negativa</strong>.</li>
</ul></li>
<li><strong>¿Tu variable respuesta es continua y estrictamente positiva, con una distribución asimétrica hacia la derecha (ej. tiempos, costos, reclamaciones de seguros)?</strong>
<ul>
<li>Usa <strong>Regresión Gamma</strong>. Es una excelente alternativa a transformar la variable con logaritmos y usar un modelo lineal.</li>
</ul></li>
<li><strong>¿Tu variable respuesta es un tiempo hasta un evento y tiene una asimetría muy pronunciada?</strong>
<ul>
<li>Considera una <strong>Regresión Inversa Gaussiana</strong>.</li>
</ul></li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-coxe2009analysis" class="csl-entry" role="listitem">
Coxe, Stefany, Stephen G West, y Leona S Aiken. 2009. <span>«The analysis of count data: A gentle introduction to Poisson regression and its alternatives»</span>. <em>Journal of personality assessment</em> 91 (2): 121-36.
</div>
<div id="ref-hosmer2013applied" class="csl-entry" role="listitem">
Hosmer Jr, David W, Stanley Lemeshow, y Rodney X Sturdivant. 2013. <em>Applied logistic regression</em>. John Wiley &amp; Sons.
</div>
<div id="ref-lambert1992zero" class="csl-entry" role="listitem">
Lambert, Diane. 1992. <span>«Zero-inflated Poisson regression, with an application to defects in manufacturing»</span>. <em>Technometrics</em> 34 (1): 1-14.
</div>
<div id="ref-nelder1972generalized" class="csl-entry" role="listitem">
Nelder, John Ashworth, y Robert WM Wedderburn. 1972. <span>«Generalized linear models»</span>. <em>Journal of the Royal Statistical Society Series A: Statistics in Society</em> 135 (3): 370-84.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./tema4.html" class="pagination-link" aria-label="Selección de variables, regularización y validación">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables, regularización y validación</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./conclusiones.html" class="pagination-link" aria-label="Conclusiones">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Conclusiones</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>