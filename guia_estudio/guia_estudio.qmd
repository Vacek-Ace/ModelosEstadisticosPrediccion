---
lang: es
format:
  pdf:
    pdf-engine: weasyprint
    title-block-banner: false 
    toc: true
    toc-title: "ndice gu铆a de estudio"
    include-before-body: portada.html
    css:../estilos.css
---

# Introducci贸n a la asignatura

Los modelos estad铆sticos han emergido como herramientas fundamentales en la era de la informaci贸n, donde la capacidad de analizar y predecir comportamientos a partir de datos se ha convertido en una habilidad esencial. En este contexto, los modelos para la predicci贸n juegan un papel crucial al permitirnos describir y cuantificar las relaciones entre variables, as铆 como anticipar resultados futuros. Este libro est谩 dise帽ado para proporcionar una comprensi贸n profunda y pr谩ctica de estas t茅cnicas, bas谩ndose en el contenido de la asignatura impartida en el **Grado en Matem谩ticas**.

El modelado estad铆stico tiene un prop贸sito dual que exploraremos en profundidad: la **predicci贸n** (la b煤squeda de la m谩xima precisi贸n) y la **inferencia** (la b煤squeda de la explicaci贸n y la comprensi贸n). Entender esta dicotom铆a es clave para seleccionar y evaluar los modelos de manera efectiva.

Comenzaremos sentando las bases de la regresi贸n lineal, desde su formulaci贸n m谩s simple hasta la complejidad del modelo m煤ltiple. A partir de ah铆, aprenderemos a enriquecer nuestros modelos mediante la **ingenier铆a de caracter铆sticas**, a seleccionar las variables m谩s relevantes con t茅cnicas de **selecci贸n y regularizaci贸n**, y finalmente, a extender nuestro alcance m谩s all谩 de la normalidad con los **Modelos Lineales Generalizados (GLM)**.

## Objetivos de la asignatura

- Aprender a formular, estimar e interpretar modelos de regresi贸n, comprendiendo los supuestos te贸ricos que los sustentan.
- Dominar el diagn贸stico de los modelos para verificar su validez y detectar problemas como la multicolinealidad o la heterocedasticidad.
- Saber aplicar t茅cnicas de ingenier铆a de caracter铆sticas, selecci贸n de variables y regularizaci贸n para optimizar el rendimiento y la interpretabilidad de los modelos.
- Extender el conocimiento de los modelos lineales a los GLM para poder modelar diferentes tipos de variables de respuesta (binarias, de conteo, etc.).
- Validar rigurosamente la capacidad predictiva de los modelos para asegurar su generalizaci贸n a nuevos datos.

## Temario de la asignatura
- **Tema 1:** Introducci贸n a los Modelos de Regresi贸n
- **Tema 2:** El Modelo de Regresi贸n Lineal Simple
- **Tema 3:** El Modelo de Regresi贸n Lineal M煤ltiple
- **Tema 4:** Ingenier铆a de Caracter铆sticas: Transformaciones e Interacciones
- **Tema 5:** Selecci贸n de Variables, Regularizaci贸n y Validaci贸n
- **Tema 6:** Modelos de Regresi贸n Generalizada (GLM)
- **Tema 7:** T贸picos Avanzados en Modelado Predictivo

# Desarrollo de la asignatura

El curso se desarrolla a lo largo de 15 semanas, con dos sesiones semanales. La metodolog铆a busca integrar la teor铆a y la pr谩ctica de forma fluida: los conceptos te贸ricos se presentar谩n junto con su implementaci贸n en R, fomentando un aprendizaje aplicado en cada clase.


## Semana 1: Presentaci贸n e Introducci贸n a los Modelos de Regresi贸n
- **Contenidos:** Presentaci贸n de la asignatura, gu铆a docente y sistema de evaluaci贸n. Se abordar谩n los conceptos fundamentales del modelado estad铆stico: el prop贸sito dual de **predecir vs. explicar** y la anatom铆a de un modelo de regresi贸n.
- ** Objetivos de Aprendizaje:**
    - Diferenciar entre un objetivo de predicci贸n y uno de inferencia.
    - Identificar los componentes clave de un modelo de regresi贸n (respuesta, predictores, error).
    - Comprender el ecosistema de modelos de regresi贸n y el rol de R en el curso.
- ** Materiales Utilizados:**
    - Apuntes (Tema 1), Diapositivas ("Introducci贸n a los Modelos Estad铆sticos"), `lab0_introduccion.html`.
- ** Actividades Planificadas:**
    - Discusi贸n sobre los objetivos de la asignatura.
    - Sesi贸n pr谩ctica introductoria con `lab0_introduccion.html` para configurar el entorno de R y RStudio.
- ** Trabajo Personal Recomendado:**
    - Lectura del Tema 1 de los apuntes.
    - Asegurar que el entorno de R/RStudio est谩 correctamente instalado y funcionando.


## Semana 2: Regresi贸n Lineal Simple (RLS) - Fundamentos y Estimaci贸n
- **Contenidos:** Formulaci贸n del modelo RLS, supuestos te贸ricos y estimaci贸n de par谩metros mediante **M铆nimos Cuadrados Ordinarios (MCO)**. Interpretaci贸n de coeficientes y coeficiente de determinaci贸n $R^2$.
- ** Objetivos de Aprendizaje:**
    - Formular matem谩ticamente el modelo de RLS.
    - Estimar los coeficientes $\beta_0$ y $\beta_1$ usando MCO.
    - Interpretar el significado pr谩ctico de la pendiente, el intercepto y $R^2$.
- ** Materiales Utilizados:**
    - Apuntes (Secciones 2.1 a 2.3), Diapositivas ("Regresi贸n Lineal Simple"), `lab1_regresion_simple.html`.
    - Ejercicios: Bolet铆n de RLS (Ejercicios 1, 2, 3).
- ** Actividades Planificadas:**
    - Ajuste de un primer modelo `lm()` en R.
    - An谩lisis e interpretaci贸n de la salida de la funci贸n `summary()`.
- ** Trabajo Personal Recomendado:**
    - Lectura de las secciones 2.1, 2.2 y 2.3 de los apuntes.
    - Realizaci贸n de los **ejercicios 1, 2 y 3** de RLS.


## Semana 3: RLS - Inferencia y Diagn贸stico
- **Contenidos:** Inferencia sobre los coeficientes (test-t), ANOVA para la significancia global (test F) y diagn贸stico completo de los supuestos a trav茅s del an谩lisis de residuos.
- ** Objetivos de Aprendizaje:**
    - Realizar e interpretar contrastes de hip贸tesis para los coeficientes.
    - Evaluar la bondad de ajuste de un modelo mediante ANOVA y $R^2$.
    - Diagnosticar la validez de los supuestos del modelo analizando los residuos.
- ** Materiales Utilizados:**
    - Apuntes (Secciones 2.4 a 2.6), Diapositivas ("Regresi贸n Lineal Simple"), `lab1_regresion_simple.html`.
    - Ejercicios: Bolet铆n de RLS (Ejercicios 4 al 10).
- ** Actividades Planificadas:**
    - Taller pr谩ctico de diagn贸stico de modelos, analizando gr谩ficamente los residuos (linealidad, homocedasticidad, normalidad).
    - Uso de tests estad铆sticos (Shapiro-Wilk, Breusch-Pagan) para confirmar el diagn贸stico visual.
- ** Trabajo Personal Recomendado:**
    - Completar el laboratorio `lab1_regresion_simple.html`.
    - Resolver los **ejercicios 4 al 10** de RLS.


## Semana 4: Regresi贸n Lineal M煤ltiple (RLM) - Formulaci贸n e Interpretaci贸n
- **Contenidos:** Extensi贸n al caso multivariante. Interpretaci贸n de coeficientes bajo el principio *ceteris paribus*. Coeficiente de determinaci贸n ajustado ($R^2_{adj}$). Diagn贸stico e identificaci贸n de la **multicolinealidad**.
- ** Objetivos de Aprendizaje:**
    - Interpretar correctamente los coeficientes de una RLM como efectos parciales.
    - Diagnosticar la presencia de multicolinealidad utilizando el Factor de Inflaci贸n de la Varianza (VIF).
- ** Materiales Utilizados:**
    - Apuntes (Tema 3), Diapositivas ("Regresi贸n Lineal M煤ltiple"), `lab2_regresion_multiple.html`.
    - Ejercicios: Bolet铆n de RLM (Ejercicios 1 al 6).
- ** Actividades Planificadas:**
    - Ajuste de un modelo de RLM en R.
    - Taller pr谩ctico de diagn贸stico de multicolinealidad, calculando e interpretando los valores VIF.
- ** Trabajo Personal Recomendado:**
    - Lectura completa del Tema 3 de los apuntes.
    - Resolver los **ejercicios 1 al 6** de RLM.


## Semana 5: Ingenier铆a de Caracter铆sticas I - Transformaciones
- **Contenidos:** T茅cnicas para mejorar el modelo: transformaciones de variables para linealizar relaciones y estabilizar la varianza (logar铆tmica, Box-Cox). Codificaci贸n de variables categ贸ricas (One-Hot vs. Ordinal).
- ** Objetivos de Aprendizaje:**
    - Saber cu谩ndo y c贸mo aplicar transformaciones para corregir violaciones de supuestos.
    - Codificar correctamente variables categ贸ricas seg煤n su naturaleza.
- ** Materiales Utilizados:**
    - Apuntes (Secciones 4.1 a 4.5), Diapositivas ("Ingenier铆a de Caracter铆sticas"), `lab3_ingenieria_caracteristicas.html`.
    - Ejercicios: Bolet铆n de Ing. de Caracter铆sticas (Ejercicios 1 al 6).
- ** Actividades Planificadas:**
    - Pr谩ctica en R sobre diagn贸stico de no-linealidad y aplicaci贸n de transformaciones.
    - Creaci贸n de variables *dummy- para predictores categ贸ricos.
- ** Trabajo Personal Recomendado:**
    - Lectura de las secciones sobre transformaciones en los apuntes (4.1-4.5).
    - Resolver los **ejercicios 1 al 6** (Tema 4).


## Semana 6: Ingenier铆a de Caracter铆sticas II - Interacciones
- **Contenidos:** Modelado de relaciones complejas mediante la inclusi贸n, visualizaci贸n e interpretaci贸n de **t茅rminos de interacci贸n** entre variables continuas y categ贸ricas.
- ** Objetivos de Aprendizaje:**
    - Identificar la necesidad de incluir un t茅rmino de interacci贸n.
    - Ajustar, visualizar e interpretar un modelo con interacciones.
- ** Materiales Utilizados:**
    - Apuntes (Secci贸n 4.6), Diapositivas ("Ingenier铆a de Caracter铆sticas"), `lab3_ingenieria_caracteristicas.html`.
    - Ejercicios: Bolet铆n de Ing. de Caracter铆sticas (Ejercicios 7 al 10).
- ** Actividades Planificadas:**
    - Ajuste de modelos con interacciones en R.
    - Visualizaci贸n de interacciones mediante gr谩ficos de efectos para interpretar c贸mo cambia la pendiente.
- ** Trabajo Personal Recomendado:**
    - Completar el laboratorio `lab3_ingenieria_caracteristicas.html`.
    - Resolver los **ejercicios 7 al 10** (Tema 4).


## Semana 7: Consolidaci贸n y Pr谩ctica de Regresi贸n Lineal
- **Contenidos:** Repaso y aplicaci贸n conjunta de RLS, RLM e ingenier铆a de caracter铆sticas.
- ** Objetivos de Aprendizaje:**
    - Integrar todos los conceptos de modelado lineal en un 煤nico flujo de trabajo.
    - Afrontar un problema de modelado de principio a fin: desde el an谩lisis exploratorio hasta el diagn贸stico final.
- ** Materiales Utilizados:**
    - Todos los materiales de los Temas 2, 3 y 4. Ejercicios de repaso de los boletines correspondientes.
- ** Actividades Planificadas:**
    - Resoluci贸n de un caso de estudio completo en clase.
    - Sesi贸n de tutor铆a y resoluci贸n de dudas para el Trabajo 1.
- ** Trabajo Personal Recomendado:**
    - Finalizar la preparaci贸n y entrega del Trabajo 1.


## Semana 8: Evaluaci贸n Parcial e Introducci贸n a la Selecci贸n de Variables
- **Contenidos:** Defensa oral del Trabajo 1. Introducci贸n a los criterios de informaci贸n (AIC, BIC, $C_p$ de Mallows) para la comparaci贸n de modelos.
- ** Objetivos de Aprendizaje:**
    - Defender y justificar las decisiones tomadas en un proyecto de modelado.
    - Comprender la base te贸rica del compromiso sesgo-varianza y c贸mo los criterios de informaci贸n lo cuantifican.
- ** Materiales Utilizados:**
    - Apuntes (Secci贸n 5.3), Diapositivas ("Selecci贸n de Variables, Regularizaci贸n y Validaci贸n").
    - Ejercicios: Bolet铆n de Selecci贸n de Variables (Ejercicio 3).
- ** Actividades Planificadas:**
    - Presentaciones orales del Trabajo 1.
    - Clase te贸rica sobre criterios de bondad de ajuste.
- ** Trabajo Personal Recomendado:**
    - Comenzar la lectura del Tema 5 y reflexionar sobre el **ejercicio conceptual 3**.


## Semana 9: M茅todos de Selecci贸n de Variables
- **Contenidos:** Estudio de los m茅todos autom谩ticos (*stepwise*) y exhaustivos (*best subset*), analizando sus ventajas y, sobre todo, sus limitaciones pr谩cticas.
- ** Objetivos de Aprendizaje:**
    - Aplicar algoritmos de selecci贸n de variables en R.
    - Analizar cr铆ticamente los resultados de los m茅todos autom谩ticos, entendiendo su inestabilidad.
- ** Materiales Utilizados:**
    - Apuntes (Secciones 5.4, 5.5), Diapositivas ("Selecci贸n de Variables, Regularizaci贸n y Validaci贸n"), `lab4_seleccion_variables.html`.
    - Ejercicios: Bolet铆n de Selecci贸n de Variables (Ejercicios 4, 5, 6).
- ** Actividades Planificadas:**
    - Pr谩ctica en R con las funciones `regsubsets()` y `step()`.
    - Discusi贸n sobre la invalidez de los p-valores en modelos seleccionados por m茅todos *stepwise*.
- ** Trabajo Personal Recomendado:**
    - Lectura de las secciones 5.4 y 5.5 de los apuntes.
    - Resolver los **ejercicios 4, 5 y 6**.


## Semana 10: Regularizaci贸n y Validaci贸n de Modelos
- **Contenidos:** T茅cnicas de regularizaci贸n (Ridge, Lasso, Elastic Net) y fundamentos de la validaci贸n de modelos, con especial foco en la **validaci贸n cruzada** (Cross-Validation).
- ** Objetivos de Aprendizaje:**
    - Comprender la diferencia fundamental entre la penalizaci贸n L1 (Lasso) y L2 (Ridge).
    - Aplicar la validaci贸n cruzada para seleccionar hiperpar谩metros y evaluar el rendimiento predictivo del modelo.
- ** Materiales Utilizados:**
    - Apuntes (Secciones 5.6, 5.7), Diapositivas ("Selecci贸n de Variables, Regularizaci贸n y Validaci贸n"), `lab4_seleccion_variables.html`.
    - Ejercicios: Bolet铆n de Selecci贸n de Variables (Ejercicios 7 al 10).
- ** Actividades Planificadas:**
    - Ajuste de modelos Lasso y Ridge con `glmnet` en R.
    - Uso de `cv.glmnet` para encontrar el valor 贸ptimo de lambda.
- ** Trabajo Personal Recomendado:**
    - Completar el laboratorio `lab4_seleccion_variables.html`.
    - Resolver los **ejercicios 7 al 10**.


## Semana 11: Modelos Lineales Generalizados (GLM) - Fundamentos
- **Contenidos:** Introducci贸n a los componentes clave que extienden el modelo lineal: la **familia exponencial**, la **funci贸n de enlace** y la estimaci贸n por M谩xima Verosimilitud (MLE).
- ** Objetivos de Aprendizaje:**
    - Identificar los tres componentes que definen cualquier GLM.
    - Entender por qu茅 se necesita MLE en lugar de MCO para estimar los GLM.
- ** Materiales Utilizados:**
    - Apuntes (Secci贸n 6.1, 6.2), Diapositivas ("Modelos Lineales Generalizados"), `lab5_modelos_generalizados.html`.
    - Ejercicios: Bolet铆n de GLM (Ejercicios 1, 2, 9).
- ** Actividades Planificadas:**
    - Clase te贸rica vinculando la regresi贸n lineal como un caso particular de los GLM.
    - An谩lisis de diferentes tipos de variables respuesta para identificar el GLM apropiado.
- ** Trabajo Personal Recomendado:**
    - Lectura de las secciones 6.1 a 6.4 de los apuntes y resoluci贸n de los **ejercicios conceptuales 1, 2 y 9**.


## Semana 12: GLM - Regresi贸n Log铆stica
- **Contenidos:** Estudio del modelo para respuestas binarias, incluyendo la interpretaci贸n de **Odds Ratios (OR)** y las m茅tricas de validaci贸n espec铆ficas como la **curva ROC** y el **AUC**.
- ** Objetivos de Aprendizaje:**
    - Ajustar e interpretar un modelo de regresi贸n log铆stica.
    - Calcular e interpretar los Odds Ratios.
    - Validar un clasificador binario mediante la matriz de confusi贸n y la curva ROC.
- ** Materiales Utilizados:**
    - Apuntes (Secci贸n 6.5), Diapositivas ("Modelos Lineales Generalizados"), `lab5_modelos_generalizados.html`.
    - Ejercicios: Bolet铆n de GLM (Ejercicios 3, 4, 5).
- ** Actividades Planificadas:**
    - Ajuste de un modelo `glm()` con `family = binomial`.
    - Taller pr谩ctico de c谩lculo de m茅tricas de clasificaci贸n y visualizaci贸n de la curva ROC.
- ** Trabajo Personal Recomendado:**
    - Resolver los **ejercicios 3, 4 y 5** sobre regresi贸n log铆stica.


## Semana 13: GLM - Regresi贸n de Poisson
- **Contenidos:** Modelado de datos de conteo, interpretaci贸n de **Incidence Rate Ratios (IRR)**, y diagn贸stico y soluci贸n del problema de la **sobredispersi贸n** mediante la Regresi贸n Binomial Negativa.
- ** Objetivos de Aprendizaje:**
    - Ajustar e interpretar un modelo de regresi贸n de Poisson.
    - Diagnosticar la sobredispersi贸n y saber cu谩ndo usar un modelo Binomial Negativo.
- ** Materiales Utilizados:**
    - Apuntes (Secci贸n 6.6), Diapositivas ("Modelos Lineales Generalizados"), `lab5_modelos_generalizados.html`.
    - Ejercicios: Bolet铆n de GLM (Ejercicios 6, 7, 8, 10).
- ** Actividades Planificadas:**
    - Ajuste de un modelo `glm()` con `family = poisson`.
    - C谩lculo del estad铆stico de dispersi贸n y comparaci贸n con un modelo `glm.nb()`.
- ** Trabajo Personal Recomendado:**
    - Completar el laboratorio `lab5_modelos_generalizados.html`.
    - Resolver los **ejercicios 6, 7, 8 y 10**.


## Semana 14: T贸picos Avanzados y Repaso
- **Contenidos:** Breve introducci贸n a extensiones de los modelos vistos, como los **Modelos Aditivos Generalizados (GAMs)**. Repaso general de toda la materia.
- ** Objetivos de Aprendizaje:**
    - Reconocer las situaciones en las que un GAM puede ser una alternativa 煤til.
    - Consolidar el conocimiento global de la asignatura y resolver dudas.
- ** Materiales Utilizados:**
    - Todos los materiales del curso, incluyendo los Ejercicios Avanzados.
- ** Actividades Planificadas:**
    - Sesi贸n de repaso general y consultas para el examen final.
    - Tutor铆as para el Trabajo Colectivo 2.
- ** Trabajo Personal Recomendado:**
    - Estudio para el examen final y desarrollo del trabajo.
    - Intentar resolver los **Ejercicios Avanzados**.


## Semana 15: Presentaci贸n de Proyectos Finales
- **Contenidos:** Exposici贸n y defensa del Trabajo Colectivo 2.
- ** Objetivos de Aprendizaje:**
    - Aplicar las t茅cnicas de la asignatura a un problema de modelado real.
    - Comunicar de forma efectiva los resultados de un an谩lisis estad铆stico.
- ** Materiales Utilizados:**
    - Proyectos desarrollados por los estudiantes.
- ** Actividades Planificadas:**
    - Presentaciones orales de los trabajos finales por parte de los grupos.
- ** Trabajo Personal Recomendado:**
    - N/A.


# Bibliograf铆a

A continuaci贸n, se presenta la bibliograf铆a utilizada y recomendada para el curso, dividida en textos principales y referencias complementarias.

## Bibliograf铆a Principal y Recomendada

- Agresti, A. (2015). *Foundations of linear and generalized linear models*. John Wiley & Sons.
- Box, G. E. P., & Cox, D. R. (1964). An analysis of transformations. *Journal of the Royal Statistical Society: Series B*, 26(2), 211-243.
- Draper, N. R. (1998). *Applied regression analysis*. McGraw-Hill.
- Fox, J., & Weisberg, S. (2018). *An R companion to applied regression*. Sage publications.
- Harrell, F. E. (2015). *Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis*. Springer.
- Hastie, T., Tibshirani, R., & Friedman, J. H. (2009). *The elements of statistical learning: data mining, inference, and prediction*. Springer.
- Hosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). *Applied logistic regression*. John Wiley & Sons.
- Jaccard, J., & Turrisi, R. (2003). *Interaction effects in multiple regression*. Sage.
- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning with Applications in R*. Springer.
- Kuhn, M., & Johnson, K. (2019). *Feature engineering and selection: a practical approach for predictive models*. CRC Press.
- Kutner, M. H., Nachtsheim, C. J., Neter, J., & Li, W. (2005). *Applied linear statistical models*. McGraw-Hill.
- McCullagh, P. (2019). *Generalized linear models*. Routledge.
- Nelder, J. A., & Wedderburn, R. W. M. (1972). Generalized linear models. *Journal of the Royal Statistical Society Series A*, 135(3), 370-384.
- Pinheiro, J. C., & Bates, D. M. (2000). *Mixed-Effects Models in S and S-PLUS*. Springer.
- Shmueli, G. (2010). To Explain or to Predict?. *Statistical Science*, 25(3), 289-310.
- Tukey, J. W. (1977). *Exploratory data analysis*. Reading, MA.
- Weisberg, S. (2005). *Applied linear regression*. Wiley.
- Wood, S. N. (2017). *Generalized Additive Models: An Introduction with R*. Chapman and Hall/CRC.
- Zheng, A., & Casari, A. (2018). *Feature engineering for machine learning: principles and techniques for data scientists*. O'Reilly Media.

## Referencias Adicionales y T贸picos Relacionados

- Bates, D., M盲chler, M., Bolker, B., & Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. *Journal of Statistical Software*, 67(1), 1-48.
- Bellman, R. E. (1978). *Artificial intelligence: can computers think?*.
- Flach, P. (2012). *Machine learning: the art and science of algorithms that make sense of data*. Cambridge University Press.
- Kelleher, J. D., & Tierney, B. (2018). *Data science*. MIT Press.
- Kelleher, J. D., Mac Namee, B., & D'arcy, A. (2020). *Fundamentals of machine learning for predictive data analytics*. MIT press.
- Molnar, C. (2020). *Interpretable machine learning*. Lulu.com.
- Murphy, K. P. (2012). *Machine learning: a probabilistic perspective*. MIT press.
- Russell, S. J. (2010). *Artificial intelligence a modern approach*. Pearson Education, Inc.
- Wirth, R., & Hipp, J. (2000). CRISP-DM: Towards a standard process model for data mining. *Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining*, 1, 29-39.
